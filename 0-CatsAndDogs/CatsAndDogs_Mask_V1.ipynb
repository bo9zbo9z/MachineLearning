{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CatsAndDogs_Mask_V1.ipynb","provenance":[{"file_id":"11uAUoq-UC0ftULnwk2LTbVryt3h-D3Q2","timestamp":1582044452297},{"file_id":"1KpHc6u2_eLqzTYla8bEH-SIPLGWtZ_vW","timestamp":1581035272578}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rl85J9Iqh4yQ"},"source":["## Cats and Dogs Mask Segmentation using tf.data\n","\n","Forked from: https://www.tensorflow.org/tutorials/images/segmentation\n","\n","At the end there is alternate model training example."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xjJySeIXh_md","colab":{}},"source":["#\"\"\"\n","# Google Collab specific stuff....\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","!ls \"/content/drive/My Drive\"\n","\n","USING_COLLAB = True\n","%tensorflow_version 2.x\n","#\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6w1an-l5h4yT","colab":{}},"source":["# Setup sys.path to find MachineLearning lib directory\n","\n","try: USING_COLLAB\n","except NameError: USING_COLLAB = False\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","import sys\n","if \"MachineLearning\" in sys.path[0]:\n","    pass\n","else:\n","    print(sys.path)\n","    if USING_COLLAB:\n","        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    else:\n","        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    \n","    print(sys.path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w1xivUWCPcVX","colab":{}},"source":["!pip install -q git+https://github.com/tensorflow/examples.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"csTt9CUvh4yZ","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import os, sys, random, warnings, time, copy, csv, gc\n","import numpy as np \n","\n","import IPython.display as display\n","from IPython.display import clear_output\n","\n","from PIL import Image\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from tensorflow_examples.models.pix2pix import pix2pix\n","import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n","\n","from tqdm import tqdm_notebook, tnrange, tqdm\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","print(\"AUTOTUNE: \", AUTOTUNE)\n","\n","from TrainingUtils import *\n","\n","#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","#warnings.filterwarnings(\"ignore\", category=UserWarning)\n","warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aplx71Xjh4yg"},"source":["## Examine and understand data\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PMdwqph-h4yd","colab":{}},"source":["# GLOBALS/CONFIG ITEMS\n","\n","# Set root directory path to data\n","if USING_COLLAB:\n","    ROOT_PATH = \"/content/drive/My Drive/ImageData/DogsCats\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","else:\n","    ROOT_PATH = \"/Users/john/Documents/ImageData/DogsCats\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","        \n","# Establish global dictionary\n","parms = GlobalParms(MODEL_NAME=\"model-CatsDogs-masks-transfer-V01.h5\",\n","                    ROOT_PATH=ROOT_PATH,\n","                    TRAIN_DIR=\"train\", \n","                    SMALL_RUN=False,\n","                    NUM_CLASSES=3,\n","                    IMAGE_ROWS=224,\n","                    IMAGE_COLS=224,\n","                    IMAGE_CHANNELS=3,\n","                    BATCH_SIZE=64,\n","                    EPOCS=10,  # set larger to improve results\n","                    IMAGE_EXT=\".jpg\",\n","                    LOSS=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                    METRICS=['accuracy'])\n","\n","parms.print_contents()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2mhhvmqN7aFa","colab":{}},"source":["\n","def show_batch_mask(display_list):\n","    plt.figure(figsize=(15, 15))\n","\n","    title = ['Input Image', 'True Mask', 'Predicted Mask']\n","\n","    for i in range(len(display_list)):\n","        plt.subplot(1, len(display_list), i+1)\n","        plt.title(title[i])\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n","        plt.axis('off')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_nrdWC3vQD1z","colab_type":"code","colab":{}},"source":["# Download dataset to local VM\n","builder = tfds.builder('oxford_iiit_pet:3.1.0')\n","info = builder.info\n","\n","# by setting register_checksums as True to pass the check\n","config = tfds.download.DownloadConfig(register_checksums = True)\n","builder.download_and_prepare(download_config=config)\n","full_dataset = builder.as_dataset()\n","\n","print(info)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rBhpD1ofHFrk","colab":{}},"source":["# Download dataset to local VM\n","#full_dataset, info = tfds.load('oxford_iiit_pet:3.1.0', with_info=True)\n","#print(info)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RSSm3dJ5guUQ","colab":{}},"source":["# Set Class names...\n","parms.set_class_names([\"Pet\", \"Bordering\", \"None\"])\n","print(\"Classes: \", parms.NUM_CLASSES, \n","      \"   Labels: \", len(parms.CLASS_NAMES), \n","      \"  \", parms.CLASS_NAMES)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oupAG8hO8IJV","colab":{}},"source":["!ls \"/root/tensorflow_datasets\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Z1R8KsrBkjgl"},"source":["## Build an input pipeline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QzIHTsEUcY2p","colab":{}},"source":["def normalize(image: tf.Tensor, mask: tf.Tensor) -> tf.Tensor:\n","    image = tf.cast(image, tf.float32) / 255.0\n","    mask -= 1\n","    return image, mask\n","\n","def process_train(cat_dog_dict: tf.Tensor) -> tf.Tensor:\n","    image = tf.image.resize(cat_dog_dict['image'], (parms.IMAGE_ROWS, parms.IMAGE_COLS))\n","    mask = tf.image.resize(cat_dog_dict['segmentation_mask'], (parms.IMAGE_ROWS, parms.IMAGE_COLS))\n","  \n","    if tf.random.uniform(()) > 0.5:\n","        image = tf.image.flip_left_right(image)\n","        mask = tf.image.flip_left_right(mask)\n","\n","    image, mask = normalize(image, mask)\n","    return image, mask\n","\n","def process_val(cat_dog_dict: tf.Tensor) -> tf.Tensor:\n","    image = tf.image.resize(cat_dog_dict['image'], (parms.IMAGE_ROWS, parms.IMAGE_COLS))\n","    mask = tf.image.resize(cat_dog_dict['segmentation_mask'], (parms.IMAGE_ROWS, parms.IMAGE_COLS))\n","\n","    image, mask = normalize(image, mask)\n","    return image, mask"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3MxUIepA5rF-","colab":{}},"source":["#Set buffer size\n","BUFFER_SIZE = 1000\n","\n","# set datasets\n","train_dataset = full_dataset[\"train\"]\n","val_dataset = full_dataset[\"test\"]\n","\n","# set lengths\n","train_len = info.splits['train'].num_examples\n","val_len = info.splits['test'].num_examples\n","images_list_len = train_len + val_len\n","\n","steps_per_epoch = np.ceil(train_len // parms.BATCH_SIZE) # set step sizes based on train & batch\n","validation_steps = np.ceil(val_len // parms.BATCH_SIZE) # set step sizes based on val & batch\n","\n","print(\"Total number: \", images_list_len, \"  Train number: \", train_len, \"  Val number: \", val_len)\n","print(\"Steps/EPOC: \", steps_per_epoch, \"  Steps/Validation: \", validation_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bhwlsx-48daB"},"source":["### Training setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-TZM_MFp5rGA","colab":{}},"source":["# Verify image paths were loaded and save one path for later in \"some_image\"\n","for f in train_dataset.take(2):\n","    some_image = f[\"image\"]\n","    some_mask = f[\"segmentation_mask\"]\n","    print(some_mask.shape)\n","\n","# map training images to pre-cache processing, includes any augmentation\n","train_dataset = train_dataset.map(process_train, num_parallel_calls=AUTOTUNE)\n","\n","# Verify the mapping worked\n","for image, mask in train_dataset.take(1):\n","    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n","    print(\"segmentation_mask: \", mask.shape, np.max(mask.numpy()), np.min(mask.numpy()))\n","\n","#train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(parms.BATCH_SIZE).repeat()\n","train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(parms.BATCH_SIZE).repeat()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w3DyZAzX7_Jw","colab":{}},"source":["# Show the images, execute this cell multiple times to see the images\n","\n","for image, mask in train_dataset.take(1):\n","    sample_image, sample_mask = image[0], mask[0]\n","show_batch_mask([sample_image, sample_mask])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CoLDjUFh8YQ8"},"source":["### Validation setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tZT2c4xY5rGD","colab":{}},"source":["# Verify image paths were loaded and save one path for later in \"some_image\"\n","for f in val_dataset.take(2):\n","    some_mask = f[\"segmentation_mask\"]\n","    print(some_mask.shape)\n","\n","# map training images to processing, includes any augmentation\n","val_dataset = val_dataset.map(process_val, num_parallel_calls=AUTOTUNE)\n","\n","# Verify the mapping worked\n","for image, mask in val_dataset.take(1):\n","    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n","    print(\"segmentation_mask: \", mask.shape)\n","\n","val_dataset = val_dataset.cache().batch(parms.BATCH_SIZE).repeat()\n","#val_dataset = val_dataset.batch(parms.BATCH_SIZE).repeat()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UHmOZtlv5rGG","colab":{}},"source":["# Test Validation, use smaller \"number_to_show\" to help show the augmentation\n","for image_batch, mask_batch in val_dataset.take(1):\n","    sample_image, sample_mask = image_batch[0], mask_batch[0]\n","show_batch_mask([sample_image, sample_mask])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WboW5rmAh4yv"},"source":["## Build  model\n","- add and validate pretrained model as a baseline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lIxJwoK4JnlX","colab":{}},"source":["class DisplayCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        clear_output(wait=True)\n","        show_predictions()\n","        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, min_lr=1e-6)\n","earlystopper = EarlyStopping(patience=8, verbose=1)\n","checkpointer = ModelCheckpoint(parms.MODEL_PATH, monitor='val_loss', verbose=1, mode=\"auto\", save_best_only=True)\n","   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Dg1IuTqEh4y0","colab":{}},"source":["base_model = tf.keras.applications.MobileNetV2(input_shape=[parms.IMAGE_ROWS, parms.IMAGE_COLS, 3], include_top=False)\n","\n","# Use the activations of these layers\n","layer_names = [\n","    'block_1_expand_relu',   # 64x64\n","    'block_3_expand_relu',   # 32x32\n","    'block_6_expand_relu',   # 16x16\n","    'block_13_expand_relu',  # 8x8\n","    'block_16_project'      # 4x4\n","]\n","layers = [base_model.get_layer(name).output for name in layer_names]\n","\n","# Create the feature extraction model\n","down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n","down_stack.trainable = False\n","\n","up_stack = [\n","    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n","    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n","    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n","    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n","]\n","\n","\n","def create_mask(pred_mask):\n","    pred_mask = tf.argmax(pred_mask, axis=-1)\n","    pred_mask = pred_mask[..., tf.newaxis]\n","    return pred_mask[0]\n","\n","\n","def show_predictions(dataset=None, num=1):\n","    if dataset:\n","        for image, mask in dataset.take(num):\n","            pred_mask = model.predict(image)\n","            show_batch_mask([image[0], mask[0], create_mask(pred_mask)])\n","    else:\n","        show_batch_mask([sample_image, sample_mask,\n","             create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n","    \n","def build_unet_model(output_channels):\n","    inputs = tf.keras.layers.Input(shape=[parms.IMAGE_ROWS, parms.IMAGE_COLS, 3])\n","    x = inputs\n","\n","    # Downsampling through the model\n","    skips = down_stack(x)\n","    x = skips[-1]\n","    skips = reversed(skips[:-1])\n","\n","    # Upsampling and establishing the skip connections\n","    for up, skip in zip(up_stack, skips):\n","        x = up(x)\n","        #####\n","        x = tf.keras.layers.BatchNormalization()(x)\n","        #####\n","        concat = tf.keras.layers.Concatenate()\n","        x = concat([x, skip])\n","\n","    # This is the last layer of the model\n","    last = tf.keras.layers.Conv2DTranspose(\n","        output_channels, 3, strides=2,\n","        padding='same')  #64x64 -> 128x128\n","\n","    x = last(x)\n","\n","    return tf.keras.Model(inputs=inputs, outputs=x)\n","\n","def compile_model(parms, model):\n","    model.compile(optimizer=tf.keras.optimizers.Adam(),\n","                  loss=parms.LOSS,\n","                  metrics=parms.METRICS)\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UHJP9A8_lLnr"},"source":["## Train model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P_AE9vRvh4y8","scrolled":true,"colab":{}},"source":["# Train model\n","model = build_unet_model(parms.NUM_CLASSES)\n","model = compile_model(parms, model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6n7g07RXDxqY","colab":{}},"source":["#model.save(parms.ROOT_PATH+ \"/\" + \"startModel.h5\")\n","#print(parms.ROOT_PATH+ \"/\" + \"startModel.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PwJAejDoJiIH","colab":{}},"source":["show_predictions()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UhqNEWnjSVVY","colab":{}},"source":["history = model.fit(train_dataset,\n","                    validation_data=val_dataset,\n","                    epochs=parms.EPOCS, \n","                    steps_per_epoch=steps_per_epoch,\n","                    validation_steps=validation_steps,\n","                    callbacks=[DisplayCallback(), reduce_lr, earlystopper])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"btOfnuWEh4y_","colab":{}},"source":["\n","# Plot the training history\n","history_df = pd.DataFrame(history.history)\n","plt.figure()\n","history_df[['loss', 'val_loss']].plot(title=\"Loss\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Loss')\n","history_df[['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UeMGmhySVUaW","colab":{}},"source":["show_predictions(val_dataset, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"COki5lZ0h4zG"},"source":["## Alternate model training approach\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3S74XA7vg6Np","colab":{}},"source":["#https://www.kaggle.com/yushas/imageprocessingtips\n","#Definie UNet Builder\n","def conv_block_mod(m, dim, acti, bn, res, do=0):\n","    n = tf.keras.layers.Conv2D(dim, 3, activation=acti, padding='same')(m)\n","    n = tf.keras.layers.BatchNormalization()(n) if bn else n\n","    n = tf.keras.layers.Dropout(do)(n) if do else n\n","    n = tf.keras.layers.Conv2D(dim, 3, activation=acti, padding='same')(n)\n","    n = tf.keras.layers.BatchNormalization()(n) if bn else n\n","    return tf.keras.layers.Concatenate()([m, n]) if res else n\n","\n","def level_block_mod(m, dim, depth, inc, acti, do, bn, mp, up, res):\n","    if depth > 0:\n","        n = conv_block_mod(m, dim, acti, bn, res)\n","        m = tf.keras.layers.MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n","        m = level_block_mod(m, int(inc*dim), depth-1, inc, acti, do, bn, mp, up, res)#再帰\n","        if up:\n","            m = tf.keras.layers.UpSampling2D()(m)\n","            m = tf.keras.layers.Conv2D(dim, 2, activation=acti, padding='same')(m)\n","        else:\n","            m = tf.keras.layers.Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n","        n = tf.keras.layers.Concatenate()([n, m])\n","        m = conv_block_mod(n, dim, acti, bn, res)\n","    else:\n","        m = conv_block_mod(m, dim, acti, bn, res, do)\n","    return m\n","\n","def UNet_mod(img_shape, out_ch=1, start_ch=64, depth=4, inc_rate=2., activation='relu', \n","         dropout=False, batchnorm=True, maxpool=True, upconv=True, residual=False):\n","    i = tf.keras.layers.Input(shape=img_shape)\n","    o = level_block_mod(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)#Unet\n","    o = tf.keras.layers.Conv2D(out_ch, 1, activation='sigmoid')(o)\n","    return Model(inputs=i, outputs=o)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WZPr-wchoy15","colab":{}},"source":["class DisplayCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        clear_output(wait=True)\n","        show_predictions()\n","        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, min_lr=1e-6)\n","earlystopper = EarlyStopping(patience=8, verbose=1)\n","   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uyHlYkZfhiaX","colab":{}},"source":["model2 = UNet_mod((parms.IMAGE_ROWS, parms.IMAGE_COLS, 3), out_ch=3, start_ch=16,depth=4,batchnorm=True,dropout=0.5)\n","model2 = compile_model(parms, model2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8I8ndvG8iJZ-","colab":{}},"source":["history2 = model2.fit(train_dataset,\n","                    validation_data=val_dataset,\n","                    epochs=parms.EPOCS, \n","                    steps_per_epoch=steps_per_epoch,\n","                    validation_steps=validation_steps,\n","                    callbacks=[DisplayCallback(), reduce_lr, earlystopper])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lxONUXqIidLJ","colab":{}},"source":["\n","# Plot the training history\n","history_df = pd.DataFrame(history2.history)\n","plt.figure()\n","history_df[['loss', 'val_loss']].plot(title=\"Loss\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Loss')\n","history_df[['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TuepxqA8lEbW","colab":{}},"source":["for image, mask in val_dataset.take(5):\n","    pred_mask = model2.predict(image)\n","    show_batch_mask([image[0], mask[0], create_mask(pred_mask)])\n"],"execution_count":0,"outputs":[]}]}