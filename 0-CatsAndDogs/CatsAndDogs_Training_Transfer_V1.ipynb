{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CatsAndDogs_Training_Transfer_V1.ipynb","provenance":[{"file_id":"11uAUoq-UC0ftULnwk2LTbVryt3h-D3Q2","timestamp":1582044452297},{"file_id":"1KpHc6u2_eLqzTYla8bEH-SIPLGWtZ_vW","timestamp":1581035272578}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rl85J9Iqh4yQ"},"source":["## Cats and Dogs classifier using Transfer Learning and tf.data\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xjJySeIXh_md","colab":{}},"source":["#\"\"\"\n","# Google Collab specific stuff....\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","!ls \"/content/drive/My Drive\"\n","\n","USING_COLLAB = True\n","%tensorflow_version 2.x\n","#\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6w1an-l5h4yT","colab":{}},"source":["# Setup sys.path to find MachineLearning lib directory\n","\n","try: USING_COLLAB\n","except NameError: USING_COLLAB = False\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","import sys\n","if \"MachineLearning\" in sys.path[0]:\n","    pass\n","else:\n","    print(sys.path)\n","    if USING_COLLAB:\n","        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib') ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    else:\n","        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    \n","    print(sys.path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"csTt9CUvh4yZ","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import os, sys, random, warnings, time, copy, csv, gc\n","import numpy as np \n","\n","import IPython.display as display\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import cv2\n","from tqdm import tqdm_notebook, tnrange, tqdm\n","import pandas as pd\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","import tensorflow_datasets as tfds\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","print(\"AUTOTUNE: \", AUTOTUNE)\n","\n","from TrainingUtils import *\n","\n","#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","#warnings.filterwarnings(\"ignore\", category=UserWarning)\n","warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aplx71Xjh4yg"},"source":["## Examine and understand data\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PMdwqph-h4yd","colab":{}},"source":["# GLOBALS/CONFIG ITEMS\n","\n","# Set root directory path to data\n","if USING_COLLAB:\n","    ROOT_PATH = \"/content/drive/My Drive/ImageData/DogsCats\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","else:\n","    ROOT_PATH = \"/Users/john/Documents/ImageData/DogsCats\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","        \n","# Establish global dictionary\n","parms = GlobalParms(MODEL_NAME=\"model-CatsDogs-tf-data-V01.h5\",\n","                    ROOT_PATH=ROOT_PATH,\n","                    TRAIN_DIR=\"train\", \n","                    SMALL_RUN=False,\n","                    NUM_CLASSES=2,\n","                    IMAGE_ROWS=224,\n","                    IMAGE_COLS=224,\n","                    IMAGE_CHANNELS=3,\n","                    BATCH_SIZE=8,\n","                    EPOCS=2,  # set larger as needed\n","                    IMAGE_EXT=\".jpg\",\n","                    FINAL_ACTIVATION='sigmoid',\n","                    LOSS='binary_crossentropy',\n","                    METRICS=['accuracy'])\n","\n","parms.print_contents()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2mhhvmqN7aFa","colab":{}},"source":["# Simple helper method to display batches of images with labels....        \n","def show_batch(image_batch, label_batch, number_to_show=25, r=5, c=5, print_shape=False):\n","    show_number = min(number_to_show, parms.BATCH_SIZE)\n","\n","    if show_number < 8: #if small number, then change row, col and figure size\n","        if parms.IMAGE_COLS > 64 or parms.IMAGE_ROWS > 64:\n","            plt.figure(figsize=(25,25)) \n","        else:\n","            plt.figure(figsize=(10,10))  \n","        r = 4\n","        c = 2 \n","    else:\n","        plt.figure(figsize=(10,10))  \n","\n","    if show_number == 1:\n","        image_batch = np.expand_dims(image_batch, axis=0)\n","        label_batch = np.expand_dims(label_batch, axis=0)\n","\n","    for n in range(show_number):\n","        if print_shape:\n","            print(\"Image shape: {}  Max: {}  Min: {}\".format(image_batch[n].shape, \n","                                                             np.max(image_batch[n]), \n","                                                             np.min(image_batch[n])))\n","        ax = plt.subplot(r,c,n+1)\n","        cmap=\"gray\"\n","        if len(image_batch[n].shape) == 3:\n","            if image_batch[n].shape[2] == 3:\n","                cmap=\"viridis\"\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]), cmap=plt.get_cmap(cmap))\n","\n","        plt.title(parms.CLASS_NAMES[np.argmax(label_batch[n])])\n","\n","        plt.axis('off')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rBhpD1ofHFrk","colab":{}},"source":["# Download dataset to local VM\n","full_dataset, info = tfds.load(name=\"cats_vs_dogs\", with_info=True, split=\"train\")\n","assert isinstance(full_dataset, tf.data.Dataset)\n","print(info)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RSSm3dJ5guUQ","colab":{}},"source":["# Set Class names...\n","parms.set_class_names([\"Cat\", \"Dog\"])\n","print(\"Classes: \", parms.NUM_CLASSES, \n","      \"   Labels: \", len(parms.CLASS_NAMES), \n","      \"  \", parms.CLASS_NAMES)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oupAG8hO8IJV","colab":{}},"source":["!ls \"/root/tensorflow_datasets/cats_vs_dogs\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Z1R8KsrBkjgl"},"source":["## Build an input pipeline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QzIHTsEUcY2p","colab":{}},"source":["def image_rescale_1_neg_1(image: tf.Tensor) -> tf.Tensor:\n","    image = tf.image.resize(image, (parms.IMAGE_ROWS, parms.IMAGE_COLS))\n","    # takes Any scale and converts to 1..-1\n","    image = (tf.constant(2., dtype=tf.float32)*(image - tf.math.reduce_min(image))/(tf.math.reduce_max(image) - tf.math.reduce_min(image)))-1\n","    return image\n","\n","def process_train(cat_dog_dict: tf.Tensor) -> tf.Tensor:\n","    image = cat_dog_dict[\"image\"]\n","    label = cat_dog_dict[\"label\"]\n","    image = image_rescale_1_neg_1(image)\n","    return image, label_to_onehot(label)\n","\n","\n","def process_val(cat_dog_dict: tf.Tensor) -> tf.Tensor:\n","    image = cat_dog_dict[\"image\"]\n","    label = cat_dog_dict[\"label\"]\n","    image = image_rescale_1_neg_1(image)\n","    return image, label_to_onehot(label)\n","\n","def label_to_onehot(label: tf.Tensor) -> tf.Tensor:\n","    return tf.one_hot(label, parms.NUM_CLASSES)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3MxUIepA5rF-","colab":{}},"source":["# split into training and validation sets of images\n","images_list_len = info.splits['train'].num_examples\n","\n","train_len = int(0.9 * images_list_len)\n","val_len = images_list_len - train_len\n","\n","# Create datasets with new sizes\n","train_dataset = full_dataset.take(train_len)  #  Creates dataset with new size\n","val_dataset = full_dataset.skip(train_len)  # Creates dataset after skipping over the size\n","\n","steps_per_epoch = np.ceil(train_len // parms.BATCH_SIZE) # set step sizes based on train & batch\n","validation_steps = np.ceil(val_len // parms.BATCH_SIZE) # set step sizes based on val & batch\n","\n","print(\"Total number: \", images_list_len, \"  Train number: \", train_len, \"  Val number: \", val_len)\n","print(\"Steps/EPOC: \", steps_per_epoch, \"  Steps/Validation: \", validation_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bhwlsx-48daB"},"source":["### Training setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lSrwCo5J7zWo","colab":{}},"source":["def cache_dataset(dataset, cache=False):\n","    if cache:\n","        if isinstance(cache, str):\n","            dataset = dataset.cache(cache)\n","        else:\n","            dataset = dataset.cache()\n","    return dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-TZM_MFp5rGA","colab":{}},"source":["# Verify image paths were loaded and save one path for later in \"some_image\"\n","for f in train_dataset.take(2):\n","    some_image = f[\"image\"]\n","    some_label = f[\"label\"]\n","    print(some_label)\n","\n","# map training images to pre-cache processing, includes any augmentation\n","train_dataset = train_dataset.map(process_train, num_parallel_calls=AUTOTUNE)\n","\n","# Verify the mapping worked\n","for image, label in train_dataset.take(1):\n","    print(\"Map 1 Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n","    print(\"Label: \", np.argmax(label.numpy()), label.numpy())\n","\n","# cache\n","train_dataset = cache_dataset(train_dataset, cache=\"./CatDogtrain1.tfcache\")\n","#train_dataset = cache_dataset(train_dataset, cache=True)\n","\n","# Repeat forever\n","train_dataset = train_dataset.repeat()\n","\n","# set the batch size\n","train_dataset = train_dataset.batch(parms.BATCH_SIZE)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w3DyZAzX7_Jw","colab":{}},"source":["# Show the images, execute this cell multiple times to see the images\n","\n","image_batch, label_batch = next(iter(train_dataset))\n","#show_batch(image_batch.numpy(), label_batch.numpy())\n","show_batch(image_batch.numpy(), label_batch.numpy(), print_shape=False, number_to_show=6)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CoLDjUFh8YQ8"},"source":["### Validation setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tZT2c4xY5rGD","colab":{}},"source":["# Verify image paths were loaded and save one path for later in \"some_image\"\n","for f in val_dataset.take(2):\n","    some_label = f[\"label\"]\n","    print(some_label)\n","\n","# map training images to processing, includes any augmentation\n","val_dataset = val_dataset.map(process_val, num_parallel_calls=AUTOTUNE)\n","\n","# Verify the mapping worked\n","for image, label in val_dataset.take(1):\n","    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n","    print(\"Label: \", np.argmax(label.numpy()), label.numpy())\n","\n","# cache\n","val_dataset = cache_dataset(val_dataset, cache=\"./CatDogVal2.tfcache\")\n","#val_dataset = cache_dataset(val_dataset, cache=True)\n","\n","# Repeat forever\n","val_dataset = val_dataset.repeat()\n","\n","# set the batch size\n","val_dataset = val_dataset.batch(parms.BATCH_SIZE)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UHmOZtlv5rGG","colab":{}},"source":["# Test Validation, use smaller \"number_to_show\" to help show the augmentation\n","\n","image_batch, label_batch = next(iter(val_dataset))\n","#show_batch(image_batch.numpy(), label_batch.numpy())\n","show_batch(image_batch.numpy(), label_batch.numpy(), number_to_show=6)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WboW5rmAh4yv"},"source":["## Build  model\n","- add and validate pretrained model as a baseline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H6KnOf_oh4yw","colab":{}},"source":["# Create any call backs for training...These are the most common.\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, min_lr=1e-6)\n","earlystopper = EarlyStopping(patience=8, verbose=1)\n","checkpointer = ModelCheckpoint(parms.MODEL_PATH, monitor='val_loss', verbose=1, mode=\"auto\", save_best_only=True)\n","#csv_logger = CSVLogger(self.cvslogfile, append=True, separator=';')\n","\n","#from keras.callbacks import TensorBoard\n","#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Dg1IuTqEh4y0","colab":{}},"source":["# Create model and compile it\n","\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D, Conv2DTranspose, Concatenate, Activation\n","from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n","from tensorflow.keras.optimizers import Adadelta, Adam, Nadam, SGD\n","########\n","\n","# https://www.tensorflow.org/api_docs/python/tf/keras/applications\n","from tensorflow.keras.applications import MobileNet, imagenet_utils, ResNet50\n","from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n","\n","actual_MobileNet = tf.keras.applications.mobilenet.MobileNet()\n","#actual_ResNet50 = tf.keras.applications.ResNet50()\n","\n","def set_train_layers(model, train_layers=20): #since 224x224x3, set the first 20 layers of the network to be non-trainable\n","    if train_layers == 0: #set all non-trainable\n","        for layer in model.layers:\n","            layer.trainable=False\n","    else:\n","        for layer in model.layers[:train_layers]:             \n","            layer.trainable=False\n","        for layer in model.layers[train_layers:]:\n","            layer.trainable=True\n","    return model\n","\n","def predict_image(model_passed, image):  \n","    image = image_rescale_1_neg_1(image)   \n","    image = np.expand_dims(image, axis=0)\n","    predictions = model_passed.predict(image)\n","    return predictions \n","\n","\n","def build_model(parms):\n","    base_model=MobileNet(weights='imagenet',include_top=False, input_shape=parms.IMAGE_DIM) #imports the mobilenet model and discards the last 1000 neuron layer.\n","    x=base_model.output\n","    x=GlobalAveragePooling2D()(x)\n","    x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n","    x=Dense(1024,activation='relu')(x) #dense layer 2\n","    x=Dense(512,activation='relu')(x) #dense layer 3\n","    preds=Dense(parms.NUM_CLASSES, activation=parms.FINAL_ACTIVATION)(x) #final layer\n","    model=Model(inputs=base_model.input,outputs=preds)\n","    return model\n","\n","def compile_model(parms, model):\n","    # Optimizers: https://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms\n","    model.compile(loss=parms.LOSS,\n","          optimizer=SGD(lr=0.001, momentum=0.9),\n","          #optimizer=\"adam\",\n","          #optimizer=\"rmsprop\",\n","          metrics=parms.METRICS)\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dj-uogcrzvYy","colab":{}},"source":["# Double check preprocessing with utility.  np.max & np.min should align with your normalization\n","# https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py\n","\n","img_MobileNet = tf.keras.applications.mobilenet.preprocess_input(tf.cast(some_image, tf.float32))\n","print(\"Image \", some_image.shape, np.max(some_image), np.min(some_image))\n","print(\"Pre   \", img_MobileNet.shape, np.max(img_MobileNet), np.min(img_MobileNet))\n","fig = plt.figure()\n","plt.imshow(tf.keras.preprocessing.image.array_to_img(img_MobileNet))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eLiR08Mqh4y3","colab":{}},"source":["#test an image just using MobileNet\n","predictions = predict_image(actual_MobileNet, some_image)\n","result = imagenet_utils.decode_predictions(predictions)\n","\n","#predictions = predict_image(actual_ResNet50, some_image)\n","#result = resnet50.decode_predictions(predictions, top=1))\n","\n","result \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DOaedfZyh4y5","colab":{}},"source":["#show the image...\n","fig = plt.figure()\n","plt.imshow(tf.keras.preprocessing.image.array_to_img(some_image))\n","fig.suptitle(parms.CLASS_NAMES[some_label])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UHJP9A8_lLnr"},"source":["## Train model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P_AE9vRvh4y8","scrolled":true,"colab":{}},"source":["# Train model\n","model = build_model(parms)\n","set_train_layers(model)\n","model = compile_model(parms, model)\n","\n","history = model.fit(train_dataset,\n","                    validation_data=val_dataset,\n","                    epochs=parms.EPOCS, \n","                    steps_per_epoch=steps_per_epoch,\n","                    validation_steps=validation_steps,\n","                    callbacks=[reduce_lr, earlystopper, checkpointer] # include any callbacks...\n","                    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"btOfnuWEh4y_","colab":{}},"source":["# Plot the training history\n","history_df = pd.DataFrame(history.history)\n","plt.figure()\n","history_df[['loss', 'val_loss']].plot(title=\"Loss\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Loss')\n","history_df[['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"COki5lZ0h4zG"},"source":["## Validate model's predictions\n","- Create actual_lables and predict_labels\n","- Calculate Confusion Matrix & Accuracy\n","- Display results\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tkrhk6FOh4zC","colab":{}},"source":["#Load saved model\n","from tensorflow.keras.models import load_model \n","def load_saved_model(model_path):\n","    model = load_model(model_path)\n","    print(\"loaded: \", model_path)\n","    return model\n","\n","model = load_saved_model(parms.MODEL_PATH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4T-oypFsh4zM","colab":{}},"source":["# Use model to generate predicted labels and probabilities\n","labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset(model, val_dataset, validation_steps, parms.BATCH_SIZE, create_bad_results_list=False)\n","#labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset(model, val_dataset, 1, parms.BATCH_SIZE, create_bad_results_list=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_IurHe_Uh4zO","colab":{}},"source":["show_confusion_matrix(labels, predict_labels, parms.CLASS_NAMES)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gdAXk58Zh4zR","colab":{}},"source":["# Graph the results\n","display_prediction_results(labels, predict_labels, predict_probabilities, parms.NUM_CLASSES, parms.CLASS_NAMES)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4e2xRnkGh4zU","colab":{}},"source":["#Create a df from the bad results list, can save as csv or use for further analysis\n","bad_results_df = pd.DataFrame(bad_results, columns =['actual', 'predict', 'prob', 'image'])\n","bad_results_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JW3AQv7Fh4zh","colab":{}},"source":["# default is to not return bad_results, change to include them, create_bad_results_list=True\n","\n","#bad_act, bad_pred, bad_prob, bad_images = zip(*bad_results)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"reSRPklT5rG0","colab":{}},"source":["# display images....        \n","def show_bad_batch(image_batch, bad_act, bad_pred, number_to_show=25):\n","    plt.figure(figsize=(10,10))\n","    show_number = number_to_show\n","    if len(image_batch) < number_to_show:\n","        show_number = len(image_batch)\n","        \n","    for n in range(show_number):\n","        ax = plt.subplot(5,5,n+1)\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]))\n","        #s = parms.CLASS_NAMES[bad_pred[n][0]]\n","        s = \"Act: \"+ str(bad_act[n][0]) + \" Pred: \" + str(bad_pred[n][0])\n","        plt.title(s)\n","        plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8mTsZs0-5rG3","colab":{}},"source":["\n","#show_bad_batch(bad_images, bad_act, bad_pred)"],"execution_count":0,"outputs":[]}]}