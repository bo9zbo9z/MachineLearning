{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rl85J9Iqh4yQ"
   },
   "source": [
    "# Preform analysis on images\n",
    "\n",
    "This ia a helper notebook and uses cats/dogs as the example.  In real usage you would copy this notebook to your subdirectory and then change the dataset access as needed.  You could then customize the reporting based on the type of problem and images.  When you look in some of my folders you will see my copy that I've used to analyze images - like for example, Dog Breeds.\n",
    "\n",
    "Sample pandas examples:\n",
    "\n",
    "https://github.com/rasbt/pattern_classification/blob/master/data_viz/matplotlib_viz_gallery.ipynb\n",
    "https://github.com/rasbt/pattern_classification/blob/master/data_viz/matplotlib_viz_gallery.ipynb\n",
    "\n",
    "### Processing for using Google Drive and normal includes\n",
    "\n",
    "The notebook uses TensorFlow 2.x.  (Eager execution is enabled by default and we use the newer versions of tf.Data.)\n",
    "\n",
    "I use Notebooks running on Colab and on my local workstation, so I need to separate some logic to make it easier to run in both locations.\n",
    "\n",
    "I was going to delete and just make Colab version, but that is not \"real world.\"  You usually have multiple environments and I'm showing you how I accommodate different environments, you might need something different...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjJySeIXh_md"
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "# Google Collab specific stuff....\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "!ls \"/content/drive/My Drive\"\n",
    "\n",
    "USING_COLLAB = True\n",
    "# Force to use 2.x version of Tensorflow\n",
    "%tensorflow_version 2.x\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6w1an-l5h4yT"
   },
   "outputs": [],
   "source": [
    "# Setup sys.path to find MachineLearning lib directory\n",
    "\n",
    "# Check if \"USING_COLLAB\" is defined, if yes, then we are using Colab, otherwise set to False\n",
    "try: USING_COLLAB\n",
    "except NameError: USING_COLLAB = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set path env var\n",
    "import sys\n",
    "if \"MachineLearning\" in sys.path[0]: \n",
    "    pass\n",
    "else:\n",
    "    print(sys.path)\n",
    "    if USING_COLLAB:\n",
    "        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    else:\n",
    "        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csTt9CUvh4yZ"
   },
   "outputs": [],
   "source": [
    "# Normal includes...\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys, random, warnings, time, copy, csv\n",
    "import numpy as np \n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# This allows the runtime to decide how best to optimize CPU/GPU usage\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from TrainingUtils import *\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aplx71Xjh4yg"
   },
   "source": [
    "## General Setup\n",
    "\n",
    "- Create a dictionary wrapped by a class for global values.  This is how I manage global vars in my notebooks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMdwqph-h4yd"
   },
   "outputs": [],
   "source": [
    "# Set root directory path to data\n",
    "if USING_COLLAB:\n",
    "    ROOT_PATH = \"/content/drive/My Drive/GitHub/MachineLearning/9-LibTest/Data\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "else:\n",
    "    ROOT_PATH = \"/Users/john/Documents/GitHub/MachineLearning/9-LibTest/Data\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "        \n",
    "# Establish global dictionary\n",
    "parms = GlobalParms(ROOT_PATH=ROOT_PATH,\n",
    "                    TRAIN_DIR=\"CatDogLabeledVerySmall\", \n",
    "                    NUM_CLASSES=2,\n",
    "                    IMAGE_ROWS=256,\n",
    "                    IMAGE_COLS=256,\n",
    "                    IMAGE_CHANNELS=3,\n",
    "                    BATCH_SIZE=1,  # must be one if you want to see different image sizes\n",
    "                    IMAGE_EXT=\".jpg\")\n",
    "\n",
    "parms.print_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWyqw8Yw5rF7"
   },
   "outputs": [],
   "source": [
    "# Simple helper method to display batches of images with labels....        \n",
    "def show_batch(image_batch, label_batch, number_to_show=25, r=5, c=5, print_shape=False):\n",
    "    show_number = min(number_to_show, parms.BATCH_SIZE)\n",
    "\n",
    "    if show_number < 8: #if small number, then change row, col and figure size\n",
    "        if parms.IMAGE_COLS > 64 or parms.IMAGE_ROWS > 64:\n",
    "            plt.figure(figsize=(25,25)) \n",
    "        else:\n",
    "            plt.figure(figsize=(10,10))  \n",
    "        r = 4\n",
    "        c = 2 \n",
    "    else:\n",
    "        plt.figure(figsize=(10,10))  \n",
    "\n",
    "    for n in range(show_number):\n",
    "        if print_shape:\n",
    "            print(\"Image shape: {}  Max: {}  Min: {}\".format(image_batch[n].shape, np.max(image_batch[n]), np.min(image_batch[n])))\n",
    "\n",
    "        ax = plt.subplot(r,c,n+1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]))\n",
    "        plt.title(parms.CLASS_NAMES[np.argmax(label_batch[n])])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wJ5iS1Tu3Jq"
   },
   "source": [
    "### Create dataset and normal mappings\n",
    "\n",
    "Pipeline Flow:\n",
    "\n",
    "create dataset -> map \"process_path\" -> repeat forever -> batch\n",
    "\n",
    "The mappings open and read an image.  These next cells should be changed based on your specific needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaK22hoX5rFr"
   },
   "outputs": [],
   "source": [
    "# Create path list and class list using cat/dog images\n",
    "# Change for your own dataset \n",
    "images_list, sub_directories = load_file_names_labeled_subdir_Util(parms.TRAIN_PATH, \n",
    "                                                                   parms.IMAGE_EXT)\n",
    "\n",
    "images_list_len = len(images_list)\n",
    "print(\"Number of images: \", images_list_len)\n",
    "\n",
    "# Set the class names.\n",
    "parms.set_class_names(sub_directories)\n",
    "print(\"Classes: {}  Labels: {}  {}\".format(parms.NUM_CLASSES, len(parms.CLASS_NAMES), parms.CLASS_NAMES) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDYxSZRP5rFu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the path, show the images that will be used\n",
    "for image_path in images_list[:2]:\n",
    "    print(image_path)\n",
    "    display.display(Image.open(str(image_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Za1IWHt5rF1"
   },
   "outputs": [],
   "source": [
    "# Return a label based on the path of the image\n",
    "def get_label(file_path: tf.Tensor) -> tf.Tensor:\n",
    "\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == parms.CLASS_NAMES\n",
    "\n",
    "# Decode the image, convert to float, normalize by 255 and resize\n",
    "def decode_img(image: tf.Tensor) -> tf.Tensor:\n",
    "\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=parms.IMAGE_CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    image = tf.image.convert_image_dtype(image, parms.IMAGE_DTYPE)\n",
    "\n",
    "    # uncomment to resize the image to the desired size.\n",
    "    #image = tf.image.resize(image, [parms.IMAGE_ROWS, parms.IMAGE_COLS])\n",
    "    return image\n",
    "\n",
    "# method mapped to load, resize and aply any augmentations\n",
    "def process_path(file_path: tf.Tensor) -> tf.Tensor:\n",
    "  \n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = decode_img(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "USATdbIyi8Ca"
   },
   "source": [
    "### Create dataset from list of images and apply mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-LXAs3e5rFx"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from list of images\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(np.array(images_list))\n",
    "\n",
    "# Verify image paths were loaded and save one path for later in \"some_image\"\n",
    "for f in full_dataset.take(2):\n",
    "    some_image = f.numpy().decode(\"utf-8\")\n",
    "    print(f.numpy())\n",
    "    \n",
    "print(\"Some Image: \", some_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TZM_MFp5rGA"
   },
   "outputs": [],
   "source": [
    "# map training images to processing, includes any augmentation\n",
    "full_dataset = full_dataset.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, label in full_dataset.take(1):\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    print(\"Label: \", label.numpy())\n",
    "\n",
    "# Repeat forever\n",
    "full_dataset = full_dataset.repeat()\n",
    "\n",
    "# set the batch size\n",
    "full_dataset = full_dataset.batch(parms.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1_Q_XaoBtZt"
   },
   "outputs": [],
   "source": [
    "#create simple iterator\n",
    "ds_iter = iter(full_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHmOZtlv5rGG"
   },
   "outputs": [],
   "source": [
    "# Show the images, execute this cell multiple times to see the images\n",
    "# Execute at least 4 times if random is applied\n",
    "\n",
    "image_batch, label_batch = next(ds_iter)\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZQ7y2k0pjHQ4"
   },
   "source": [
    "### Collect image information\n",
    "\n",
    "This will loop over each image and collect information to be used to create a Pandas dataframe.  The dataframe will then be used to report information.  You can also save the dataframe for future analysis.\n",
    "\n",
    "This is where you can also customize what information is collected.\n",
    "\n",
    "The size of the image is not changed, but you can change so every image is exactly like how it will be used for training.  I've found that looking at the raw image information is more helpful than looking at images that have been resized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCM_Xd4irwy_"
   },
   "outputs": [],
   "source": [
    "# Collect various information about an image\n",
    "def dataset_analysis(ds_iter, steps, test=False):\n",
    "    if test == True:\n",
    "        steps = 4\n",
    "\n",
    "    image_info = []\n",
    "\n",
    "    for i in tqdm(range(int(steps))):\n",
    "        image_batch, label_batch = next(ds_iter)\n",
    "        #show_batch(image_batch.numpy(), label_batch.numpy())\n",
    "\n",
    "        for j in range(parms.BATCH_SIZE):\n",
    "            image = image_batch[j].numpy()\n",
    "            label = label_batch[j].numpy()\n",
    "            label = np.argmax(label)\n",
    "            r = image.shape[0]\n",
    "            c = image.shape[1]\n",
    "            d = 0\n",
    "            mean0=0\n",
    "            mean1=0\n",
    "            mean2=0\n",
    "            if parms.IMAGE_CHANNELS == 3:\n",
    "                d = image.shape[2]\n",
    "                mean0 = np.mean(image[:,:,0])\n",
    "                mean1 = np.mean(image[:,:,1])\n",
    "                mean2 = np.mean(image[:,:,2])\n",
    "            image_info.append([label, r, c, d, np.mean(image), np.std(image), mean0, mean1, mean2])\n",
    "\n",
    "            if test:\n",
    "                print(image_info[-1])\n",
    "                \n",
    "    return image_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJIlgXSStQIY"
   },
   "outputs": [],
   "source": [
    "# Build image_info list\n",
    "ds_iter = iter(full_dataset)\n",
    "\n",
    "steps = np.ceil(images_list_len // parms.BATCH_SIZE)\n",
    "\n",
    "image_info = dataset_analysis(ds_iter, steps=steps, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pas-QSw6p8gA"
   },
   "outputs": [],
   "source": [
    "# Build pandas dataframe\n",
    "image_info_df = pd.DataFrame(image_info, columns =['label', 'row','col', 'dim', 'mean', 'std', \"chmean0\", \"chmean1\", \"chmean2\"])\n",
    "print(image_info_df.describe())\n",
    "image_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YO68MUsjp8kX"
   },
   "outputs": [],
   "source": [
    "#https://jamesrledoux.com/code/group-by-aggregate-pandas\n",
    "image_info_df.groupby('label').agg({'mean': ['count', 'mean', 'min', 'max'], 'std': ['mean', 'min', 'max'], 'row': ['mean', 'min', 'max'],'col': ['mean', 'min', 'max'], 'chmean0':['mean'],'chmean1':['mean'],'chmean2':['mean'] })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JBVoJW-Xp8o3"
   },
   "outputs": [],
   "source": [
    "image_info_df.agg({'mean': ['mean', 'min', 'max'], 'std': ['mean', 'min', 'max'], 'row': ['mean', 'min', 'max'],'col': ['mean', 'min', 'max'] })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_3lyzlN6qFcc"
   },
   "outputs": [],
   "source": [
    "image_mean = image_info_df[\"mean\"]\n",
    "print(\"Mean: \", np.mean(image_mean), \"  STD: \", np.std(image_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6_tIxRQqIOn"
   },
   "outputs": [],
   "source": [
    "image_info_df[\"label\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GL1wjemvqLFy"
   },
   "outputs": [],
   "source": [
    "image_info_df[\"label\"].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AW_A3EyHqQsY"
   },
   "outputs": [],
   "source": [
    "image_info_df.hist(column='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9uHkKRqqVnv"
   },
   "outputs": [],
   "source": [
    "image_info_df.plot.scatter(x='row', y='col', color='Blue', label='Row Col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FlM5KWjqZSd"
   },
   "outputs": [],
   "source": [
    "# Save results\n",
    "result_path = os.path.join(parms.ROOT_PATH, \"image-info.pkl\")\n",
    "image_info_df.to_pickle(result_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wbxDcF1yqcjY"
   },
   "outputs": [],
   "source": [
    "# open and read saved file\n",
    "image_info_df = pd.read_pickle(result_path)\n",
    "image_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goQF3VdzJc9z"
   },
   "source": [
    "### Final Thoughts.....\n",
    "\n",
    "This is a pattern notebook that should be copied and modified as needed for the specific training.\n",
    "\n",
    "Some of the things to pay close attention to are:\n",
    "\n",
    "- **class balance** is a big one!!  If unbalanced and not addressed will greatly impact training.\n",
    "\n",
    "- **image size distribution** overall and with respect to the classes.  This can influence your approach to sizing and augmentation.\n",
    "\n",
    "- **mean and std** have been helpful to understand when the images were more dark or light.  These values can also be used for feature-wise, zero center and stdnorm processing.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Orig_TFDataset_Analysis_V1.ipynb",
   "provenance": [
    {
     "file_id": "1uSN9c7HDnr2pXLzNManXX4eXFhH1c6Dy",
     "timestamp": 1582568730984
    },
    {
     "file_id": "1KpHc6u2_eLqzTYla8bEH-SIPLGWtZ_vW",
     "timestamp": 1582184535490
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
