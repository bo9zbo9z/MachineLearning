{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rl85J9Iqh4yQ"
   },
   "source": [
    "# TF.image Augmentations Playground\n",
    "\n",
    "This notebook allows you to experiment with different image augmentations.  It also shows how to use TF.py_function and a way to create a custom percentage wrapper.  It is NOT a step by step guide, but more of a playground.\n",
    "\n",
    "The dataset illustrated is cats/dogs.  In real usage you would copy this notebook into your subdirectory and then change global parms as needed.  You will see a copy of this notebook in some of my folders.\n",
    "\n",
    "To add/remove the augmentations, uncomment/comment the calls or add methods of your own.\n",
    "\n",
    "The augmentation methods are in TF.image and other ones I have used in the past.  (A good list of what you can do to an image)\n",
    "\n",
    "Here is the TF.image information\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/image\n",
    "\n",
    "These are also good research links:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.shift.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.ndimage.interpolation.rotate.html\n",
    "\n",
    "https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/py_function\n",
    "\n",
    "\n",
    "Other good reads about brightness, contrast and gamma:\n",
    "\n",
    "https://www.orpalis.com/blog/color-adjustments-brightness-contrast-and-gamma-2/\n",
    "\n",
    "https://www.cambridgeincolour.com/tutorials/gamma-correction.htm\n",
    "\n",
    "\n",
    "### Processing for using Google Drive and normal includes\n",
    "\n",
    "The notebook uses TensorFlow 2.x.  (Eager execution is enabled by default and we use the newer versions of tf.Data.)\n",
    "\n",
    "I use Notebooks with Colab and on my local workstation, so I need to separate some logic to make it easier to run in both locations.\n",
    "\n",
    "I was going to delete and just make Colab version, but that is not \"real world.\"  You usually have multiple environments and I'm showing you how I accommodate different environments, you might need something different...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjJySeIXh_md"
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "# Google Collab specific stuff....\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "!ls \"/content/drive/My Drive\"\n",
    "\n",
    "USING_COLLAB = True\n",
    "# Force to use 2.x version of Tensorflow\n",
    "%tensorflow_version 2.x\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6w1an-l5h4yT"
   },
   "outputs": [],
   "source": [
    "# Setup sys.path to find MachineLearning lib directory\n",
    "\n",
    "# Check if \"USING_COLLAB\" is defined, if yes, then we are using Colab, otherwise set to False\n",
    "try: USING_COLLAB\n",
    "except NameError: USING_COLLAB = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set path env var\n",
    "import sys\n",
    "if \"MachineLearning\" in sys.path[0]:\n",
    "    pass\n",
    "else:\n",
    "    print(sys.path)\n",
    "    if USING_COLLAB:\n",
    "        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    else:\n",
    "        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csTt9CUvh4yZ"
   },
   "outputs": [],
   "source": [
    "# Normal includes...\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys, random, warnings, time, copy, csv\n",
    "import numpy as np \n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# This allows the runtime to decide how best to optimize CPU/GPU usage\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from TrainingUtils import *\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aplx71Xjh4yg"
   },
   "source": [
    "## General Setup\n",
    "\n",
    "- Create a dictionary wrapped by a class for global values.  This is how I manage global vars in my notebooks.\n",
    "- Load a couple of images that will be used to create a very simple dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMdwqph-h4yd"
   },
   "outputs": [],
   "source": [
    "# Set root directory path to data\n",
    "if USING_COLLAB:\n",
    "    ROOT_PATH = \"/content/drive/My Drive/GitHub/MachineLearning/9-LibTest/Data\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "else:\n",
    "    ROOT_PATH = \"/Users/john/Documents/GitHub/MachineLearning/9-LibTest/Data\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "        \n",
    "# Establish global dictionary\n",
    "parms = GlobalParms(ROOT_PATH=ROOT_PATH,\n",
    "                    TRAIN_DIR=\"CatDogLabeledVerySmall\", \n",
    "                    NUM_CLASSES=2,\n",
    "                    IMAGE_ROWS=256,\n",
    "                    IMAGE_COLS=256,\n",
    "                    IMAGE_CHANNELS=3,\n",
    "                    BATCH_SIZE=4,\n",
    "                    IMAGE_EXT=\".jpg\")\n",
    "\n",
    "parms.print_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaK22hoX5rFr"
   },
   "outputs": [],
   "source": [
    "# Create path list and class list using cat/dog images\n",
    "# Change for your own dataset \n",
    "images_list, sub_directories = load_file_names_labeled_subdir_Util(parms.TRAIN_PATH, \n",
    "                                                                   parms.IMAGE_EXT)\n",
    "\n",
    "# Reduce the number of images from 12 to 2, makes it easier to show augmentation\n",
    "del images_list[1:7]\n",
    "del images_list[2:7]\n",
    "\n",
    "images_list_len = len(images_list)\n",
    "print(\"Number of images: \", images_list_len)\n",
    "\n",
    "# Set the class names.\n",
    "parms.set_class_names(sub_directories)\n",
    "print(\"Classes: {}  Labels: {}  {}\".format(parms.NUM_CLASSES, len(parms.CLASS_NAMES), parms.CLASS_NAMES) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDYxSZRP5rFu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the path, show the images that will be used\n",
    "for image_path in images_list[:2]:\n",
    "    print(image_path)\n",
    "    display.display(Image.open(str(image_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1R8KsrBkjgl"
   },
   "source": [
    "## Build an input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWyqw8Yw5rF7"
   },
   "outputs": [],
   "source": [
    "# Simple helper method to display batches of images with labels....        \n",
    "def show_batch(image_batch, label_batch, number_to_show=25, r=5, c=5, print_shape=False):\n",
    "    show_number = min(number_to_show, parms.BATCH_SIZE)\n",
    "\n",
    "    if show_number < 8: #if small number, then change row, col and figure size\n",
    "        if parms.IMAGE_COLS > 64 or parms.IMAGE_ROWS > 64:\n",
    "            plt.figure(figsize=(25,25)) \n",
    "        else:\n",
    "            plt.figure(figsize=(10,10))  \n",
    "        r = 4\n",
    "        c = 2 \n",
    "    else:\n",
    "        plt.figure(figsize=(10,10))  \n",
    "\n",
    "    if show_number == 1:\n",
    "        image_batch = np.expand_dims(image_batch, axis=0)\n",
    "        label_batch = np.expand_dims(label_batch, axis=0)\n",
    "\n",
    "    for n in range(show_number):\n",
    "        if print_shape:\n",
    "            print(\"Image shape: {}  Max: {}  Min: {}\".format(image_batch[n].shape, np.max(image_batch[n]), np.min(image_batch[n])))\n",
    "        ax = plt.subplot(r,c,n+1)\n",
    "        cmap=\"gray\"\n",
    "        if len(image_batch[n].shape) == 3:\n",
    "            if image_batch[n].shape[2] == 3:\n",
    "                cmap=\"viridis\"\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]), cmap=plt.get_cmap(cmap))\n",
    "        plt.title(parms.CLASS_NAMES[np.argmax(label_batch[n])])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Za1IWHt5rF1"
   },
   "outputs": [],
   "source": [
    "# Return a label based on the path of the image\n",
    "def get_label(file_path: tf.Tensor) -> tf.Tensor:\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == parms.CLASS_NAMES\n",
    "\n",
    "# Decode the image, convert to float, normalize by 255 and resize\n",
    "def decode_img(image: tf.Tensor) -> tf.Tensor:\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=parms.IMAGE_CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    image = tf.image.convert_image_dtype(image, parms.IMAGE_DTYPE)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(image, [parms.IMAGE_ROWS, parms.IMAGE_COLS])\n",
    "\n",
    "# method mapped to load, resize and aply any augmentations\n",
    "def process_path(file_path: tf.Tensor) -> tf.Tensor:\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = decode_img(image)\n",
    "\n",
    "    # add any augmentations\n",
    "    image = image_aug(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw9K3tNx1VyT"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Various image rescaling methods\n",
    "# These are optional, I included them because sometimes you need to rescale an image\n",
    "\n",
    "def image_rescale_0_255(image: tf.Tensor) -> tf.Tensor:\n",
    "    # takes ANY scale and converts to 0..255\n",
    "    image = tf.constant(255, dtype=tf.float32)*((image - tf.math.reduce_min(image))/(tf.math.reduce_max(image) - tf.math.reduce_min(image)))\n",
    "    return image\n",
    "\n",
    "def image_rescale_0_1(image: tf.Tensor) -> tf.Tensor:\n",
    "    # takes ANY scale and converts to 0..1\n",
    "    image = (image - tf.math.reduce_min(image))/(tf.math.reduce_max(image) - tf.math.reduce_min(image))\n",
    "    return image\n",
    "\n",
    "def image_rescale_1_neg_1(image: tf.Tensor) -> tf.Tensor:\n",
    "    # takes Any scale and converts to 1..-1\n",
    "    image = (tf.constant(2., dtype=tf.float32)*(image - tf.math.reduce_min(image))/(tf.math.reduce_max(image) - tf.math.reduce_min(image)))-1\n",
    "    return image\n",
    "\n",
    "def image_rescale_0_1_alt(image: tf.Tensor) -> tf.Tensor:\n",
    "    # takes 0..255 and converts to 0..1\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    return image\n",
    "\n",
    "def image_rescale_1_neg_1_alt(image: tf.Tensor) -> tf.Tensor:\n",
    "    # takes 0..1 and converts to 1..-1\n",
    "    image = tf.subtract(image, 0.5)\n",
    "    image = tf.multiply(image, 2.0)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcvmHfSJ5GF7"
   },
   "outputs": [],
   "source": [
    "# Simple test for the rescaling methods\n",
    "t = tf.Variable([0, .5, 1])\n",
    "print(\"0 to 255: \", image_rescale_0_255(t))\n",
    "                           \n",
    "t = tf.Variable([0, 127.5, 255])\n",
    "print(\"0 to 1: \", image_rescale_0_1(t))\n",
    "                                                                                  \n",
    "t = tf.Variable([0, 127.5, 255])\n",
    "print(\"1 to -1: \", image_rescale_1_neg_1(t))\n",
    "\n",
    "t = tf.Variable([0, 127.5, 255])\n",
    "print(\"0 to 1: \", image_rescale_0_1_alt(t))\n",
    "\n",
    "t = tf.Variable([0, .5, 1])\n",
    "print(\"1 to -1: \", image_rescale_1_neg_1_alt(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJ2b_A53jIVP"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These methods are from TF.image.  I mainly have the the random ones, but there \n",
    "are corresponding non-random ones that will always apply augmentation.  \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "import scipy.ndimage\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "def image_blur(image):\n",
    "    \"\"\"\n",
    "    Takes an image and applies Gaussian Blur using skimage filters.\n",
    "    Applies random +/- sigma_max to the image\n",
    "    \"\"\"\n",
    "    sigma_max = 3.0\n",
    "    sigma = tf.random.uniform(0., sigma_max)  # change range or remove if want a fixed sigma value\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.int32)\n",
    "    image = gaussian(image, sigma=sigma, multichannel=True)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image\n",
    "\n",
    "def image_random_shift(image,\n",
    "                       shift_x=60, # number of pixels, should be > 0 and less than width\n",
    "                       shift_y=60 # number of pixels, should be > 0 and less than height\n",
    "                       ):\n",
    "    \"\"\"\n",
    "    Takes an image and randomly shifts it up/down and/or right/left by number of pixels\n",
    "    Modify this if you want different behavior when shifting, this was most common for my usage.\n",
    "    Uses ndimage.shift for pixel movement\n",
    "    \"\"\"\n",
    "\n",
    "    shift_x = int(tf.random.uniform(-shift_x, shift_x))  # could also just hard code pos or neg values\n",
    "    shift_y = int(tf.random.uniform(-shift_y, shift_y))  # could also just hard code pos or neg values\n",
    "\n",
    "    if shift_x > 0 and shift_y > 0:\n",
    "        # alternate between x and y, remove if you want both applied\n",
    "        if bool(np.random.choice([0, 1], p=[0.5, 0.5])):  # change p values as needed\n",
    "            shift_x = 0\n",
    "        else:\n",
    "            shift_y = 0\n",
    "\n",
    "    shift = (shift_x, shift_y, 0)\n",
    "    image = scipy.ndimage.shift(image, shift, mode='constant', cval=0.0) #cval is fill value.  See scipy doc\n",
    "    return image\n",
    "    \n",
    "    \n",
    "def image_random_rotate(image, max_angle=45):\n",
    "    \"\"\"\n",
    "    Takes an image and randomly rotates it between +/- max_angle\n",
    "    Uses ndimage for rotation\n",
    "    \"\"\"\n",
    "    \n",
    "    angle = tf.random.uniform(-max_angle, max_angle)\n",
    "    image = scipy.ndimage.interpolation.rotate(image,\n",
    "                                                angle,\n",
    "                                                reshape=False)\n",
    "    return image\n",
    "\n",
    "def image_aug(image: tf.Tensor) -> tf.Tensor:\n",
    "    # This is called from the process_path to augment images\n",
    "\n",
    "    #print(type(image)) # uncomment for testing, should start and end with a tensor....\n",
    "\n",
    "    #######################################################\n",
    "    # rotate using tf.py_function\n",
    "    #######################################################\n",
    "    #if tf.random.uniform(()) > 0.5:\n",
    "    #   im_shape = image.shape\n",
    "    #   [image,] = tf.py_function(image_random_rotate, [image], [tf.float32])  #parms must be tensors\n",
    "    #   image.set_shape(im_shape)\n",
    "    #######################################################\n",
    "        \n",
    "    #######################################################\n",
    "    # shift using tf.py_function\n",
    "    #######################################################\n",
    "    #if tf.random.uniform(()) > 0.5:\n",
    "    #   im_shape = image.shape\n",
    "    #   [image,] = tf.py_function(image_random_shift, [image], [tf.float32])  #parms must be tensors\n",
    "    #   image.set_shape(im_shape)\n",
    "    #######################################################\n",
    "\n",
    "    #######################################################\n",
    "    # Blur using tf.py_function\n",
    "    #######################################################\n",
    "    #if tf.random.uniform(()) > 0.5:\n",
    "    #   im_shape = image.shape\n",
    "    #   [image,] = tf.py_function(image_blur, [image], [tf.float32])  #parms must be tensors\n",
    "    #   image.set_shape(im_shape)\n",
    "    #######################################################\n",
    "\n",
    "    #######################################################\n",
    "    # These are native tf.image methods\n",
    "    #######################################################\n",
    "    #image = tf.image.random_flip_left_right(image)\n",
    "    #image = tf.image.flip_up_down(image)\n",
    "    #image = tf.image.random_flip_up_down(image)\n",
    "    #image = tf.image.random_hue(image, 0.08) #  -delta - +delta\n",
    "    #image = tf.image.random_saturation(image, 0.6, 1.6)  #lower, upper\n",
    "    #image = tf.image.random_brightness(image, 0.05) # -delta - +delta\n",
    "    #image = tf.image.adjust_contrast(image, 1.4)\n",
    "    #image = tf.image.random_contrast(image, 0.7, 1.5) # lower, upper\n",
    "    #image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=3, dtype=tf.int32)) #0-4, 0/360, 90/180/270\n",
    "    #image = tf.image.random_jpeg_quality(image, 25, 100) #min 0-100, min<max, max 0-100\n",
    "    #######################################################\n",
    "\n",
    "    #######################################################\n",
    "    # random zoom - random crop + resize which will zoom the image\n",
    "    #######################################################\n",
    "    #w = parms.IMAGE_COLS\n",
    "    #h = parms.IMAGE_ROWS\n",
    "    #p = 0.90\n",
    "    #image = tf.image.resize(tf.image.random_crop(image, (int(h*p), int(w*p), 3)), (h, w))\n",
    "    #######################################################\n",
    "\n",
    "    #######################################################\n",
    "    # Gamma \n",
    "    #######################################################\n",
    "    #gamma = tf.math.reduce_mean(image) + 0.5\n",
    "    #image = tf.image.adjust_gamma(image, gamma=gamma)\n",
    "    #######################################################\n",
    "\n",
    "    #######################################################\n",
    "    # roll \n",
    "    #######################################################\n",
    "    #shift = 10 # pixels to roll, can be pos/neg\n",
    "    #axis = 1  # 0 or 1, u/d or r/l\n",
    "    #image = tf.roll(image, shift, axis)\n",
    "    #######################################################\n",
    "\n",
    "    #######################################################\n",
    "    # These next examples two show how to create a custom random value\n",
    "    # Helps if you want to over-ride the normal 50/50 and have different augmentations\n",
    "    # applied.  Uses tensors to do the random behavior\n",
    "    #######################################################\n",
    "    #\n",
    "    # This uses flip_up_down\n",
    "    #sample = tf.random.categorical(tf.math.log([[0., 1.]]), 1)   # change values as needed [0., 1.] is always True\n",
    "    #image = tf.cond(sample == 1, lambda: tf.image.flip_up_down(image), lambda: image)\n",
    "    #\n",
    "    # This uses two methods, one for True, one for False (adjust_contrast and flip_up_down)\n",
    "    sample = tf.random.categorical(tf.math.log([[0.5, 0.5]]), 1)   # change values as needed [0., 1.] is always True\n",
    "    image = tf.cond(sample == 1, lambda: tf.image.adjust_contrast(image, 0.1), lambda: tf.image.flip_up_down(image))\n",
    "    #######################################################\n",
    "\n",
    "    ######################################################\n",
    "    # Rescaling tests\n",
    "    #######################################################\n",
    "    #image = image_rescale_0_255(image)\n",
    "    #image = image_rescale_0_1(image)\n",
    "    ######################################################\n",
    "\n",
    "    #print(type(image)) # uncomment for testing, should start and end with a tensor....\n",
    "\n",
    "    #image = tf.clip_by_value(image, 0., 1.)  # after majority of augmentations, clip back to 0, 1 before returning\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wJ5iS1Tu3Jq"
   },
   "source": [
    "### Create dataset and normal mappings\n",
    "\n",
    "Pipeline Flow:\n",
    "\n",
    "create dataset -> map \"process_path\" -> repeat forever -> batch\n",
    "\n",
    "This will illustrate whatever methods have been uncommented in the image_aug method.\n",
    "\n",
    "These 3 methods must be rerun if you change which methods are used.  That is mainly due to the mapping.  And, it is best to start with a clean dataset after any augmentation changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-LXAs3e5rFx"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from list of images\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(np.array(images_list))\n",
    "\n",
    "# Verify image paths were loaded and save one path for later in \"some_image\"\n",
    "for f in full_dataset.take(2):\n",
    "    some_image = f.numpy().decode(\"utf-8\")\n",
    "    print(f.numpy())\n",
    "    \n",
    "print(\"Some Image: \", some_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TZM_MFp5rGA"
   },
   "outputs": [],
   "source": [
    "# map training images to processing, includes any augmentation\n",
    "full_dataset = full_dataset.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, label in full_dataset.take(1):\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    print(\"Label: \", label.numpy())\n",
    "\n",
    "# Repeat forever\n",
    "full_dataset = full_dataset.repeat()\n",
    "\n",
    "# set the batch size\n",
    "full_dataset = full_dataset.batch(parms.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHmOZtlv5rGG"
   },
   "outputs": [],
   "source": [
    "# Show the images, execute this cell multiple times to see the images\n",
    "# Execute at least 4 times if random is applied\n",
    "\n",
    "image_batch, label_batch = next(iter(full_dataset))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goQF3VdzJc9z"
   },
   "source": [
    "### Final Thoughts.....\n",
    "\n",
    "Play around with uncommenting different methods and using different percentages.  I've found that by separating this type of research work from your training notebook helps keep clutter at a minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cfmxVxkamDl"
   },
   "outputs": [],
   "source": [
    "############# WORKING\n",
    "\n",
    "import numpy as np\n",
    "def add_s_p(X_img):\n",
    "    # Need to produce a copy as to not modify the original image\n",
    "    #X_imgs_copy = X_imgs.copy()\n",
    "    #row, col, _ = X_imgs_copy[0].shape\n",
    "    row, col, _ = X_img.shape\n",
    "    #salt_vs_pepper = 0.2\n",
    "    salt_vs_pepper = 0.2\n",
    "    amount = 0.004\n",
    "    num_salt = np.ceil(amount * X_img.size * salt_vs_pepper)\n",
    "    num_pepper = np.ceil(amount * X_img.size * (1.0 - salt_vs_pepper))\n",
    "    print(num_salt, num_pepper)\n",
    "    # Add Salt noise\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt)) for i in X_img.shape]\n",
    "    print(\"-255\", coords)\n",
    "    #X_img[coords[0], coords[1], :] = 1\n",
    "    X_img[coords[0], coords[1], :] = -255\n",
    "\n",
    "    # Add Pepper noise\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in X_img.shape]\n",
    "    print(\"255\", coords)\n",
    "\n",
    "    #X_img[coords[0], coords[1], :] = 0\n",
    "    X_img[coords[0], coords[1], :] = 255\n",
    "        \n",
    "    return X_img\n",
    "\n",
    "    ##########\n",
    "\n",
    "def add_salt_pepper_noise(X_imgs):\n",
    "    # Need to produce a copy as to not modify the original image\n",
    "    X_imgs_copy = X_imgs.copy()\n",
    "    row, col, _ = X_imgs_copy[0].shape\n",
    "    salt_vs_pepper = 0.2\n",
    "    amount = 0.004\n",
    "    num_salt = np.ceil(amount * X_imgs_copy[0].size * salt_vs_pepper)\n",
    "    num_pepper = np.ceil(amount * X_imgs_copy[0].size * (1.0 - salt_vs_pepper))\n",
    "    \n",
    "    for X_img in X_imgs_copy:\n",
    "        # Add Salt noise\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in X_img.shape]\n",
    "        X_img[coords[0], coords[1], :] = 1\n",
    "\n",
    "        # Add Pepper noise\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in X_img.shape]\n",
    "        X_img[coords[0], coords[1], :] = 0\n",
    "    return X_imgs_copy\n",
    "    \n",
    " ########## \n",
    "def masking_noise(data, sess, v):\n",
    "    \"\"\"Apply masking noise to data in X.\n",
    "    In other words a fraction v of elements of X\n",
    "    (chosen at random) is forced to zero.\n",
    "    :param data: array_like, Input data\n",
    "    :param sess: TensorFlow session\n",
    "    :param v: fraction of elements to distort, float\n",
    "    :return: transformed data\n",
    "    \"\"\"\n",
    "    data_noise = data.copy()\n",
    "    rand = tf.random_uniform(data.shape)\n",
    "    data_noise[sess.run(tf.nn.relu(tf.sign(v - rand))).astype(np.bool)] = 0\n",
    "\n",
    "    return data_noise\n",
    "\n",
    "#######\n",
    "def salt_and_pepper_noise(X, v):\n",
    "    \"\"\"Apply salt and pepper noise to data in X.\n",
    "    In other words a fraction v of elements of X\n",
    "    (chosen at random) is set to its maximum or minimum value according to a\n",
    "    fair coin flip.\n",
    "    If minimum or maximum are not given, the min (max) value in X is taken.\n",
    "    :param X: array_like, Input data\n",
    "    :param v: int, fraction of elements to distort\n",
    "    :return: transformed data\n",
    "    \"\"\"\n",
    "    X_noise = X.copy()\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    mn = X.min()\n",
    "    mx = X.max()\n",
    "\n",
    "    for i, sample in enumerate(X):\n",
    "        mask = np.random.randint(0, n_features, v)\n",
    "\n",
    "        for m in mask:\n",
    "\n",
    "            if np.random.random() < 0.5:\n",
    "                X_noise[i][m] = mn\n",
    "            else:\n",
    "                X_noise[i][m] = mx\n",
    "\n",
    "    return X_noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFLkZ14xR8qX"
   },
   "outputs": [],
   "source": [
    "# EXPERIMENTIAL\n",
    "\n",
    "# https://medium.com/@dimkak_89085/thanks-for-your-article-it-is-quite-helpful-ce665dc31705\n",
    "\n",
    "def create_random_sparse_mask(points_num, batch_dim, im_dims_list, all_dims):\n",
    "    coords = [tf.random.uniform([batch_dim, points_num], minval=0, maxval=i, dtype=tf.int32) for i in im_dims_list]\n",
    "    batch_indeces = tf.range(batch_dim)\n",
    "    batch_indeces = tf.tile(batch_indeces, [points_num])\n",
    "    coords = tf.stack(coords, axis=-1)\n",
    "    coords = tf.reshape(coords, [-1, 3])\n",
    "    coords = tf.concat([tf.expand_dims(batch_indeces, -1), coords], axis=-1)\n",
    "    values = tf.ones([batch_dim*points_num], dtype=tf.float32)\n",
    "    sparse_mask = tf.scatter_nd(coords, values, all_dims)\n",
    "    return sparse_mask\n",
    "\n",
    "def add_salt_pepper_noise(image_batch, amount = 0.004, salt_vs_pepper = 0.2):\n",
    "    image_batch = tf.expand_dims(image_batch, axis=0)\n",
    "\n",
    "    tensor_dims = tf.shape(image_batch)\n",
    "    b_dim = tensor_dims[0]\n",
    "    im_dims = tensor_dims[1:]\n",
    "    pixel_num = tf.reduce_prod(im_dims)\n",
    "    num_salt = tf.cast(tf.math.ceil(amount * tf.cast(pixel_num, tf.float32) * salt_vs_pepper), tf.int32)\n",
    "    num_pepper = tf.cast(tf.math.ceil(amount * tf.cast(pixel_num, tf.float32) * (1.0 - salt_vs_pepper)), tf.int32)\n",
    "    im_dims = tf.split(im_dims, num_or_size_splits=im_dims.shape[0], axis=0)\n",
    "    #im_dims = tf.split(im_dims, num_or_size_splits=im_dims.shape[0].value, axis=0)\n",
    "    im_dims = [tf.squeeze(i) for i in im_dims]\n",
    "    # Add salt noise\n",
    "    sparsePixels = create_random_sparse_mask(num_salt, b_dim, im_dims, tensor_dims)\n",
    "    neg_sparsePixels = 1 - sparsePixels\n",
    "    image_batch = image_batch*neg_sparsePixels + sparsePixels\n",
    "    # Add pepper noise\n",
    "    sparsePixels = create_random_sparse_mask(num_pepper, b_dim, im_dims, tensor_dims)\n",
    "    neg_sparsePixels = 1 - sparsePixels\n",
    "    image_batch = image_batch*neg_sparsePixels\n",
    "\n",
    "    return tf.squeeze(image_batch, axis=0)\n",
    "\n",
    "def add_gaussian_noise(image_batch, stddev = 0.1):\n",
    "    noise = tf.random.truncated_normal(tf.shape(image_batch), mean=0.5, stddev=stddev, dtype=tf.float32)\n",
    "    noise = tf.clip_by_value(noise, 0.0, 1.0)\n",
    "    image_batch = 0.75*image_batch + 0.25*noise\n",
    "    return image_batch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Orig_TFImage_Augmentations_V1.ipynb",
   "provenance": [
    {
     "file_id": "1uSN9c7HDnr2pXLzNManXX4eXFhH1c6Dy",
     "timestamp": 1582568730984
    },
    {
     "file_id": "1KpHc6u2_eLqzTYla8bEH-SIPLGWtZ_vW",
     "timestamp": 1582184535490
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
