{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WeR_ksRk8jkH"
   },
   "source": [
    "# Google Colaboratory – Storing and acquiring data for training\n",
    "\n",
    "This notebook will cover how to obtain data to use in Colab notebooks.  These next topics are like “which comes first, the chicken or the egg?”   Do you find data and then worry about storage, or do you figure out storage, then worry about the data.  Truth is both of these play together and need to be considered jointly.  I use a combination of using Google Drive for permanent storage along with using the local Colab VM for training (images, Panda, csv, numpy files, etc).  Notebooks, models and config items are stored in Drive, training data stored on VM for local usage.  This does require some extra time before you can start your training, so you can compare which one is best for your situation.  I've found that taking 5 or so minutes to copy data to the VM is well worth the time you save when training.  \n",
    "\n",
    "My personal Kaggle guideline is that if the competition data size is below 10G, then I use colab, otherwise use Kaggle.\n",
    "\n",
    "**Storage**\n",
    "\n",
    "Google has three main places you can store your information and each has pros/cons.\n",
    "\n",
    "| Characteristics  | Colab VM | Drive | Cloud Storage |\n",
    "| :----: | :----: | :----: | :----: |\n",
    "| Cost | none | 15G free | Varies |\n",
    "| Retrieval Speed | fastest | slowest | fast |\n",
    "| Permanent | no | yes | yes |\n",
    "| Created | when you start Colab | when you sign-up for Google | when purchased |\n",
    "\n",
    "Link that covers the differences between Drive and Cloud Storage:\n",
    "\n",
    "http://www.differencebetween.net/technology/difference-between-google-cloud-and-google-drive/\n",
    "\n",
    "\n",
    "**Acquiring Data**\n",
    "\n",
    "There are two main ways you acquire data for training:  public domain (Google, Kaggle, Microsoft, Facebook, etc) or you can create your own.  This notebook will focus on using public Google and Kaggle data.  When I say “Google data” I'm referencing the link below.  But the data included comes from many sources, not just Google.  It is not all Google data, but those data sets in which Google has TensorFlow examples.  Also, there is data set overlap between all of the companies.  For instance, the “Dog & Cats” data can be found in multiple locations.\n",
    "\n",
    "https://www.tensorflow.org/resources/models-datasets\n",
    "\n",
    "\n",
    "**Basic Linux commands**\n",
    "\n",
    "It is a good idea to have a basic understanding of some simple Linux commands.  This link is a good starting point and can explain any command you find in this notebook.\n",
    "\n",
    "https://www.tjhsst.edu/~dhyatt/superap/unixcmd.html\n",
    "\n",
    "**General Colab Information**\n",
    "\n",
    "If you are new to Colab, this is a good starter.\n",
    "\n",
    "https://medium.com/dair-ai/primer-for-learning-google-colab-bb4cabca5dd6\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mO-nfKB90kf"
   },
   "source": [
    "### Explore the Colab Local VM drive\n",
    "\n",
    "When you launched this notebook, a VM was started with some pre-loaded local storage.  As you can see there were some sample files loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xraafFqQQnu0"
   },
   "outputs": [],
   "source": [
    "# List the contents on your local VM drive, there is a sample_data folder\n",
    "# If this is the first time you have executed code, it might take a few seconds to initialize and start the VM\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8F2RtK89Sly"
   },
   "outputs": [],
   "source": [
    "# List the contents of the sample_data folder\n",
    "! ls sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sqf21Qz9W1B"
   },
   "outputs": [],
   "source": [
    "# Show the contents of sample_data/README.md\n",
    "!cat sample_data/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BWKhP20b_FKb"
   },
   "source": [
    "### Obtaining Kaggle data sets\n",
    "\n",
    "To use Kaggle data sets, you must have registered in Kaggle and accepted the data agreement.  You register for a Kaggle account once, but you have to accept the data agreement for each data store (or contest) you are interested in.  You then can create a personal key and load the data into your environment.  I'm showing using Colab, but these steps should work with about any environment.\n",
    "\n",
    "Link to detailed steps (very good):\n",
    "\n",
    "https://stackoverflow.com/questions/49310470/using-kaggle-datasets-in-google-colab\n",
    "\n",
    "Here is a high-level summary:\n",
    "1. In Kaggle: Register for a Kaggle account (this is free)\n",
    "2. In Kaggle: From you Account tab, create & download your kaggle.json token\n",
    "3. in Kaggle: For any data you want to use, agree to usage (basically join the contest)\n",
    "4. Start Colab notebook  (assume you have already have a free Google account)\n",
    "5. In Colab: Upload your kaggle.json file \n",
    "6. In Colab: Install Kaggle libs and modify access rights\n",
    "7. In Colab: List or upload Kaggle files\n",
    "\n",
    "Here are some other research links:\n",
    "\n",
    "https://www.kaggle.com/suraj2596/download-datasets-to-your-google-drive\n",
    "https://github.com/Kaggle/kaggle-api/issues/160\n",
    "https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3102,
     "status": "ok",
     "timestamp": 1586993476380,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "SOHkl2uVVCHO",
    "outputId": "18d759aa-cbc4-4c2d-c29b-07c365f038c6"
   },
   "outputs": [],
   "source": [
    "# To start, install kaggle libs, make sure you are using the latest version...\n",
    "#!pip install -q kaggle\n",
    "\n",
    "# WORK AROUND TO GET NEW VERSION: https://stackoverflow.com/questions/58643979/google-colaboratory-use-kaggle-server-version-1-5-6-client-version-1-5-4-fai\n",
    "!pip install --upgrade --force-reinstall --no-deps kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZprfedjsUz35"
   },
   "outputs": [],
   "source": [
    "# Upload your \"kaggle.json\" file that you created from your Kaggle Account tab\n",
    "# If you downloaded it, it would be in your \"Downloads\" directory\n",
    "\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyzBblw6Buv7"
   },
   "outputs": [],
   "source": [
    "# On your VM, create kaggle directory and modify access rights\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9etdhqHzVCd2"
   },
   "outputs": [],
   "source": [
    "# To verify everythong worked, execute commands to list data sets and competitions\n",
    "\n",
    "!kaggle datasets list\n",
    "!kaggle competitions list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VzMgntiCN3o"
   },
   "source": [
    "### Copy Kaggle files\n",
    "\n",
    "**The next few cells are examples, do not run unles you want the data**\n",
    "\n",
    "\n",
    "Make sure you update the folders on c and p correctly\n",
    "\n",
    " **-c** is the competition and **-p** is where it will be placed\n",
    "\n",
    " To copy to Google Drive:\n",
    "\n",
    "!kaggle competitions download -c titanic  -p /content/drive/My\\ Drive/kaggle/titanic\n",
    "\n",
    "To copy to local VM:\n",
    "\n",
    "!kaggle competitions download -c titanic  -p kaggle/titanic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyAMXx19C7j4"
   },
   "outputs": [],
   "source": [
    "# Using the Titantic data set as an example and copy to local VM (It is small, so easy to start with...)\n",
    "# I put Kaggle files in a kaggle subdirectory, but you can put them as needed\n",
    "\n",
    "!kaggle competitions download -c titanic -p kaggle/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ejt_u7mxdZb"
   },
   "outputs": [],
   "source": [
    "# Show the downloaded files in kaggle directory\n",
    "!ls kaggle/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkTJa8Pfarn"
   },
   "outputs": [],
   "source": [
    "# Another example for dogs-vs-cats but going to Google Drive\n",
    "\n",
    "!kaggle competitions download -c dogs-vs-cats -p /content/drive/My\\ Drive/kaggle/dogscats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sf9A_nnVG1ko"
   },
   "outputs": [],
   "source": [
    "# If the data set was not listed, you can always use the API link in the Data section\n",
    "# I found this very helpful!\n",
    "\n",
    "# Go to the competition, select \"Data\" tab, then select the \"API\"\n",
    "# Te API is below the description and just above the list of data.\n",
    "# This will copy the API link to your clip board, then paste it in a Notebook cell\n",
    "\n",
    "# This is from the Airbus Ship Detection Challenge: https://www.kaggle.com/c/airbus-ship-detection/data\n",
    "\n",
    "!kaggle competitions download -c airbus-ship-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKrBbB6PJtVt"
   },
   "outputs": [],
   "source": [
    "# If you want to unzip the files, example is for Google Drive\n",
    "\n",
    "# Can be modified for local VM\n",
    "\n",
    "# The u stands for update and the q stands for quiet - the latter is a good idea \n",
    "# because massive output can sometimes cause your Google Colab notebook to crash\n",
    "\n",
    "#!unzip -uq \"drive/My Drive/PATH_TO_ZIP\" -d \"drive/My Drive/PATH_TO_OUTPUT\"\n",
    "\n",
    "\n",
    "#!unzip -uq \"/content/drive/My Drive/kaggle/dogscats/train.zip\" -d \"/content/drive/My Drive/kaggle/dogscats/\"\n",
    "\n",
    "print(\"Done unzipping....\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2RbAlMCu98l7"
   },
   "source": [
    "### Copy file(s) from Google Drive to Local VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REVtD54KuiUW"
   },
   "outputs": [],
   "source": [
    "# To mount Google Drive, run cell, click on link, select account and copy/paste your access token\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# if successful, you will see \"Mounted at /content/drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyXq7dQA-PA4"
   },
   "outputs": [],
   "source": [
    "# List contents to verify it is mounted correctly\n",
    "!ls \"/content/drive/My Drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TB-ZeeB4AJos"
   },
   "outputs": [],
   "source": [
    "# verify name of file(s) to copy, change <your file> to actual file\n",
    "!ls \"/content/drive/My Drive/<your file>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qE7af4z_YeW"
   },
   "outputs": [],
   "source": [
    "# To copy files from Google Drive to the VM local filesystem\n",
    "\n",
    "# Create any directories as needed using mkdir\n",
    "\n",
    "# Actual copy, replace the name and location with your files\n",
    "!cp -r \"/content/drive/My Drive/Colab Notebooks/<your file>\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUrRWWWGAsvS"
   },
   "outputs": [],
   "source": [
    "# Should see your files(s) or directories on local VM\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1TJ3BJ7Lk6s"
   },
   "source": [
    "### Obtaining Google data sets via TensorFlow\n",
    "\n",
    "The next section will illustrate how to use data sets provided by TensorFlow database.  The steps are:\n",
    "1. Find the data set you are interested in\n",
    "2. Load the data along with the information (I've found showing the “info” is helpful)\n",
    "3. Process the data based on the description\n",
    "\n",
    "Link to the data set home page:\n",
    "\n",
    "https://www.tensorflow.org/datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pM2bFPHIMU0-"
   },
   "outputs": [],
   "source": [
    "# Standard includes so everything works.....\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Force TensorFlow 2.x\n",
    "%tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)  # double check on tensorflow version\n",
    "\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jgGGkg0My4h"
   },
   "outputs": [],
   "source": [
    "# Simple helper method to display images....        \n",
    "def show_batch(image_batch, label_batch, number_to_show=25, r=5, c=5):\n",
    "    plt.figure(figsize=(10,10))  \n",
    "\n",
    "    for n in range(number_to_show):\n",
    "        ax = plt.subplot(r,c,n+1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]))\n",
    "        plt.title(str(label_batch[n].numpy()))\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qImZdNE6NqqM"
   },
   "outputs": [],
   "source": [
    "# See available datasets or can look on the site\n",
    "print(tfds.list_builders())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwo0IioCNtDh"
   },
   "outputs": [],
   "source": [
    "# As an example, construct a tf.data.Dataset using mnist\n",
    "# Add \"with_info\" to get all of the dataset information\n",
    "\n",
    "dataset, info = tfds.load(name=\"mnist\", split=\"train\", with_info=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ig26QJGvUpoh"
   },
   "outputs": [],
   "source": [
    "#Show the files that were downloaded, this can be different based on what was downloaded...\n",
    "!ls /root/tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kuoPXNZVOPdL"
   },
   "outputs": [],
   "source": [
    "# Show the information about the data set\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kbSuY1w2SRtA"
   },
   "outputs": [],
   "source": [
    "# Build your input pipeline with batch size 32\n",
    "\n",
    "# tf.data.experimental.AUTOTUNE just means that Google will decide how best to optimize during runtime\n",
    "\n",
    "dataset = dataset.shuffle(1024).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for features in dataset.take(1):\n",
    "    image_batch, label_batch = features[\"image\"], features[\"label\"]\n",
    "\n",
    "# Verify it worked\n",
    "print(image_batch.shape, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IVMFgn5NdbC"
   },
   "outputs": [],
   "source": [
    "# Show first 25 images of the batch\n",
    "show_batch(image_batch, label_batch)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StoringAndAcquiringDataForTraining_V1.ipynb",
   "provenance": [
    {
     "file_id": "1RI_kEia8Gg3w9RmapNIbAUX6FmWRSbAV",
     "timestamp": 1582375733483
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
