{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rl85J9Iqh4yQ"
   },
   "source": [
    "# Map & Cache functionality and Eager vs Graph execution\n",
    "\n",
    "This is not a full coverage of tf.dataset functionality or an in depth coverage of Eager vs Graph processing.  I combined these because when you are using the “map” functionality, you are in Graph mode, so it is beneficial to understand some of the differences as you apply the concepts.\n",
    "\n",
    "What led me to create this was that I spent several weeks thinking I had a code problem when my actual problem was that I did not understand how “map”, “Cache” and “Graph/Eager” worked together.  \n",
    "\n",
    "tf.datasets are new and at first I wondered why I should migrate my code to use them.  One word – speed.  There is a great notebook that shows Keras Generators compared with datasets.  You can load & run it yourself, bottom line is that having the ability to cache, prefetch data and apply tensors helps training run faster and simplifies the data pipeline.  Here is a link to a couple of notebooks, the first one uses the Flowers dataset to show speed differences, the second is more detailed covering parallel concepts:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "https://www.tensorflow.org/guide/data_performance\n",
    "\n",
    "Eager execution:\n",
    "\n",
    "If Eager execution is new to you, this is a simple notebook that covers the basics.\n",
    "\n",
    "https://colab.research.google.com/github/zaidalyafeai/Notebooks/blob/master/Eager_Execution_Enabled.ipynb\n",
    "\n",
    "\n",
    "### Processing for using Google Drive and normal includes\n",
    "\n",
    "The notebook uses TensorFlow 2.x.  (Eager execution is enabled by default and we use the newer versions of tf.Data.)\n",
    "\n",
    "I use Notebooks with Colab and on my local workstation, so I need to separate some logic to make it easier to run in both locations.\n",
    "\n",
    "I was going to delete and just make Colab version, but that is not \"real world.\"  You usually have multiple environments and I'm showing you how I accommodate different environments, you might need something different..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjJySeIXh_md"
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "# Google Collab specific stuff....\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "!ls \"/content/drive/My Drive\"\n",
    "\n",
    "USING_COLLAB = True\n",
    "# Force to use 2.x version of Tensorflow\n",
    "%tensorflow_version 2.x\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YjrBdIVDqZR6"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6w1an-l5h4yT"
   },
   "outputs": [],
   "source": [
    "# Setup sys.path to find MachineLearning lib directory\n",
    "\n",
    "# Check if \"USING_COLLAB\" is defined, if yes, then we are using Colab, otherwise set to False\n",
    "try: USING_COLLAB\n",
    "except NameError: USING_COLLAB = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set path env var\n",
    "import sys\n",
    "if \"MachineLearning\" in sys.path[0]:\n",
    "    pass\n",
    "else:\n",
    "    print(sys.path)\n",
    "    if USING_COLLAB:\n",
    "        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib') ##### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    else:\n",
    "        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ##### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csTt9CUvh4yZ"
   },
   "outputs": [],
   "source": [
    "# Normal includes...\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys, random, warnings, time, copy, csv, gc\n",
    "import numpy as np \n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook, tnrange, tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# This allows the runtime to decide how best to optimize CPU/GPU usage\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from TrainingUtils import *\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aplx71Xjh4yg"
   },
   "source": [
    "## General Setup\n",
    "\n",
    "- Create a dictionary wrapped by a class for global values.  This is how I manage global vars in my notebooks.\n",
    "- Load a couple of images that will be used to create a very simple dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMdwqph-h4yd"
   },
   "outputs": [],
   "source": [
    "# Set root directory path to data\n",
    "if USING_COLLAB:\n",
    "    ROOT_PATH = \"/content/drive/My Drive/GitHub/MachineLearning/9-LibTest/Data\"  ##### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "else:\n",
    "    ROOT_PATH = \"/Users/john/Documents/GitHub/MachineLearning/9-LibTest/Data\"  ##### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "        \n",
    "# Establish global dictionary\n",
    "parms = GlobalParms(ROOT_PATH=ROOT_PATH,\n",
    "                    TRAIN_DIR=\"CatDogLabeledVerySmall\", \n",
    "                    NUM_CLASSES=2,\n",
    "                    IMAGE_ROWS=256,\n",
    "                    IMAGE_COLS=256,\n",
    "                    IMAGE_CHANNELS=3,\n",
    "                    BATCH_SIZE=4,\n",
    "                    IMAGE_EXT=\".jpg\")\n",
    "\n",
    "parms.print_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaK22hoX5rFr"
   },
   "outputs": [],
   "source": [
    "# Create path list and class list    \n",
    "images_list, sub_directories = load_file_names_labeled_subdir_Util(parms.TRAIN_PATH, \n",
    "                                                                   parms.IMAGE_EXT)\n",
    "\n",
    "# Reduce the number of images from 12 to 2, makes it easier to show augmentation\n",
    "del images_list[1:7]\n",
    "del images_list[2:7]\n",
    "\n",
    "images_list_len = len(images_list)\n",
    "print(\"Number of images: \", images_list_len)\n",
    "\n",
    "# Set the class names.\n",
    "parms.set_class_names(sub_directories)\n",
    "print(\"Classes: {}  Labels: {}  {}\".format(parms.NUM_CLASSES, len(parms.CLASS_NAMES), parms.CLASS_NAMES) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDYxSZRP5rFu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the path, show the images that will be used\n",
    "for image_path in images_list[:2]:\n",
    "    print(image_path)\n",
    "    display.display(Image.open(str(image_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1R8KsrBkjgl"
   },
   "source": [
    "## Build an input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWyqw8Yw5rF7"
   },
   "outputs": [],
   "source": [
    "# Simple helper method to display batches of images with labels....        \n",
    "def show_batch(image_batch, label_batch, number_to_show=25, r=5, c=5):\n",
    "    show_number = min(number_to_show, parms.BATCH_SIZE)\n",
    "\n",
    "    if show_number < 8: #if small number, then change row, col and figure size\n",
    "        if parms.IMAGE_COLS > 64 or parms.IMAGE_ROWS > 64:\n",
    "            plt.figure(figsize=(25,25)) \n",
    "        else:\n",
    "            plt.figure(figsize=(10,10))  \n",
    "        r = 4\n",
    "        c = 2 \n",
    "    else:\n",
    "        plt.figure(figsize=(10,10))  \n",
    "\n",
    "    if show_number == 1:\n",
    "        image_batch = np.expand_dims(image_batch, axis=0)\n",
    "        label_batch = np.expand_dims(label_batch, axis=0)\n",
    "\n",
    "    for n in range(show_number):\n",
    "        ax = plt.subplot(r,c,n+1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]))\n",
    "        plt.title(parms.CLASS_NAMES[np.argmax(label_batch[n])])\n",
    "        plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Za1IWHt5rF1"
   },
   "outputs": [],
   "source": [
    "# Return a label based on the path of the image\n",
    "def get_label(file_path: tf.Tensor) -> tf.Tensor:\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    return parts[-2] == parms.CLASS_NAMES\n",
    "\n",
    "# Decode the image, convert to float, normalize by 255 and resize\n",
    "def decode_img(image: tf.Tensor) -> tf.Tensor:\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=parms.IMAGE_CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    image = tf.image.convert_image_dtype(image, parms.IMAGE_DTYPE)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(image, [parms.IMAGE_ROWS, parms.IMAGE_COLS])\n",
    "\n",
    "# Perform any augmentations on just the \"dog\" image\n",
    "def image_aug(image: tf.Tensor, file_path: tf.Tensor) -> tf.Tensor:\n",
    "    # do any augmentations\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    if parts[-2] == \"01-Dog\":\n",
    "      #image = tf.image.rot90(image, 2)\n",
    "      image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    image = tf.clip_by_value(image, 0, 1)  # always clip back to 0, 1 before returning\n",
    "    return image\n",
    "\n",
    "# Method that will take a path and return the image and label\n",
    "def process_path_eager(file_path: tf.Tensor) -> tf.Tensor:\n",
    "    print(\"Eager (False), in Graph mode: \", tf.executing_eagerly() )\n",
    "\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = decode_img(image)\n",
    "    # add any augmentations\n",
    "    image = image_aug(image, file_path)\n",
    "    return image, label\n",
    "\n",
    "def process_path(file_path: tf.Tensor) -> tf.Tensor:\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = decode_img(image)\n",
    "    # add any augmentations\n",
    "    image = image_aug(image, file_path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHLfkV6j5rF5"
   },
   "outputs": [],
   "source": [
    "# Normal dataset input pipeline\n",
    "def prepare_for_training(dataset, cache=True, shuffle_buffer_size=1000):\n",
    "\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            dataset = dataset.cache(cache) # Use a file to cache the images\n",
    "        else:\n",
    "            dataset = dataset.cache()  # Use memory to cache the images\n",
    "\n",
    "    # Repeat forever\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    # set the batch size\n",
    "    dataset = dataset.batch(parms.BATCH_SIZE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wJ5iS1Tu3Jq"
   },
   "source": [
    "### Create dataset and normal mappings (positive case)\n",
    "\n",
    "Pipeline Flow:\n",
    "\n",
    "create dataset -> map \"process_path_eager\" -> repeat forever -> batch\n",
    "\n",
    "This will also show when we are in Eager vs Graph execution.  Basic rule, anytime we are applying methods, we are in Graph mode.  In Graph mode you are not able to evaluate a tensor, so using a method like \".numpy()\" will not work.  All processing must be tensor based.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-LXAs3e5rFx"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from list of images\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(np.array(images_list))\n",
    "\n",
    "# Verify image paths were loaded and save one path for later in \"some_image\"\n",
    "for f in full_dataset.take(2):\n",
    "    some_image = f.numpy().decode(\"utf-8\")\n",
    "    print(f.numpy())\n",
    "    \n",
    "print(\"Some Image: \", some_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TZM_MFp5rGA"
   },
   "outputs": [],
   "source": [
    "# Show we are in Eager execution\n",
    "print(\"Outside of map, Eager (True): \", tf.executing_eagerly() )\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "full_dataset = full_dataset.map(process_path_eager, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, label in full_dataset.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape, np.max(image.numpy()), np.min(image.numpy()))\n",
    "    print(\"Label: \", label.numpy())\n",
    "    \n",
    "# Ready to be used for training, cache is turned off\n",
    "full_dataset = prepare_for_training(full_dataset, cache=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHmOZtlv5rGG"
   },
   "outputs": [],
   "source": [
    "# Show the images, execute this cell multiple times to see the \"dog\" image, rotation should be applied randomally\n",
    "# Execute at least 4 times...\n",
    "image_batch, label_batch = next(iter(full_dataset))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8RtmW0BUB_Df"
   },
   "source": [
    "### Add memory caching\n",
    "\n",
    "Pipeline Flow:\n",
    "\n",
    "create dataset -> map \"process_path\" -> cache -> repeat forever -> batch\n",
    "\n",
    "Since cache is after the map that has image augmentation, the augmentation will only be done once and then saved in cache.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCtrG5kSCGfi"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from list of images\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(np.array(images_list))\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "full_dataset = full_dataset.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "# Ready to be used for training, cache is turned on\n",
    "full_dataset = prepare_for_training(full_dataset, cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DL20fyitCGq6"
   },
   "outputs": [],
   "source": [
    "# Show the images, execute this cell multiple times, \"dog\" image will not change\n",
    "# Execute at least 4 times...\n",
    "image_batch, label_batch = next(iter(full_dataset))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCqfwYqEDKub"
   },
   "source": [
    "### Add file caching\n",
    "\n",
    "Same impact as memory cache.\n",
    "\n",
    "Pipeline Flow:\n",
    "\n",
    "create dataset -> map \"process_path\" -> cache -> repeat forever -> batch\n",
    "\n",
    "Since cache is after the map that has image augmentation, the augmentation will only be done once and then saved in cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8F766mGIDLLm"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from list of images\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(np.array(images_list))\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "full_dataset = full_dataset.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "# Ready to be used for training, cache is turned on\n",
    "full_dataset = prepare_for_training(full_dataset, cache=\"./play.tfcache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4IsF_QrDLYH"
   },
   "outputs": [],
   "source": [
    "# Show the images, execute this cell multiple times, \"dog\" image will not change\n",
    "# Execute at least 4 times...\n",
    "image_batch, label_batch = next(iter(full_dataset))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xBgdFesGDxXU"
   },
   "source": [
    "### New Cache order, add Blur and random augmentation\n",
    "\n",
    "Same impact as memory cache.\n",
    "\n",
    "Pipeline Flow:\n",
    "\n",
    "create dataset -> map \"process_path_blur\" -> cache -> map process_image_aug -> repeat forever -> batch\n",
    "\n",
    "Since cache is after the map that has image Blur augmentation, the Blur augmentation will only be done once and then saved in cache.  But random_flip_up_down will be applied on all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-5OFh6PDxlZ"
   },
   "outputs": [],
   "source": [
    "# These two methods take the \"prepare_for_training\" and seperate it into two methods\n",
    "\n",
    "def cache_dataset(dataset, cache=True):\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            dataset = dataset.cache(cache)\n",
    "        else:\n",
    "            dataset = dataset.cache()\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def prepare_for_training_no_cache(dataset, shuffle_buffer_size=1000):\n",
    "\n",
    "    # Repeat forever\n",
    "    dataset = dataset.repeat()\n",
    "\n",
    "    # set the batch size\n",
    "    dataset = dataset.batch(parms.BATCH_SIZE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fg-IJfySGj21"
   },
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "def image_blur(image):\n",
    "    if bool(np.random.choice([0, 1], p=[0, 1.0])):  # change p values as needed . [0., 1.0] is always True\n",
    "        sigma_max = 4.0\n",
    "        sigma = random.uniform(3., sigma_max)  # change range or remove if want a fixed sigma value\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.int32)\n",
    "        image = gaussian(image, sigma=sigma, multichannel=True)\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image\n",
    "\n",
    "def process_path_blur(file_path: tf.Tensor) -> tf.Tensor:\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = decode_img(image)\n",
    "\n",
    "    #######################################################\n",
    "    # Blur using tf.py_function\n",
    "    im_shape = image.shape\n",
    "    [image,] = tf.py_function(image_blur, [image], [tf.float32])  #parms must be tensors\n",
    "    image.set_shape(im_shape)\n",
    "    #######################################################\n",
    "    return image, label\n",
    "\n",
    "def process_image_aug(image: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n",
    "    # add any augmentations\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfB8U0AZDxwB"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from list of images\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices(np.array(images_list))\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "full_dataset = full_dataset.map(process_path_blur, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# apply cache\n",
    "full_dataset = cache_dataset(full_dataset, cache=True) # Saved in memory, same as using a temp file for cache\n",
    "\n",
    "# map the random augmentation\n",
    "full_dataset = full_dataset.map(process_image_aug, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Ready to be used for training\n",
    "full_dataset = prepare_for_training_no_cache(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwNVoaTZGOML"
   },
   "outputs": [],
   "source": [
    "# Show the images, execute this cell multiple times\n",
    "# All images will have \"Blur\" applied\n",
    "# \"cat\" or \"dog\" image will change as augmentation is applied after cache\n",
    "# Execute at least 4 times...\n",
    "image_batch, label_batch = next(iter(full_dataset))\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goQF3VdzJc9z"
   },
   "source": [
    "### Final Thoughts.....\n",
    "\n",
    "https://stackoverflow.com/questions/50519343/how-to-cache-data-during-the-first-epoch-correctly-tensorflow-dataset\n",
    "\n",
    "The implementation of the Dataset.cache() transformation is fairly simple: it builds up a list of the elements that pass through it as you iterate over completely it the first time, and it returns elements from that list on subsequent attempts to iterate over it. If the first pass only performs a partial pass over the data then the list is incomplete, and TensorFlow doesn't try to use the cached data, because it doesn't know whether the remaining elements will be needed, and in general it might need to reprocess all the preceding elements to compute the remaining elements.\n",
    "\n",
    "\n",
    "https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TFDatasets_V1.ipynb",
   "provenance": [
    {
     "file_id": "1uSN9c7HDnr2pXLzNManXX4eXFhH1c6Dy",
     "timestamp": 1582568730984
    },
    {
     "file_id": "1KpHc6u2_eLqzTYla8bEH-SIPLGWtZ_vW",
     "timestamp": 1582184535490
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
