{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DogBreeds-Training-V1.ipynb","provenance":[{"file_id":"11uAUoq-UC0ftULnwk2LTbVryt3h-D3Q2","timestamp":1582044452297},{"file_id":"1KpHc6u2_eLqzTYla8bEH-SIPLGWtZ_vW","timestamp":1581035272578}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rl85J9Iqh4yQ"},"source":["## Dog Breed classifier using Transfer Learning and tf.data\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xjJySeIXh_md","colab":{}},"source":["#\"\"\"\n","# Google Collab specific stuff....\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","!ls \"/content/drive/My Drive\"\n","\n","USING_COLLAB = True\n","%tensorflow_version 2.x\n","#\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6w1an-l5h4yT","colab":{}},"source":["# Setup sys.path to find MachineLearning lib directory\n","\n","try: USING_COLLAB\n","except NameError: USING_COLLAB = False\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","import sys\n","if \"MachineLearning\" in sys.path[0]:\n","    pass\n","else:\n","    print(sys.path)\n","    if USING_COLLAB:\n","        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    else:\n","        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    \n","    print(sys.path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"csTt9CUvh4yZ","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import os, sys, random, warnings, time, copy, csv, gc\n","import numpy as np \n","\n","import IPython.display as display\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import cv2\n","from tqdm import tqdm_notebook, tnrange, tqdm\n","import pandas as pd\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","import tensorflow_datasets as tfds\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","print(\"AUTOTUNE: \", AUTOTUNE)\n","\n","from TrainingUtils import *\n","\n","#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","#warnings.filterwarnings(\"ignore\", category=UserWarning)\n","warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aplx71Xjh4yg"},"source":["## Examine and understand data\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PMdwqph-h4yd","colab":{}},"source":["# GLOBALS/CONFIG ITEMS\n","\n","# Set root directory path to data\n","if USING_COLLAB:\n","    ROOT_PATH = \"/content/drive/My Drive/ImageData/DogBreeds\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","else:\n","    ROOT_PATH = \"/Users/john/Documents/ImageData/DogBreeds\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","        \n","# Establish global dictionary\n","parms = GlobalParms(MODEL_NAME=\"model-DogBreeds-tf-data-V02.h5\",\n","                    ROOT_PATH=ROOT_PATH,\n","                    TRAIN_DIR=\"train\", \n","                    SMALL_RUN=False,\n","                    NUM_CLASSES=120,\n","                    IMAGE_ROWS=224,\n","                    IMAGE_COLS=224,\n","                    IMAGE_CHANNELS=3,\n","                    BATCH_SIZE=32,\n","                    EPOCS=10,  # change to larger to improve results\n","                    IMAGE_EXT=\".jpg\",\n","                    FINAL_ACTIVATION='softmax',\n","                    LOSS='categorical_crossentropy',\n","                    METRICS=['accuracy'])\n","\n","parms.print_contents()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2mhhvmqN7aFa","colab":{}},"source":["# Simple helper method to display batches of images with labels....        \n","def show_batch(image_batch, label_batch, number_to_show=25, r=5, c=5, print_shape=False):\n","    show_number = min(number_to_show, parms.BATCH_SIZE)\n","\n","    if show_number < 8: #if small number, then change row, col and figure size\n","        if parms.IMAGE_COLS > 64 or parms.IMAGE_ROWS > 64:\n","            plt.figure(figsize=(25,25)) \n","        else:\n","            plt.figure(figsize=(10,10))  \n","        r = 4\n","        c = 2 \n","    else:\n","        plt.figure(figsize=(10,10))  \n","\n","    if show_number == 1:\n","        image_batch = np.expand_dims(image_batch, axis=0)\n","        label_batch = np.expand_dims(label_batch, axis=0)\n","\n","    for n in range(show_number):\n","        if print_shape:\n","            print(\"Image shape: {}  Max: {}  Min: {}\".format(image_batch[n].shape, np.max(image_batch[n]), np.min(image_batch[n])))\n","        ax = plt.subplot(r,c,n+1)\n","        cmap=\"gray\"\n","        if len(image_batch[n].shape) == 3:\n","            if image_batch[n].shape[2] == 3:\n","                cmap=\"viridis\"\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]), cmap=plt.get_cmap(cmap))\n","        plt.title(parms.CLASS_NAMES[np.argmax(label_batch[n])])\n","        plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rBhpD1ofHFrk","colab":{}},"source":["# Download dataset to local VM\n","datasets, info = tfds.load(name='stanford_dogs', with_info=True, as_supervised=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RSSm3dJ5guUQ","colab":{}},"source":["# Set Class names...\n","parms.set_class_names(['Chihuahua', 'Japanese_spaniel', 'Maltese_dog', 'Pekinese', 'Shih-Tzu', 'Blenheim_spaniel', 'papillon', 'toy_terrier', 'Rhodesian_ridgeback', 'Afghan_hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black-tan_coonhound', 'Walker_hound', 'English_foxhound', 'redbone', 'borzoi', 'Irish_wolfhound', 'Italian_greyhound', 'whippet', 'Ibizan_hound', 'Norwegian_elkhound', 'otterhound', 'Saluki', 'Scottish_deerhound', 'Weimaraner', 'Staffordshire_bullterrier', 'American_Staffordshire_terrier', 'Bedlington_terrier', 'Border_terrier', 'Kerry_blue_terrier', 'Irish_terrier', 'Norfolk_terrier', 'Norwich_terrier', 'Yorkshire_terrier', 'wire-haired_fox_terrier', 'Lakeland_terrier', 'Sealyham_terrier', 'Airedale', 'cairn', 'Australian_terrier', 'Dandie_Dinmont', 'Boston_bull', 'miniature_schnauzer', 'giant_schnauzer', 'standard_schnauzer', 'Scotch_terrier', 'Tibetan_terrier', 'silky_terrier', 'soft-coated_wheaten_terrier', 'West_Highland_white_terrier', 'Lhasa', 'flat-coated_retriever', 'curly-coated_retriever', 'golden_retriever', 'Labrador_retriever', 'Chesapeake_Bay_retriever', 'German_short-haired_pointer', 'vizsla', 'English_setter', 'Irish_setter', 'Gordon_setter', 'Brittany_spaniel', 'clumber', 'English_springer', 'Welsh_springer_spaniel', 'cocker_spaniel', 'Sussex_spaniel', 'Irish_water_spaniel', 'kuvasz', 'schipperke', 'groenendael', 'malinois', 'briard', 'kelpie', 'komondor', 'Old_English_sheepdog', 'Shetland_sheepdog', 'collie', 'Border_collie', 'Bouvier_des_Flandres', 'Rottweiler', 'German_shepherd', 'Doberman', 'miniature_pinscher', 'Greater_Swiss_Mountain_dog', 'Bernese_mountain_dog', 'Appenzeller', 'EntleBucher', 'boxer', 'bull_mastiff', 'Tibetan_mastiff', 'French_bulldog', 'Great_Dane', 'Saint_Bernard', 'Eskimo_dog', 'malamute', 'Siberian_husky', 'affenpinscher', 'basenji', 'pug', 'Leonberg', 'Newfoundland', 'Great_Pyrenees', 'Samoyed', 'Pomeranian', 'chow', 'keeshond', 'Brabancon_griffon', 'Pembroke', 'Cardigan', 'toy_poodle', 'miniature_poodle', 'standard_poodle', 'Mexican_hairless', 'dingo', 'dhole', 'African_hunting_dog'])\n","\n","print(\"Classes: \", parms.NUM_CLASSES, \n","      \"   Labels: \", len(parms.CLASS_NAMES), \n","      \"  \", parms.CLASS_NAMES)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Z1R8KsrBkjgl"},"source":["## Build an input pipeline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QzIHTsEUcY2p","colab":{}},"source":["import random\n","import scipy.ndimage\n","from skimage.filters import gaussian\n","\n","def image_blur(image):\n","    # Takes an image and applies Gaussian Blur using skimage filters.\n","    # Applies random +/- sigma_max to the image\n","\n","    if bool(np.random.choice([0, 1], p=[0.7, 0.3])):  # change p values as needed . [0., 1.0] is always True\n","        sigma_max = 3.0\n","        sigma = random.uniform(0., sigma_max)  # change range or remove if want a fixed sigma value\n","        image = tf.image.convert_image_dtype(image, dtype=tf.int32)\n","        image = gaussian(image, sigma=sigma, multichannel=True)\n","        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n","    return image\n","\n","def image_aug_pre_cache(image: tf.Tensor) -> tf.Tensor:\n","\n","    #######################################################\n","    # Blur using tf.py_function\n","    #######################################################\n","    im_shape = image.shape\n","    [image,] = tf.py_function(image_blur, [image], [tf.float32])  #parms must be tensors\n","    image.set_shape(im_shape)\n","    #######################################################\n","\n","    image = tf.clip_by_value(image, 0., 1.)  # after majority of augmentations, clip back to 0, 1 before returning\n","    return image\n","\n","def image_aug_post_cache(image: tf.Tensor) -> tf.Tensor:\n","\n","    #######################################################\n","    # These are native tf.image methods\n","    #######################################################\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_flip_up_down(image)\n","\n","    #######################################################\n","    # random zoom - random crop + resize which will zoom the image\n","    #######################################################\n","    w = parms.IMAGE_COLS\n","    h = parms.IMAGE_ROWS\n","    p = 0.90\n","    image = tf.image.resize(tf.image.random_crop(image, (int(h*p), int(w*p), 3)), (h, w))\n","    #######################################################\n","\n","    image = tf.clip_by_value(image, 0., 1.)  # after majority of augmentations, clip back to 0, 1 before returning\n","    return image\n","\n","def image_normalize_0_1(image: tf.Tensor) -> tf.Tensor:\n","    image = tf.image.resize(image, (parms.IMAGE_COLS, parms.IMAGE_ROWS))\n","    image = tf.cast(image, tf.float32) / 255.\n","    return image\n","\n","def image_normalize_0_1_to_1_neg_1(image: tf.Tensor) -> tf.Tensor:\n","    image = tf.subtract(image, 0.5)\n","    image = tf.multiply(image, 2.0)\n","    return image\n","\n","def image_normalize_1_to_neg_1(image: tf.Tensor) -> tf.Tensor:\n","    image = tf.image.resize(image, (parms.IMAGE_ROWS, parms.IMAGE_COLS))\n","    image = tf.cast(image, tf.float32) / 255.\n","    image = tf.subtract(image, 0.5)\n","    image = tf.multiply(image, 2.0)\n","    return image\n","\n","def process_train_pre_cache(image: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n","    image = image_normalize_0_1(image)\n","    image = image_aug_pre_cache(image)\n","    return image, label_to_onehot(label)\n","\n","def process_train_post_cache(image: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n","    image = image_aug_post_cache(image)\n","    image = image_normalize_0_1_to_1_neg_1(image) # ImageNet needs 1 to -1\n","    return image, label\n","\n","def process_val(image: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n","    image = image_normalize_1_to_neg_1(image)\n","    return image, label_to_onehot(label)\n","\n","def label_to_onehot(label: tf.Tensor) -> tf.Tensor:\n","    return tf.one_hot(label, parms.NUM_CLASSES)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3MxUIepA5rF-","colab":{}},"source":["# Create Dataset from list of images\n","train_dataset = datasets['train']\n","val_dataset = datasets['test']\n","\n","# split into training and validation sets of images\n","full_train_len = info.splits['train'].num_examples\n","full_val_len = info.splits['test'].num_examples\n","\n","# If doing a sanity check (Small Run), then select a subset of the files\n","if parms.SMALL_RUN:\n","    full_train_len_adj = int(full_train_len * 0.2)\n","    full_val_len_adj = int(full_val_len * 0.05)\n","else:\n","    #full_val_len_adj = int(full_val_len * 0.2)\n","    full_train_len_adj = full_train_len\n","    full_val_len_adj = full_val_len\n","\n","images_list_len = full_train_len_adj + full_val_len_adj\n","train_len = full_train_len_adj\n","val_len = full_val_len_adj\n","\n","# Create datasets with new sizes\n","train_dataset = train_dataset.take(train_len) \n","val_dataset = val_dataset.take(val_len)\n","\n","steps_per_epoch = np.ceil(train_len // parms.BATCH_SIZE) # set step sizes based on train & batch\n","validation_steps = np.ceil(val_len // parms.BATCH_SIZE) # set step sizes based on val & batch\n","\n","print(\"Total number: \", images_list_len, \"  Train number: \", train_len, \"  Val number: \", val_len)\n","print(\"Steps/EPOC: \", steps_per_epoch, \"  Steps/Validation: \", validation_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bhwlsx-48daB"},"source":["### Training setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lSrwCo5J7zWo","colab":{}},"source":["def cache_dataset(dataset, cache=False):\n","    if cache:\n","        if isinstance(cache, str):\n","            dataset = dataset.cache(cache)\n","        else:\n","            dataset = dataset.cache()\n","    return dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-TZM_MFp5rGA","colab":{}},"source":["# Verify image paths were loaded and save one path for later in \"some_image\"\n","for f in train_dataset.take(2):\n","    some_image = f[0]\n","    some_label = f[1]\n","    print(f[1])\n","\n","# map training images to pre-cache processing, includes any augmentation\n","train_dataset = train_dataset.map(process_train_pre_cache, num_parallel_calls=AUTOTUNE)\n","\n","# Verify the mapping worked\n","for image, label in train_dataset.take(1):\n","    print(\"Map 1 Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n","    print(\"Label: \", np.argmax(label.numpy()), label.numpy())\n","\n","# cache\n","train_dataset = cache_dataset(train_dataset, cache=\"./breedtrain1.tfcache\")\n","#train_dataset = cache_dataset(train_dataset) # no cache\n","\n","# map training images to post-cache processing, includes any augmentation\n","train_dataset = train_dataset.map(process_train_post_cache, num_parallel_calls=AUTOTUNE)\n","\n","# Verify the mapping worked\n","for image, label in train_dataset.take(1):\n","    print(\"Map 2 Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n","    print(\"Label: \", np.argmax(label.numpy()), label.numpy())\n","\n","\n","# Repeat forever\n","train_dataset = train_dataset.repeat()\n","\n","# set the batch size\n","train_dataset = train_dataset.batch(parms.BATCH_SIZE)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QrNPp8r2CCjo","colab":{}},"source":["#!rm \"./breedval2.tfcache_0.lockfile\"\n","t = np.array([9, 9, 9])\n","print(t.shape[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w3DyZAzX7_Jw","colab":{}},"source":["# Show the images, execute this cell multiple times to see the images\n","\n","image_batch, label_batch = next(iter(train_dataset))\n","#show_batch(image_batch.numpy(), label_batch.numpy())\n","show_batch(image_batch.numpy(), label_batch.numpy(), print_shape=False, number_to_show=6)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CoLDjUFh8YQ8"},"source":["### Validation setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tZT2c4xY5rGD","colab":{}},"source":["# Verify image paths were loaded and save one path for later in \"some_image\"\n","for f in val_dataset.take(2):\n","    print(f[1])\n","\n","# map training images to processing, includes any augmentation\n","val_dataset = val_dataset.map(process_val, num_parallel_calls=AUTOTUNE)\n","\n","# Verify the mapping worked\n","for image, label in val_dataset.take(1):\n","    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n","    print(\"Label: \", np.argmax(label.numpy()), label.numpy())\n","\n","# cache\n","val_dataset = cache_dataset(val_dataset, cache=\"./breedval2.tfcache\")\n","#val_dataset = cache_dataset(val_dataset) # no cache\n","\n","# Repeat forever\n","val_dataset = val_dataset.repeat()\n","\n","# set the batch size\n","val_dataset = val_dataset.batch(parms.BATCH_SIZE)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UHmOZtlv5rGG","colab":{}},"source":["# Test Validation, use smaller \"number_to_show\" to help show the augmentation\n","\n","image_batch, label_batch = next(iter(val_dataset))\n","#show_batch(image_batch.numpy(), label_batch.numpy())\n","show_batch(image_batch.numpy(), label_batch.numpy(), number_to_show=6)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WboW5rmAh4yv"},"source":["## Build  model\n","- add and validate pretrained model as a baseline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H6KnOf_oh4yw","colab":{}},"source":["# Create any call backs for training...These are the most common.\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, min_lr=1e-6)\n","earlystopper = EarlyStopping(patience=8, verbose=1)\n","checkpointer = ModelCheckpoint(parms.MODEL_PATH, monitor='val_loss', verbose=1, mode=\"auto\", save_best_only=True)\n","#csv_logger = CSVLogger(self.cvslogfile, append=True, separator=';')\n","\n","#from keras.callbacks import TensorBoard\n","#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Dg1IuTqEh4y0","colab":{}},"source":["# Create model and compile it\n","\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D, Conv2DTranspose, Concatenate, Activation\n","from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n","from tensorflow.keras.optimizers import Adadelta, Adam, Nadam, SGD\n","########\n","\n","# https://www.tensorflow.org/api_docs/python/tf/keras/applications\n","from tensorflow.keras.applications import MobileNet, imagenet_utils, ResNet50\n","from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n","\n","actual_MobileNet = tf.keras.applications.mobilenet.MobileNet()\n","#actual_ResNet50 = tf.keras.applications.ResNet50()\n","\n","def set_train_layers(model, train_layers=20): #since 224x224x3, set the first 20 layers of the network to be non-trainable\n","    if train_layers == 0: #set all non-trainable\n","        for layer in model.layers:\n","            layer.trainable=False\n","    else:\n","        for layer in model.layers[:train_layers]:             \n","            layer.trainable=False\n","        for layer in model.layers[train_layers:]:\n","            layer.trainable=True\n","    return model\n","\n","def predict_image(model_passed, image):  \n","    image = image_normalize_1_to_neg_1(image)   \n","    image = np.expand_dims(image, axis=0)\n","    predictions = model_passed.predict(image)\n","    return predictions \n","\n","\n","def build_model(parms):\n","    base_model=MobileNet(weights='imagenet',include_top=False, input_shape=parms.IMAGE_DIM) #imports the mobilenet model and discards the last 1000 neuron layer.\n","    #base_model=ResNet50(weights='imagenet',include_top=False, input_shape=parms.IMAGE_DIM) #imports the ResNet50 model and discards the last 1000 neuron layer.\n","    x=base_model.output\n","    x=GlobalAveragePooling2D()(x)\n","    x=Dropout(0.3) (x)\n","    x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n","    #x=Dense(1024,activation='relu')(x) #dense layer 2\n","    x=Dropout(0.4) (x)\n","    #x=Dense(512,activation='relu')(x) #dense layer 3\n","    preds=Dense(parms.NUM_CLASSES, activation=parms.FINAL_ACTIVATION)(x) #final layer\n","    model=Model(inputs=base_model.input,outputs=preds)\n","    return model\n","\n","def compile_model(parms, model):\n","    # Optimizers: https://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms\n","    model.compile(loss=parms.LOSS,\n","          optimizer=SGD(lr=0.001, momentum=0.9),\n","          #optimizer=\"adam\",\n","          #optimizer=\"rmsprop\",\n","          metrics=parms.METRICS)\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dj-uogcrzvYy","colab":{}},"source":["# Double check preprocessing with utility.  np.max & np.min should align with your normalization\n","# https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py\n","\n","img_MobileNet = tf.keras.applications.mobilenet.preprocess_input(tf.cast(some_image, tf.float32))\n","print(\"Image \", some_image.shape, np.max(some_image), np.min(some_image))\n","print(\"Pre   \", img_MobileNet.shape, np.max(img_MobileNet), np.min(img_MobileNet))\n","fig = plt.figure()\n","plt.imshow(tf.keras.preprocessing.image.array_to_img(img_MobileNet))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eLiR08Mqh4y3","colab":{}},"source":["#test an image just using MobileNet\n","predictions = predict_image(actual_MobileNet, some_image)\n","result = imagenet_utils.decode_predictions(predictions)\n","\n","#predictions = predict_image(actual_ResNet50, some_image)\n","#result = resnet50.decode_predictions(predictions, top=1))\n","\n","result \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DOaedfZyh4y5","colab":{}},"source":["#show the image...\n","fig = plt.figure()\n","plt.imshow(tf.keras.preprocessing.image.array_to_img(some_image))\n","fig.suptitle(parms.CLASS_NAMES[some_label])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UHJP9A8_lLnr"},"source":["## Train model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P_AE9vRvh4y8","scrolled":true,"colab":{}},"source":["# Train model\n","model = build_model(parms)\n","set_train_layers(model)\n","model = compile_model(parms, model)\n","\n","history = model.fit(train_dataset,\n","                    validation_data=val_dataset,\n","                    epochs=parms.EPOCS, \n","                    steps_per_epoch=steps_per_epoch,\n","                    validation_steps=validation_steps,\n","                    callbacks=[reduce_lr, earlystopper, checkpointer] # include any callbacks...\n","                    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"btOfnuWEh4y_","colab":{}},"source":["# Plot the training history\n","history_df = pd.DataFrame(history.history)\n","plt.figure()\n","history_df[['loss', 'val_loss']].plot(title=\"Loss\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Loss')\n","history_df[['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"COki5lZ0h4zG"},"source":["## Validate model's predictions\n","- Create actual_lables and predict_labels\n","- Calculate Confusion Matrix & Accuracy\n","- Display results\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tkrhk6FOh4zC","colab":{}},"source":["#Load saved model\n","from tensorflow.keras.models import load_model \n","def load_saved_model(model_path):\n","    model = load_model(model_path)\n","    print(\"loaded: \", model_path)\n","    return model\n","\n","model = load_saved_model(parms.MODEL_PATH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4T-oypFsh4zM","colab":{}},"source":["# Use model to generate predicted labels and probabilities\n","labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset(model, val_dataset, validation_steps, parms.BATCH_SIZE, create_bad_results_list=False)\n","#labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset(model, val_dataset, 1, parms.BATCH_SIZE, create_bad_results_list=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_IurHe_Uh4zO","colab":{}},"source":["show_confusion_matrix(labels, predict_labels, parms.CLASS_NAMES, show_graph=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gdAXk58Zh4zR","colab":{}},"source":["# Graph the results\n","display_prediction_results(labels, predict_labels, predict_probabilities, parms.NUM_CLASSES, parms.CLASS_NAMES)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4e2xRnkGh4zU","colab":{}},"source":["#Create a df from the bad results list, can save as csv or use for further analysis\n","bad_results_df = pd.DataFrame(bad_results, columns =['actual', 'predict', 'prob', 'image'])\n","bad_results_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JW3AQv7Fh4zh","colab":{}},"source":["# default is to not return bad_results, change to include them, create_bad_results_list=True\n","\n","#bad_act, bad_pred, bad_prob, bad_images = zip(*bad_results)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"reSRPklT5rG0","colab":{}},"source":["# display images....        \n","def show_bad_batch(image_batch, bad_act, bad_pred, number_to_show=25):\n","    plt.figure(figsize=(10,10))\n","    show_number = number_to_show\n","    if len(image_batch) < number_to_show:\n","        show_number = len(image_batch)\n","        \n","    for n in range(show_number):\n","        ax = plt.subplot(5,5,n+1)\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n][0]))\n","        #s = parms.CLASS_NAMES[bad_pred[n][0]]\n","        s = \"Act: \"+ str(bad_act[n][0]) + \" Pred: \" + str(bad_pred[n][0])\n","        plt.title(s)\n","        plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8mTsZs0-5rG3","colab":{}},"source":["\n","#show_bad_batch(bad_images, bad_act, bad_pred)"],"execution_count":0,"outputs":[]}]}