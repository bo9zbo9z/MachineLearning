{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DogBreeds_TFDataset_Analysis_V1.ipynb","provenance":[{"file_id":"1uSN9c7HDnr2pXLzNManXX4eXFhH1c6Dy","timestamp":1582568730984},{"file_id":"1KpHc6u2_eLqzTYla8bEH-SIPLGWtZ_vW","timestamp":1582184535490}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rl85J9Iqh4yQ"},"source":["# Dog Breeds analysis\n","\n","Sample pandas examples:\n","\n","https://github.com/rasbt/pattern_classification/blob/master/data_viz/matplotlib_viz_gallery.ipynb\n","https://github.com/rasbt/pattern_classification/blob/master/data_viz/matplotlib_viz_gallery.ipynb\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CwvFftZiqrRE"},"source":["### Processing for using Google Drive and normal includes\n","\n","The notebook uses TensorFlow 2.x.  (Eager execution is enabled by default and we use the newer versions of tf.Data.)\n","\n","I use Notebooks with Colab and on my local workstation, so I need to seperate some logic to make it easier to run in both locations.\n","\n","I was going to delete and just make Colab version, but that is not \"real world.\"  You usually have multiple environments and I'm showing you how I accommodate different environments, you might need something different...\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xjJySeIXh_md","colab":{}},"source":["#\"\"\"\n","# Google Collab specific stuff....\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","!ls \"/content/drive/My Drive\"\n","\n","USING_COLLAB = True\n","# Force to use 2.x version of Tensorflow\n","%tensorflow_version 2.x\n","#\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6w1an-l5h4yT","colab":{}},"source":["# Setup sys.path to find MachineLearning lib directory\n","\n","# Check if \"USING_COLLAB\" is defined, if yes, then we are using Colab, otherwise set to False\n","try: USING_COLLAB\n","except NameError: USING_COLLAB = False\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","# set path env var\n","import sys\n","if \"MachineLearning\" in sys.path[0]:\n","    pass\n","else:\n","    print(sys.path)\n","    if USING_COLLAB:\n","        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    else:\n","        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    \n","    print(sys.path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"csTt9CUvh4yZ","colab":{}},"source":["# Normal includes...\n","\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import os, sys, random, warnings, time, copy, csv\n","import numpy as np \n","\n","import IPython.display as display\n","from PIL import Image\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","# This allows the runtime to decide how best to optimize CPU/GPU usage\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","from TrainingUtils import *\n","\n","#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","#warnings.filterwarnings(\"ignore\", category=UserWarning)\n","warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aplx71Xjh4yg"},"source":["## General Setup\n","\n","- Create a dictionary wrapped by a class for global values.  This is how I manage global vars in my notebooks.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PMdwqph-h4yd","colab":{}},"source":["# Set root directory path to data\n","if USING_COLLAB:\n","    ROOT_PATH = \"/content/drive/My Drive/GitHub/MachineLearning/9-LibTest/Data\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","else:\n","    ROOT_PATH = \"/Users/john/Documents/GitHub/MachineLearning/9-LibTest/Data\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","        \n","# Establish global dictionary\n","parms = GlobalParms(ROOT_PATH=ROOT_PATH,\n","                    TRAIN_DIR=\"CatDogLabeledVerySmall\", \n","                    NUM_CLASSES=120,\n","                    IMAGE_ROWS=224,\n","                    IMAGE_COLS=224,\n","                    IMAGE_CHANNELS=3,\n","                    BATCH_SIZE=1,  # must be one if you want to see different image sizes\n","                    IMAGE_EXT=\".jpg\")\n","\n","parms.print_contents()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vWyqw8Yw5rF7","colab":{}},"source":["# Simple helper method to display batches of images with labels....        \n","def show_batch(image_batch, label_batch, number_to_show=25, r=5, c=5, print_shape=False):\n","    show_number = min(number_to_show, parms.BATCH_SIZE)\n","\n","    if show_number < 8: #if small number, then change row, col and figure size\n","        if parms.IMAGE_COLS > 64 or parms.IMAGE_ROWS > 64:\n","            plt.figure(figsize=(25,25)) \n","        else:\n","            plt.figure(figsize=(10,10))  \n","        r = 4\n","        c = 2 \n","    else:\n","        plt.figure(figsize=(10,10))  \n","\n","    #if show_number == 1:\n","    #  image_batch = np.expand_dims(image_batch, axis=0)\n","    #  label_batch = np.expand_dims(label_batch, axis=0)\n","\n","    for n in range(show_number):\n","        if print_shape:\n","            print(\"Image shape: {}  Max: {}  Min: {}\".format(image_batch[n].shape, np.max(image_batch[n]), np.min(image_batch[n])))\n","\n","        ax = plt.subplot(r,c,n+1)\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]))\n","        plt.title(parms.CLASS_NAMES[np.argmax(label_batch[n])])\n","        plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0wJ5iS1Tu3Jq"},"source":["### Create dataset and normal mappings\n","\n","Pipeline Flow:\n","\n","create dataset -> map \"process_path\" -> repeat forever -> batch\n","\n","The mappings open and read an image.  These next cells should be changed based on your specific needs.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uaK22hoX5rFr","colab":{}},"source":["# Download dataset to local VM\n","\n","import tensorflow_datasets as tfds\n","datasets, info = tfds.load(name='stanford_dogs', with_info=True, as_supervised=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a1UcgQXIoWsS","colab":{}},"source":["# Set Class names...\n","parms.set_class_names(['Chihuahua', 'Japanese_spaniel', 'Maltese_dog', 'Pekinese', 'Shih-Tzu', 'Blenheim_spaniel', 'papillon', 'toy_terrier', 'Rhodesian_ridgeback', 'Afghan_hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black-tan_coonhound', 'Walker_hound', 'English_foxhound', 'redbone', 'borzoi', 'Irish_wolfhound', 'Italian_greyhound', 'whippet', 'Ibizan_hound', 'Norwegian_elkhound', 'otterhound', 'Saluki', 'Scottish_deerhound', 'Weimaraner', 'Staffordshire_bullterrier', 'American_Staffordshire_terrier', 'Bedlington_terrier', 'Border_terrier', 'Kerry_blue_terrier', 'Irish_terrier', 'Norfolk_terrier', 'Norwich_terrier', 'Yorkshire_terrier', 'wire-haired_fox_terrier', 'Lakeland_terrier', 'Sealyham_terrier', 'Airedale', 'cairn', 'Australian_terrier', 'Dandie_Dinmont', 'Boston_bull', 'miniature_schnauzer', 'giant_schnauzer', 'standard_schnauzer', 'Scotch_terrier', 'Tibetan_terrier', 'silky_terrier', 'soft-coated_wheaten_terrier', 'West_Highland_white_terrier', 'Lhasa', 'flat-coated_retriever', 'curly-coated_retriever', 'golden_retriever', 'Labrador_retriever', 'Chesapeake_Bay_retriever', 'German_short-haired_pointer', 'vizsla', 'English_setter', 'Irish_setter', 'Gordon_setter', 'Brittany_spaniel', 'clumber', 'English_springer', 'Welsh_springer_spaniel', 'cocker_spaniel', 'Sussex_spaniel', 'Irish_water_spaniel', 'kuvasz', 'schipperke', 'groenendael', 'malinois', 'briard', 'kelpie', 'komondor', 'Old_English_sheepdog', 'Shetland_sheepdog', 'collie', 'Border_collie', 'Bouvier_des_Flandres', 'Rottweiler', 'German_shepherd', 'Doberman', 'miniature_pinscher', 'Greater_Swiss_Mountain_dog', 'Bernese_mountain_dog', 'Appenzeller', 'EntleBucher', 'boxer', 'bull_mastiff', 'Tibetan_mastiff', 'French_bulldog', 'Great_Dane', 'Saint_Bernard', 'Eskimo_dog', 'malamute', 'Siberian_husky', 'affenpinscher', 'basenji', 'pug', 'Leonberg', 'Newfoundland', 'Great_Pyrenees', 'Samoyed', 'Pomeranian', 'chow', 'keeshond', 'Brabancon_griffon', 'Pembroke', 'Cardigan', 'toy_poodle', 'miniature_poodle', 'standard_poodle', 'Mexican_hairless', 'dingo', 'dhole', 'African_hunting_dog'])\n","\n","print(\"Classes: \", parms.NUM_CLASSES, \n","      \"   Labels: \", len(parms.CLASS_NAMES), \n","      \"  \", parms.CLASS_NAMES)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"USATdbIyi8Ca"},"source":["### Create dataset from list of images and apply mappings"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M-LXAs3e5rFx","colab":{}},"source":["# Create Dataset from list of images\n","full_dataset = datasets['train']\n","full_len = info.splits['train'].num_examples\n","\n","#full_dataset = datasets['test']  \n","#full_len = info.splits['test'].num_examples\n","\n","# Verify image paths were loaded and save one path for later in \"some_image\"\n","for f in full_dataset.take(2):\n","    some_image = f[0]\n","    print(f[1])\n","    \n","#print(\"Some Image: \", some_image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-TZM_MFp5rGA","colab":{}},"source":["# Repeat forever\n","full_dataset = full_dataset.repeat()\n","\n","# set the batch size\n","full_dataset = full_dataset.batch(parms.BATCH_SIZE)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T1_Q_XaoBtZt","colab":{}},"source":["#create simple iterator\n","ds_iter = iter(full_dataset)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UHmOZtlv5rGG","colab":{}},"source":["# Show the images, execute this cell multiple times to see the images\n","# Execute at least 4 times if random is applied\n","\n","image_batch, label_batch = next(ds_iter)\n","show_batch(image_batch.numpy(), label_batch.numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZQ7y2k0pjHQ4"},"source":["### Collect image information\n","\n","This will loop over each image and collect information to be used to create a Pandas dataframe.  The dataframe will then be used to report information.  You can also save the dataframe for future analysis.\n","\n","This is where you can also customize what information is collected.\n","\n","The size of the image is not changed, but you can change so every image is exactly like how it will be used for training.  I've found that looking at the raw image information is more helpful than looking at images that have been resized.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BCM_Xd4irwy_","colab":{}},"source":["# Collect various information about an image\n","def dataset_analysis(ds_iter, steps, test=False):\n","    if test == True:\n","        steps = 4\n","\n","    image_info = []\n","\n","    for i in tqdm(range(int(steps))):\n","        image_batch, label_batch = next(ds_iter)\n","        #show_batch(image_batch.numpy(), label_batch.numpy())\n","\n","        for j in range(parms.BATCH_SIZE):\n","            image = image_batch[j].numpy()\n","            label = label_batch[j].numpy()\n","            #label = np.argmax(label)\n","            r = image.shape[0]\n","            c = image.shape[1]\n","            d = 0\n","            mean0=0\n","            mean1=0\n","            mean2=0\n","            if parms.IMAGE_CHANNELS == 3:\n","                d = image.shape[2]\n","                mean0 = np.mean(image[:,:,0])\n","                mean1 = np.mean(image[:,:,1])\n","                mean2 = np.mean(image[:,:,2])\n","            image_info.append([label, r, c, d, np.mean(image), np.std(image), mean0, mean1, mean2])\n","\n","            if test:\n","                print(image_info[-1])\n","                \n","    return image_info"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JJIlgXSStQIY","colab":{}},"source":["# Build image_info list\n","\n","ds_iter = iter(full_dataset)\n","\n","steps = np.ceil(full_len // parms.BATCH_SIZE)\n","\n","image_info = dataset_analysis(ds_iter, steps=steps, test=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pas-QSw6p8gA","colab":{}},"source":["# Build pandas dataframe\n","image_info_df = pd.DataFrame(image_info, columns =['label', 'row','col', 'dim', 'mean', 'std', \"chmean0\", \"chmean1\", \"chmean2\"])\n","print(image_info_df.describe())\n","image_info_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YO68MUsjp8kX","colab":{}},"source":["#https://jamesrledoux.com/code/group-by-aggregate-pandas\n","image_info_df.groupby('label').agg({'mean': ['count', 'mean', 'min', 'max'], 'std': ['mean', 'min', 'max'], 'row': ['mean', 'min', 'max'],'col': ['mean', 'min', 'max'], 'chmean0':['mean'],'chmean1':['mean'],'chmean2':['mean'] })\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JBVoJW-Xp8o3","colab":{}},"source":["image_info_df.agg({'mean': ['mean', 'min', 'max'], 'std': ['mean', 'min', 'max'], 'row': ['mean', 'min', 'max'],'col': ['mean', 'min', 'max'] })\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_3lyzlN6qFcc","colab":{}},"source":["image_mean = image_info_df[\"mean\"]\n","print(\"Mean: \", np.mean(image_mean), \"  STD: \", np.std(image_mean))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"E6_tIxRQqIOn","colab":{}},"source":["plt.rcParams['figure.figsize'] = [20, 10]\n","image_info_df[\"label\"].value_counts().plot.bar()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GL1wjemvqLFy","colab":{}},"source":["plt.rcParams['figure.figsize'] = [20, 10]\n","image_info_df[\"label\"].value_counts().plot.pie()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AW_A3EyHqQsY","colab":{}},"source":["image_info_df.hist(column='mean')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p9uHkKRqqVnv","colab":{}},"source":["image_info_df.plot.scatter(x='row', y='col', color='Blue', label='Row-Col')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7FlM5KWjqZSd","colab":{}},"source":["# Save results\n","result_path = os.path.join(parms.ROOT_PATH, \"image-info.pkl\")\n","image_info_df.to_pickle(result_path)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wbxDcF1yqcjY","colab":{}},"source":["# open and read saved file\n","image_info_df = pd.read_pickle(result_path)\n","image_info_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"goQF3VdzJc9z"},"source":["### Final Thoughts.....\n","\n","Classes are balanced - like they should be :).  \n","\n","Image size is mainly clustered less than 600, so resizing to 224 should be ok - won't lose too much detail.\n","\n","Mean and STD are consistent across classes.\n","\n","Should be able to apply normal augmentation techniques. "]}]}