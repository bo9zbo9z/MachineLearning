{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rl85J9Iqh4yQ"
   },
   "source": [
    "# Dog Breeds - TF.image Augmentations Playground\n",
    "\n",
    "This notebook allows you to experiment with different image augmentations.  It also shows how to use TF.py_function and a way to create a custom percentage wrapper.  It is NOT a step by step guide, but more of a playground.\n",
    "\n",
    "The dataset illustrated is cats/dogs.  In real usage you would copy this notebook into your subdirectory and then change global parms as needed.  You will see a copy of this notebook in some of my folders.\n",
    "\n",
    "To add/remove the augmentations, uncomment/comment the calls or add methods of your own.\n",
    "\n",
    "The augmentation methods are the one in TF.image and other ones I have used in the past.  (A good list of what you can do to an image)\n",
    "\n",
    "Here is the TF.image information\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/image\n",
    "\n",
    "These are also good research links:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.shift.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.ndimage.interpolation.rotate.html\n",
    "\n",
    "https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/py_function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwvFftZiqrRE"
   },
   "source": [
    "### Processing for using Google Drive and normal includes\n",
    "\n",
    "The notebook uses TensorFlow 2.x.  (Eager execution is enabled by default and we use the newer versions of tf.Data.)\n",
    "\n",
    "I use Notebooks with Colab and on my local workstation, so I need to separate some logic to make it easier to run in both locations.\n",
    "\n",
    "I was going to delete and just make Colab version, but that is not \"real world.\"  You usually have multiple environments and I'm showing you how I accommodate different environments, you might need something different..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xjJySeIXh_md"
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "# Google Collab specific stuff....\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "!ls \"/content/drive/My Drive\"\n",
    "\n",
    "USING_COLLAB = True\n",
    "# Force to use 2.x version of Tensorflow\n",
    "%tensorflow_version 2.x\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6w1an-l5h4yT"
   },
   "outputs": [],
   "source": [
    "# Setup sys.path to find MachineLearning lib directory\n",
    "\n",
    "# Check if \"USING_COLLAB\" is defined, if yes, then we are using Colab, otherwise set to False\n",
    "try: USING_COLLAB\n",
    "except NameError: USING_COLLAB = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set path env var\n",
    "import sys\n",
    "if \"MachineLearning\" in sys.path[0]:\n",
    "    pass\n",
    "else:\n",
    "    print(sys.path)\n",
    "    if USING_COLLAB:\n",
    "        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    else:\n",
    "        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csTt9CUvh4yZ"
   },
   "outputs": [],
   "source": [
    "# Normal includes...\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys, random, warnings, time, copy, csv\n",
    "import numpy as np \n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# This allows the runtime to decide how best to optimize CPU/GPU usage\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "from TrainingUtils import *\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aplx71Xjh4yg"
   },
   "source": [
    "## General Setup\n",
    "\n",
    "- Create a dictionary wrapped by a class for global values.  This is how I manage global vars in my notebooks.\n",
    "- Load a couple of images that will be used to create a very simple dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMdwqph-h4yd"
   },
   "outputs": [],
   "source": [
    "# Set root directory path to data\n",
    "if USING_COLLAB:\n",
    "    ROOT_PATH = \"/content/drive/My Drive/GitHub/MachineLearning/9-LibTest/Data\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "else:\n",
    "    ROOT_PATH = \"/Users/john/Documents/GitHub/MachineLearning/9-LibTest/Data\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "        \n",
    "# Establish global dictionary\n",
    "parms = GlobalParms(ROOT_PATH=ROOT_PATH,\n",
    "                    TRAIN_DIR=\"CatDogLabeledVerySmall\", \n",
    "                    NUM_CLASSES=120,\n",
    "                    IMAGE_ROWS=224,\n",
    "                    IMAGE_COLS=224,\n",
    "                    IMAGE_CHANNELS=3,\n",
    "                    BATCH_SIZE=32,\n",
    "                    IMAGE_EXT=\".jpg\")\n",
    "\n",
    "parms.print_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWyqw8Yw5rF7"
   },
   "outputs": [],
   "source": [
    "# Simple helper method to display batches of images with labels....        \n",
    "def show_batch(image_batch, label_batch, number_to_show=25, r=5, c=5, print_shape=False):\n",
    "    show_number = min(number_to_show, parms.BATCH_SIZE)\n",
    "\n",
    "    if show_number < 8: #if small number, then change row, col and figure size\n",
    "        if parms.IMAGE_COLS > 64 or parms.IMAGE_ROWS > 64:\n",
    "            plt.figure(figsize=(25,25)) \n",
    "        else:\n",
    "            plt.figure(figsize=(10,10))  \n",
    "        r = 4\n",
    "        c = 2 \n",
    "    else:\n",
    "        plt.figure(figsize=(10,10))  \n",
    "\n",
    "    if show_number == 1:\n",
    "        image_batch = np.expand_dims(image_batch, axis=0)\n",
    "        label_batch = np.expand_dims(label_batch, axis=0)\n",
    "\n",
    "    for n in range(show_number):\n",
    "        if print_shape:\n",
    "            print(\"Image shape: {}  Max: {}  Min: {}\".format(image_batch[n].shape, np.max(image_batch[n]), np.min(image_batch[n])))\n",
    "        ax = plt.subplot(r,c,n+1)\n",
    "        cmap=\"gray\"\n",
    "        if len(image_batch[n].shape) == 3:\n",
    "            if image_batch[n].shape[2] == 3:\n",
    "                cmap=\"viridis\"\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]), cmap=plt.get_cmap(cmap))\n",
    "        plt.title(parms.CLASS_NAMES[np.argmax(label_batch[n])])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaK22hoX5rFr"
   },
   "outputs": [],
   "source": [
    "# Download dataset to local VM\n",
    "import tensorflow_datasets as tfds\n",
    "datasets, info = tfds.load(name='stanford_dogs', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Brq8QnaVxSNv"
   },
   "outputs": [],
   "source": [
    "# Set Class names...\n",
    "parms.set_class_names(['Chihuahua', 'Japanese_spaniel', 'Maltese_dog', 'Pekinese', 'Shih-Tzu', 'Blenheim_spaniel', 'papillon', 'toy_terrier', 'Rhodesian_ridgeback', 'Afghan_hound', 'basset', 'beagle', 'bloodhound', 'bluetick', 'black-tan_coonhound', 'Walker_hound', 'English_foxhound', 'redbone', 'borzoi', 'Irish_wolfhound', 'Italian_greyhound', 'whippet', 'Ibizan_hound', 'Norwegian_elkhound', 'otterhound', 'Saluki', 'Scottish_deerhound', 'Weimaraner', 'Staffordshire_bullterrier', 'American_Staffordshire_terrier', 'Bedlington_terrier', 'Border_terrier', 'Kerry_blue_terrier', 'Irish_terrier', 'Norfolk_terrier', 'Norwich_terrier', 'Yorkshire_terrier', 'wire-haired_fox_terrier', 'Lakeland_terrier', 'Sealyham_terrier', 'Airedale', 'cairn', 'Australian_terrier', 'Dandie_Dinmont', 'Boston_bull', 'miniature_schnauzer', 'giant_schnauzer', 'standard_schnauzer', 'Scotch_terrier', 'Tibetan_terrier', 'silky_terrier', 'soft-coated_wheaten_terrier', 'West_Highland_white_terrier', 'Lhasa', 'flat-coated_retriever', 'curly-coated_retriever', 'golden_retriever', 'Labrador_retriever', 'Chesapeake_Bay_retriever', 'German_short-haired_pointer', 'vizsla', 'English_setter', 'Irish_setter', 'Gordon_setter', 'Brittany_spaniel', 'clumber', 'English_springer', 'Welsh_springer_spaniel', 'cocker_spaniel', 'Sussex_spaniel', 'Irish_water_spaniel', 'kuvasz', 'schipperke', 'groenendael', 'malinois', 'briard', 'kelpie', 'komondor', 'Old_English_sheepdog', 'Shetland_sheepdog', 'collie', 'Border_collie', 'Bouvier_des_Flandres', 'Rottweiler', 'German_shepherd', 'Doberman', 'miniature_pinscher', 'Greater_Swiss_Mountain_dog', 'Bernese_mountain_dog', 'Appenzeller', 'EntleBucher', 'boxer', 'bull_mastiff', 'Tibetan_mastiff', 'French_bulldog', 'Great_Dane', 'Saint_Bernard', 'Eskimo_dog', 'malamute', 'Siberian_husky', 'affenpinscher', 'basenji', 'pug', 'Leonberg', 'Newfoundland', 'Great_Pyrenees', 'Samoyed', 'Pomeranian', 'chow', 'keeshond', 'Brabancon_griffon', 'Pembroke', 'Cardigan', 'toy_poodle', 'miniature_poodle', 'standard_poodle', 'Mexican_hairless', 'dingo', 'dhole', 'African_hunting_dog'])\n",
    "\n",
    "print(\"Classes: \", parms.NUM_CLASSES, \n",
    "      \"   Labels: \", len(parms.CLASS_NAMES), \n",
    "      \"  \", parms.CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1R8KsrBkjgl"
   },
   "source": [
    "## Build an input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJ2b_A53jIVP"
   },
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import scipy.ndimage\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "def image_blur(image):\n",
    "    # Takes an image and applies Gaussian Blur using skimage filters.\n",
    "    # Applies random +/- sigma_max to the image\n",
    "\n",
    "    if bool(np.random.choice([0, 1], p=[0.7, 0.3])):  # change p values as needed . [0., 1.0] is always True\n",
    "        sigma_max = 3.0\n",
    "        sigma = random.uniform(0., sigma_max)  # change range or remove if want a fixed sigma value\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.int32)\n",
    "        image = gaussian(image, sigma=sigma, multichannel=True)\n",
    "        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image\n",
    "\n",
    "def image_aug_pre_cache(image: tf.Tensor) -> tf.Tensor:\n",
    "\n",
    "    #######################################################\n",
    "    # Blur using tf.py_function\n",
    "    #######################################################\n",
    "    im_shape = image.shape\n",
    "    [image,] = tf.py_function(image_blur, [image], [tf.float32])  #parms must be tensors\n",
    "    image.set_shape(im_shape)\n",
    "    #######################################################\n",
    "\n",
    "    image = tf.clip_by_value(image, 0., 1.)  # after majority of augmentations, clip back to 0, 1 before returning\n",
    "    return image\n",
    "\n",
    "def image_aug_post_cache(image: tf.Tensor) -> tf.Tensor:\n",
    "\n",
    "    #######################################################\n",
    "    # These are native tf.image methods\n",
    "    #######################################################\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    #######################################################\n",
    "    # random zoom - random crop + resize which will zoom the image\n",
    "    #######################################################\n",
    "    w = parms.IMAGE_COLS\n",
    "    h = parms.IMAGE_ROWS\n",
    "    p = 0.90\n",
    "    image = tf.image.resize(tf.image.random_crop(image, (int(h*p), int(w*p), 3)), (h, w))\n",
    "    #######################################################\n",
    "\n",
    "    image = tf.clip_by_value(image, 0., 1.)  # after majority of augmentations, clip back to 0, 1 before returning\n",
    "    return image\n",
    "\n",
    "def image_normalize_0_1(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.resize(image, (parms.IMAGE_ROWS, parms.IMAGE_COLS))\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    return image\n",
    "\n",
    "def image_normalize_0_1_to_1_neg_1(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.subtract(image, 0.5)\n",
    "    image = tf.multiply(image, 2.0)\n",
    "    return image\n",
    "\n",
    "def image_normalize_1_to_neg_1(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.resize(image, (parms.IMAGE_ROWS, parms.IMAGE_COLS))\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    image = tf.subtract(image, 0.5)\n",
    "    image = tf.multiply(image, 2.0)\n",
    "    return image\n",
    "\n",
    "def process_train_pre_cache(image: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n",
    "    image = image_normalize_0_1(image)\n",
    "    image = image_aug_pre_cache(image)\n",
    "    return image, label_to_onehot(label)\n",
    "\n",
    "def process_train_post_cache(image: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n",
    "    image = image_aug_post_cache(image)\n",
    "    image = image_normalize_0_1_to_1_neg_1(image) # ImageNet needs 1 to -1\n",
    "    return image, label\n",
    "\n",
    "def process_val(image: tf.Tensor, label: tf.Tensor) -> tf.Tensor:\n",
    "    image = image_normalize_1_to_neg_1(image)\n",
    "    return image, label_to_onehot(label)\n",
    "\n",
    "def label_to_onehot(label: tf.Tensor) -> tf.Tensor:\n",
    "    return tf.one_hot(label, parms.NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wJ5iS1Tu3Jq"
   },
   "source": [
    "### Figure out - Train dataset and pre-cache mappings\n",
    "\n",
    "Pipeline Flow:\n",
    "\n",
    "create dataset -> map \"process_train_pre_cache\" -> repeat forever -> batch\n",
    "\n",
    "This will illustrate resizing and pre-cache augmentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDYxSZRP5rFu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create Dataset from list of images\n",
    "train_dataset = datasets['train']\n",
    "train_len = info.splits['train'].num_examples\n",
    "\n",
    "# Verify image paths were loaded and save one path for later in \"some_image\"\n",
    "for f in train_dataset.take(2):\n",
    "    some_image = f[0]\n",
    "    print(f[1])\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "train_dataset = train_dataset.map(process_train_pre_cache, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, label in train_dataset.take(1):\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    print(\"Label: \", np.argmax(label.numpy()), label.numpy())\n",
    "\n",
    "# Repeat forever\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# set the batch size\n",
    "train_dataset = train_dataset.batch(parms.BATCH_SIZE)\n",
    "\n",
    "#create simple iterator - DELETE in training notebook\n",
    "ds_iter_1 = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4T5jVYVZxwI9"
   },
   "outputs": [],
   "source": [
    "# Show the images, execute this cell multiple times to see the images\n",
    " \n",
    "image_batch, label_batch = next(ds_iter_1)\n",
    "show_batch(image_batch.numpy(), label_batch.numpy(), number_to_show=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqTg7BQ7xrdk"
   },
   "source": [
    "### Add final Train pre-cache and post-cache mappings\n",
    "\n",
    "Pipeline Flow:\n",
    "\n",
    "create dataset -> map \"process_train_pre_cache\" -> cache -> process_train_post_cache -> repeat forever -> batch\n",
    "\n",
    "This will illustrate resizing and pre and post cache augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0vKGWLwzF74"
   },
   "outputs": [],
   "source": [
    "def cache_dataset(dataset, cache=False):\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            dataset = dataset.cache(cache)\n",
    "        else:\n",
    "            dataset = dataset.cache()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0GIO7zZugZE"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from list of images\n",
    "train_dataset = datasets['train']\n",
    "train_len = info.splits['train'].num_examples\n",
    "\n",
    "# Verify image paths were loaded and save one path for later in \"some_image\"\n",
    "for f in train_dataset.take(2):\n",
    "    some_image = f[0]\n",
    "    print(f[1])\n",
    "\n",
    "# map training images to pre-cache processing, includes any augmentation\n",
    "train_dataset = train_dataset.map(process_train_pre_cache, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, label in train_dataset.take(1):\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    print(\"Label: \", np.argmax(label.numpy()), label.numpy())\n",
    "\n",
    "# cache\n",
    "#train_dataset = cache_dataset(train_dataset, cache=\"./breedtrain2.tfcache\")\n",
    "train_dataset = cache_dataset(train_dataset) # no cache\n",
    "\n",
    "# map training images to post-cache processing, includes any augmentation\n",
    "train_dataset = train_dataset.map(process_train_post_cache, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Repeat forever\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# set the batch size\n",
    "train_dataset = train_dataset.batch(parms.BATCH_SIZE)\n",
    "\n",
    "#create simple iterator - DELETE in training notebook\n",
    "ds_iter_2 = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vFdH7hFugfX"
   },
   "outputs": [],
   "source": [
    "# Show the images, execute this cell multiple times to see the images\n",
    "\n",
    "image_batch, label_batch = next(ds_iter_2)\n",
    "show_batch(image_batch.numpy(), label_batch.numpy(), print_shape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJA3gyzByDnF"
   },
   "source": [
    "### Create Val dataset mappings\n",
    "\n",
    "Pipeline Flow:\n",
    "\n",
    "create val dataset -> map \"process_val\" -> cache -> repeat forever -> batch\n",
    "\n",
    "This will illustrate resizing for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjWEkLSFyRYw"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from list of images\n",
    "val_dataset = datasets['test']\n",
    "val_len = info.splits['test'].num_examples\n",
    "\n",
    "# Verify image paths were loaded and save one path for later in \"some_image\"\n",
    "for f in val_dataset.take(2):\n",
    "    some_image = f[0]\n",
    "    print(f[1])\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "val_dataset = val_dataset.map(process_val, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, label in val_dataset.take(1):\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    print(\"Label: \", np.argmax(label.numpy()), label.numpy())\n",
    "\n",
    "# cache\n",
    "#val_dataset = cache_dataset(val_dataset, cache=\"./breedval2.tfcache\")\n",
    "val_dataset = cache_dataset(val_dataset) # no cache\n",
    "\n",
    "# Repeat forever\n",
    "val_dataset = val_dataset.repeat()\n",
    "\n",
    "# set the batch size\n",
    "val_dataset = val_dataset.batch(parms.BATCH_SIZE)\n",
    "\n",
    "#create simple iterator - DELETE in training notebook\n",
    "ds_iter_3 = iter(val_dataset)\n",
    "ds_iter_3 = iter(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoD9Ub8TyRiT"
   },
   "outputs": [],
   "source": [
    "# Show the images, execute this cell multiple times to see the images\n",
    "\n",
    "image_batch, label_batch = next(ds_iter_3)\n",
    "show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "goQF3VdzJc9z"
   },
   "source": [
    "### Final Thoughts.....\n",
    "\n",
    "Needed to split augmentation into a pre/post methods because the Blur takes long, so wanted to cache resizing and Blur, but random apply the other augmentations along with the final change to have values between 1 and -1.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DogBreeds_TFImage_Augmentations_V1.ipynb",
   "provenance": [
    {
     "file_id": "1uSN9c7HDnr2pXLzNManXX4eXFhH1c6Dy",
     "timestamp": 1582568730984
    },
    {
     "file_id": "1KpHc6u2_eLqzTYla8bEH-SIPLGWtZ_vW",
     "timestamp": 1582184535490
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
