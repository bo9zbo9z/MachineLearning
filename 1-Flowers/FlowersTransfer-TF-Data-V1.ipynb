{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"FlowersTransfer-TF-Data-V1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rl85J9Iqh4yQ"},"source":["## Flowers classifier using Transfer Learning and tf.data\n","\n","\n","Accuracy : 0.9090909090909091\n","\n","Classification Report\n","              precision    recall  f1-score   support\n","\n","           0    0.96429   0.90000   0.93103        60\n","           1    0.88750   0.98611   0.93421        72\n","           2    0.81538   0.89831   0.85484        59\n","           3    0.98462   0.86486   0.92086        74\n","           4    0.90698   0.89655   0.90173        87\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xjJySeIXh_md","colab":{}},"source":["#\"\"\"\n","# Google Collab specific stuff....\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","!ls \"/content/drive/My Drive\"\n","\n","USING_COLLAB = True\n","%tensorflow_version 2.x\n","#\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6w1an-l5h4yT","colab":{}},"source":["# Setup sys.path to find MachineLearning lib directory\n","\n","try: USING_COLLAB\n","except NameError: USING_COLLAB = False\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","import sys\n","if \"MachineLearning\" in sys.path[0]:\n","    pass\n","else:\n","    print(sys.path)\n","    if USING_COLLAB:\n","        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    else:\n","        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","    \n","    print(sys.path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"csTt9CUvh4yZ","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import os, sys, random, warnings, time, copy, csv, gc\n","import numpy as np \n","\n","import IPython.display as display\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import cv2\n","from tqdm import tqdm_notebook, tnrange, tqdm\n","import pandas as pd\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","print(\"AUTOTUNE: \", AUTOTUNE)\n","\n","from TrainingUtils import *\n","\n","#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","#warnings.filterwarnings(\"ignore\", category=UserWarning)\n","warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aplx71Xjh4yg"},"source":["## Examine and understand data\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PMdwqph-h4yd","colab":{}},"source":["# GLOBALS/CONFIG ITEMS\n","\n","# Set root directory path to data\n","if USING_COLLAB:\n","    ROOT_PATH = \"/content/drive/My Drive/ImageData/Flowers\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","else:\n","    ROOT_PATH = \"/Users/john/Documents/ImageData/Flowers\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n","        \n","# Establish global dictionary\n","parms = GlobalParms(ROOT_PATH=ROOT_PATH,\n","                    TRAIN_DIR=\"train\", \n","                    SMALL_RUN=False,\n","                    NUM_CLASSES=5,\n","                    IMAGE_ROWS=224,\n","                    IMAGE_COLS=224,\n","                    IMAGE_CHANNELS=3,\n","                    BATCH_SIZE=32,\n","                    EPOCS=10,\n","                    IMAGE_EXT=\".jpg\",\n","                    FINAL_ACTIVATION='sigmoid',\n","                    LOSS='binary_crossentropy',\n","                    METRICS=['accuracy'])\n","\n","parms.print_contents()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mq-NmUCg5rFo","colab":{}},"source":["#\"\"\"\n","# If not loaded, uncomment one of these to load the database as needed\n","\n","# This loads the files into a temporary directory                                         \n","load_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n","                                         fname='flower_photos', untar=True)\n","\n","# This loads the files into a actual directory, WILL TAKE LONGER TO UNZIP AND TRAIN.  But stored on Drive\n","#load_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n","#                                         fname='flower_photos', untar=True, cache_subdir=parms.TRAIN_PATH)\n","\n","\n","# set new value for TRAIN_PATH\n","parms.set_train_path(load_dir) # If we downloaded the images, then overide TRAIN_PATH\n","print(load_dir, parms.TRAIN_PATH)\n","\n","#\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uaK22hoX5rFr","colab":{}},"source":["if parms.SMALL_RUN:\n","    max_subdir_files = 10\n","else:\n","    max_subdir_files = 1000000\n","    \n","images_list, sub_directories = load_file_names_labeled_subdir_Util(parms.TRAIN_PATH, \n","                                                                   parms.IMAGE_EXT, \n","                                                                   max_dir_files=max_subdir_files)\n","\n","images_list_len = len(images_list)\n","print(\"Number of images: \", images_list_len)\n","\n","random.shuffle(images_list) # randomize the list\n","\n","# Set the class names.\n","parms.set_class_names(sub_directories)\n","print(\"Classes: \", parms.NUM_CLASSES, \n","      \"   Labels: \", len(parms.CLASS_NAMES), \n","      \"  \", parms.CLASS_NAMES)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YDYxSZRP5rFu","scrolled":true,"colab":{}},"source":["# Show a few images\n","for image_path in images_list[:3]:\n","    print(image_path)\n","    display.display(Image.open(str(image_path)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M-LXAs3e5rFx","colab":{}},"source":["# Create Dataset from list of images\n","full_dataset = tf.data.Dataset.from_tensor_slices(np.array(images_list))\n","full_dataset = full_dataset.shuffle(images_list_len)\n","\n","# Verify image paths were loaded and save one path for later in \"some_image\"\n","for f in full_dataset.take(5):\n","    some_image = f.numpy().decode(\"utf-8\")\n","    print(f.numpy())\n","    \n","print(\"Some Image: \", some_image)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Z1R8KsrBkjgl"},"source":["## Build an input pipeline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2Za1IWHt5rF1","colab":{}},"source":["\n","def get_label(file_path):\n","    # convert the path to a list of path components\n","    parts = tf.strings.split(file_path, os.path.sep)\n","    # The second to last is the class-directory\n","    return parts[-2] == parms.CLASS_NAMES\n","\n","def decode_image(image):\n","    # convert the compressed string to a 3D uint8 tensor\n","    image = tf.image.decode_jpeg(image, channels=parms.IMAGE_CHANNELS)\n","    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n","    image = tf.image.convert_image_dtype(image, parms.IMAGE_DTYPE)\n","    # resize the image to the desired size.\n","    return tf.image.resize(image, [parms.IMAGE_ROWS, parms.IMAGE_COLS])\n","\n","def image_aug(image):\n","    # do any augmentations\n","    if tf.random.uniform(()) > 0.25:    \n","        k = tf.random.uniform(shape=[], minval=1, maxval=4, dtype=tf.int32)\n","        image = tf.image.rot90(image, k) #0-4, 0/270, 90/180/270\n","\n","    image = tf.clip_by_value(image, 0, 1)  # always clip back to 0, 1 before returning\n","    return image\n","\n","def process_path_train(file_path):\n","    label = get_label(file_path)\n","    # load the raw data from the file as a string\n","    image = tf.io.read_file(file_path)\n","    image = decode_image(image)\n","    # add any augmentations\n","    image = image_aug(image)\n","    return image, label\n","\n","def process_path_val(file_path):\n","    label = get_label(file_path)\n","    # load the raw data from the file as a string\n","    image = tf.io.read_file(file_path)\n","    image = decode_image(image)\n","    return image, label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LHLfkV6j5rF5","colab":{}},"source":["def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n","    # This is a small dataset, only load it once, and keep it in memory.\n","    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n","    # fit in memory.\n","    if cache:\n","        if isinstance(cache, str):\n","            ds = ds.cache(cache)\n","        else:\n","            ds = ds.cache()\n","\n","    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n","\n","    # Repeat forever\n","    ds = ds.repeat()\n","    ds = ds.batch(parms.BATCH_SIZE)\n","\n","    # `prefetch` lets the dataset fetch batches in the background while the model\n","    # is training.\n","    ds = ds.prefetch(buffer_size=AUTOTUNE)\n","\n","    return ds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vWyqw8Yw5rF7","colab":{}},"source":["# display images....        \n","def show_batch(image_batch, label_batch, number_to_show=25):\n","    plt.figure(figsize=(10,10))\n","    show_number = number_to_show\n","    if parms.BATCH_SIZE < number_to_show:\n","        show_number = parms.BATCH_SIZE\n","        \n","    for n in range(show_number):\n","        ax = plt.subplot(5,5,n+1)\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]))\n","        plt.title(parms.CLASS_NAMES[np.argmax(label_batch[n])].title())\n","        plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3MxUIepA5rF-","colab":{}},"source":["# split into training and validation sets of images\n","train_len = int(0.9 * images_list_len)\n","val_len = images_list_len - train_len\n","\n","# Create datasets with new sizes\n","train_dataset = full_dataset.take(train_len)  #  Creates dataset with new size\n","val_dataset = full_dataset.skip(train_len)  # Creates dataset after skipping over the size\n","\n","print(\"Total number: \", images_list_len, \"  Train number: \", train_len, \"  Val number: \", val_len)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-TZM_MFp5rGA","colab":{}},"source":["# map training images to processing, includes any augmentation\n","train_dataset = train_dataset.map(process_path_train, num_parallel_calls=AUTOTUNE)\n","\n","# Verify the mapping worked\n","for image, label in train_dataset.take(1):\n","    print(\"Image shape: \", image.numpy().shape)\n","    print(\"Label: \", label.numpy())\n","    \n","# Ready to be used for training\n","train_dataset = prepare_for_training(train_dataset)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tZT2c4xY5rGD","colab":{}},"source":["# map validation images to processing\n","val_dataset = val_dataset.map(process_path_val, num_parallel_calls=AUTOTUNE)\n","\n","# Verify the mapping worked\n","for image, label in val_dataset.take(1):\n","    print(\"Image shape: \", image.numpy().shape)\n","    print(\"Label: \", label.numpy())\n","    \n","# Ready to be used for training\n","val_dataset = prepare_for_training(val_dataset)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UHmOZtlv5rGG","colab":{}},"source":["# Test Training\n","\n","image_batch, label_batch = next(iter(train_dataset))\n","show_batch(image_batch.numpy(), label_batch.numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"npZrR1e65rGJ","colab":{}},"source":["# Test Validation\n","\n","image_batch, label_batch = next(iter(val_dataset))\n","show_batch(image_batch.numpy(), label_batch.numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WboW5rmAh4yv"},"source":["## Build  model\n","- add and validate pretrained model as a baseline"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H6KnOf_oh4yw","colab":{}},"source":["# Create any call backs for training...These are the most common.\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n","\n","reduce_lr = ReduceLROnPlateau(monitor='loss', patience=2, verbose=1, min_lr=1e-6)\n","earlystopper = EarlyStopping(patience=8, verbose=1)\n","checkpointer = ModelCheckpoint(parms.MODEL_PATH, monitor='val_loss', verbose=1, mode=\"auto\", save_best_only=True)\n","#csv_logger = CSVLogger(self.cvslogfile, append=True, separator=';')\n","\n","#from keras.callbacks import TensorBoard\n","#tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Dg1IuTqEh4y0","colab":{}},"source":["# Create model and compile it\n","\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D, Conv2DTranspose, Concatenate, Activation\n","from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n","from tensorflow.keras.optimizers import Adadelta, Adam, Nadam, SGD\n","########\n","#new with transfer learning\n","from tensorflow.keras.applications import MobileNet, imagenet_utils\n","from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n","\n","actual_MobileNet = tf.keras.applications.mobilenet.MobileNet()\n","        \n","def set_train_layers(model, train_layers=20): #since 224x224x3, set the first 20 layers of the network to be non-trainable\n","    if train_layers == 0: #set all non-trainable\n","        for layer in model.layers:\n","            layer.trainable=False\n","    else:\n","        for layer in model.layers[:train_layers]:             \n","            layer.trainable=False\n","        for layer in model.layers[train_layers:]:\n","            layer.trainable=True\n","    return model\n","\n","def predict_image(image):     \n","    image = np.expand_dims(image, axis=0)\n","    image = tf.keras.applications.mobilenet.preprocess_input(image)\n","    predictions = actual_MobileNet.predict(image)\n","    results = imagenet_utils.decode_predictions(predictions)\n","    return results #list of decoded imagenet results\n","\n","\n","def build_model(CFG):\n","    base_model=MobileNet(weights='imagenet',include_top=False, input_shape=parms.IMAGE_DIM) #imports the mobilenet model and discards the last 1000 neuron layer.\n","    x=base_model.output\n","    x=GlobalAveragePooling2D()(x)\n","    x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n","    x=Dense(1024,activation='relu')(x) #dense layer 2\n","    x=Dense(512,activation='relu')(x) #dense layer 3\n","    preds=Dense(parms.NUM_CLASSES, activation=parms.FINAL_ACTIVATION)(x) #final layer\n","    model=Model(inputs=base_model.input,outputs=preds)\n","    return model\n","\n","def compile_model(CFG, model):\n","    model.compile(loss=parms.LOSS,\n","          #optimizer=SGD(lr=0.001, momentum=0.9),\n","          optimizer=Adam(),\n","          metrics=parms.METRICS)\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eLiR08Mqh4y3","colab":{}},"source":["#test an image just using MobileNet\n","from tensorflow.keras.preprocessing import image\n","img = image.load_img(some_image, target_size=(224, 224))\n","img_array = image.img_to_array(img)\n","result = predict_image(img_array)\n","result\n","\n","#str(parms.CLASS_NAMES[0])+'/*'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DOaedfZyh4y5","colab":{}},"source":["#show the image...\n","from IPython.display import Image\n","Image(filename=some_image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ePBlD6LrFrSC","colab":{}},"source":["# Show the activation layers, can be trained or initial model (BETA)\n","#model_raw = build_model(CFG)\n","#img_path = os.path.join(parms.TRAIN_PATH, \"Cat/2.jpg\")\n","#image_show_seq_model_layers_BETA(img_path, model_raw, parms.IMAGE_DIM, \n","#                                 activation_layer_num=0, activation_channel_num=11)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UHJP9A8_lLnr"},"source":["## Train model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P_AE9vRvh4y8","scrolled":true,"colab":{}},"source":["# Train model\n","steps_per_epoch = np.ceil(train_len // parms.BATCH_SIZE) # set step sizes based on train & batch\n","validation_steps = np.ceil(val_len // parms.BATCH_SIZE) # set step sizes based on val & batch\n","\n","model = build_model(parms)\n","model = compile_model(parms, model)\n","\n","history = model.fit(train_dataset,\n","                    validation_data=val_dataset,\n","                    epochs=parms.EPOCS, \n","                    steps_per_epoch=steps_per_epoch,\n","                    validation_steps=validation_steps,\n","                    callbacks=[reduce_lr, earlystopper, checkpointer] # include any callbacks...\n","                    )\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"btOfnuWEh4y_","colab":{}},"source":["# Plot the training history\n","history_df = pd.DataFrame(history.history)\n","plt.figure()\n","history_df[['loss', 'val_loss']].plot(title=\"Loss\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Loss')\n","history_df[['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")\n","plt.xlabel('Epocs')\n","plt.ylabel('Accuracy')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"COki5lZ0h4zG"},"source":["## Validate model's predictions\n","- Create actual_lables and predict_labels\n","- Calculate Confusion Matrix & Accuracy\n","- Display results\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tkrhk6FOh4zC","colab":{}},"source":["#Load saved model\n","from tensorflow.keras.models import load_model \n","def load_saved_model(model_path):\n","    model = load_model(model_path)\n","    print(\"loaded: \", model_path)\n","    return model\n","\n","model = load_saved_model(parms.MODEL_PATH)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4T-oypFsh4zM","colab":{}},"source":["# Use model to generate predicted labels and probabilities\n","#labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset(model, val_dataset, 1, parms.BATCH_SIZE, create_bad_results_list=False)\n","labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset(model, val_dataset, validation_steps, parms.BATCH_SIZE, create_bad_results_list=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_IurHe_Uh4zO","colab":{}},"source":["show_confusion_matrix(labels, predict_labels, parms.CLASS_NAMES)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gdAXk58Zh4zR","colab":{}},"source":["# Graph the results\n","\n","display_prediction_results(labels, predict_labels, predict_probabilities, parms.NUM_CLASSES, parms.CLASS_NAMES)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4e2xRnkGh4zU","colab":{}},"source":["#Create a df from the bad results list, can save as csv or use for further analysis\n","bad_results_df = pd.DataFrame(bad_results, columns =['actual', 'predict', 'prob', 'image'])\n","bad_results_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JW3AQv7Fh4zh","colab":{}},"source":["# default is to not return bad_results, change to include them, create_bad_results_list=True\n","\n","#bad_act, bad_pred, bad_prob, bad_images = zip(*bad_results)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"reSRPklT5rG0","colab":{}},"source":["# display bad images....        \n","def show_bad_batch(image_batch, bad_act, bad_pred, number_to_show=25):\n","    plt.figure(figsize=(10,10))\n","    show_number = number_to_show\n","    if len(image_batch) < number_to_show:\n","        show_number = len(image_batch)\n","\n","    for n in range(show_number):\n","        ax = plt.subplot(5,5,n+1)\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n][0]))\n","        #s = parms.CLASS_NAMES[bad_pred[n][0]]\n","        s = \"Act: \"+ str(bad_act[n][0]) + \" Pred: \" + str(bad_pred[n][0])\n","        plt.title(s)\n","        plt.axis('off')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8mTsZs0-5rG3","colab":{}},"source":["print(\"    0)\", parms.CLASS_NAMES[0],\n","      \"  1)\", parms.CLASS_NAMES[1],\n","      \"  2)\", parms.CLASS_NAMES[2],\n","      \"  3)\", parms.CLASS_NAMES[3],\n","      \"  4)\", parms.CLASS_NAMES[4])\n","#show_bad_batch(bad_images, bad_act, bad_pred)"],"execution_count":0,"outputs":[]}]}