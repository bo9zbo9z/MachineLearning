{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl85J9Iqh4yQ"
   },
   "source": [
    "# Kaggle Cell Protein Classification - Create model on Kaggle Environment\n",
    "\n",
    "Link to competition: https://www.kaggle.com/c/human-protein-atlas-image-classification\n",
    "\n",
    "This notebook was converted from my prior Kaggle notebook.  Migrated to TF 2.x and converted various methods to be more native TF.  This creates a model to classify all proteins in a cell.  This is a multi-classification problem as more than one protein can be present in a sample.  This was run on the Kaggle environment, the training files are large.  The cell protein links are very good and help with the understanding of the different proteins and color stains.  \n",
    "\n",
    "\n",
    "## Cell Protein Links:\n",
    "https://www.proteinatlas.org/humanproteome/cell\n",
    "\n",
    "https://www.proteinatlas.org/learn/dictionary/cell\n",
    "\n",
    "\n",
    "## Other links:\n",
    "Great analysis: https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline\n",
    "\n",
    "3rd place solution: https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/77320\n",
    "\n",
    "## Final Classification Report from Training images:\n",
    "\n",
    "Accuracy : 0.4034256559766764\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0    0.81948   0.83375   0.82655      2412\n",
    "           1    0.73514   0.62100   0.67327       219\n",
    "           2    0.74301   0.64492   0.69050       659\n",
    "           3    0.65948   0.51689   0.57955       296\n",
    "           4    0.73810   0.66159   0.69775       328\n",
    "           5    0.61420   0.43355   0.50830       459\n",
    "           6    0.51479   0.51176   0.51327       170\n",
    "           7    0.72519   0.62363   0.67059       457\n",
    "           8    0.00000   0.00000   0.00000        11\n",
    "           9    1.00000   0.28571   0.44444         7\n",
    "          10    1.00000   0.50000   0.66667         4\n",
    "          11    0.73885   0.61053   0.66859       190\n",
    "          12    0.73000   0.52518   0.61088       139\n",
    "          13    0.65789   0.48544   0.55866       103\n",
    "          14    0.83158   0.78607   0.80818       201\n",
    "          15    0.00000   0.00000   0.00000         8\n",
    "          16    0.60000   0.16484   0.25862        91\n",
    "          17    0.31034   0.30000   0.30508        30\n",
    "          18    0.41727   0.33143   0.36943       175\n",
    "          19    0.49242   0.23050   0.31401       282\n",
    "          20    0.66667   0.14815   0.24242        27\n",
    "          21    0.71386   0.62779   0.66806       763\n",
    "          22    0.59821   0.47183   0.52756       142\n",
    "          23    0.77897   0.72167   0.74923       503\n",
    "          24    0.72917   0.64815   0.68627        54\n",
    "          25    0.70211   0.71169   0.70687      1540\n",
    "          26    0.46429   0.22034   0.29885        59\n",
    "          27    0.00000   0.00000   0.00000         3\n",
    "          \n",
    "   micro avg    0.73121   0.65559   0.69134      9332\n",
    "   \n",
    "   macro avg    0.60646   0.45059   0.50156      9332\n",
    "   \n",
    "weighted avg    0.71972   0.65559   0.68136      9332\n",
    "\n",
    " samples avg    0.72583   0.68251   0.67804      9332\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3363,
     "status": "ok",
     "timestamp": 1586184025551,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "csTt9CUvh4yZ",
    "outputId": "17fd0a24-d543-4dac-b901-6e21da5b016b"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys, random, warnings, time, copy, csv, gc\n",
    "import numpy as np \n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange, tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "print(\"AUTOTUNE: \", AUTOTUNE)\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aplx71Xjh4yg"
   },
   "source": [
    "## Initial Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied in class from personal library\n",
    "\n",
    "class GlobalParms(object):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.keys_and_defaults = {\n",
    "         \"MODEL_NAME\": \"\",  # if you leave .h5 off, puts into a subdirectory\n",
    "         \"ROOT_PATH\": \"\",  # Location of the data for storing any data or files\n",
    "         \"TRAIN_DIR\": \"\",  # Subdirectory in the Root for Training files\n",
    "         \"TEST_DIR\": \"\",  # Optional subdirectory in  Root for Testing file\n",
    "         \"SUBMISSION_PATH\": None,  # Optional subdirectory for Contest files\n",
    "         \"MODEL_PATH\": None,  # Optional, subdirectory for saving/loading model\n",
    "         \"TRAIN_PATH\": None,  # Subdirectory in the Root for Training files\n",
    "         \"TEST_PATH\": None,  # Optional subdirectory in  Root for Testing file\n",
    "         \"SMALL_RUN\": False,   # Optional, run size will be reduced\n",
    "         \"NUM_CLASSES\": 0,  # Number of classes\n",
    "         \"CLASS_NAMES\": [],  # list of class names\n",
    "         \"IMAGE_ROWS\": 0,  # Row size of the image\n",
    "         \"IMAGE_COLS\": 0,  # Col size of the image\n",
    "         \"IMAGE_CHANNELS\": 0,  # Num of Channels, 1 for Greyscale, 3 for color\n",
    "         \"BATCH_SIZE\": 0,  # Number of images in each batch\n",
    "         \"EPOCS\": 0,  # Max number of training EPOCS\n",
    "         \"ROW_SCALE_FACTOR\": 1,  # Optional, allows scaling of an image.\n",
    "         \"COL_SCALE_FACTOR\": 1,  # Optional, allows scaling of an image.\n",
    "         \"IMAGE_EXT\": \".jpg\",  # Extent of the image file_ext\n",
    "         # Optional, default is np.float64, reduce memory by using np.float32\n",
    "         # or np.float16\n",
    "         \"IMAGE_DTYPE\": np.float32,\n",
    "         # Optional, change default if needed, can save memory space\n",
    "         \"Y_DTYPE\": np.int,\n",
    "         \"LOAD_MODEL\": False,  # Optional, If you want to load a saved model\n",
    "         \"SUBMISSION\": \"submission.csv\",  # Optional, Mainly used for Kaggle\n",
    "         \"METRICS\": ['accuracy'],  # ['categorical_accuracy'], ['accuracy']\n",
    "         \"FINAL_ACTIVATION\": 'sigmoid',  # sigmoid, softmax\n",
    "         \"LOSS\": \"\"  # 'binary_crossentropy', 'categorical_crossentropy'\n",
    "        }\n",
    "\n",
    "        self.__dict__.update(self.keys_and_defaults)\n",
    "        self.__dict__.update((k, v) for k, v in kwargs.items()\n",
    "                             if k in self.keys_and_defaults)\n",
    "\n",
    "        # Automatically reduce the training parms, change as needed\n",
    "        if self.__dict__[\"SMALL_RUN\"]:\n",
    "            self.__dict__[\"BATCH_SIZE\"] = 1\n",
    "            self.__dict__[\"EPOCS\"] = 2\n",
    "            self.__dict__[\"ROW_SCALE_FACTOR\"] = 1\n",
    "            self.__dict__[\"COL_SCALE_FACTOR\"] = 1\n",
    "\n",
    "        # Use configuration items to create real ones\n",
    "        self.__dict__[\"SCALED_ROW_DIM\"] = \\\n",
    "            np.int(self.__dict__[\"IMAGE_ROWS\"] /\n",
    "                   self.__dict__[\"ROW_SCALE_FACTOR\"])\n",
    "\n",
    "        self.__dict__[\"SCALED_COL_DIM\"] =  \\\n",
    "            np.int(self.__dict__[\"IMAGE_COLS\"] /\n",
    "                   self.__dict__[\"COL_SCALE_FACTOR\"])\n",
    "\n",
    "        if self.__dict__[\"TRAIN_PATH\"] is None:  # Not passed, so set it\n",
    "            self.__dict__[\"TRAIN_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"ROOT_PATH\"],\n",
    "                             self.__dict__[\"TRAIN_DIR\"])\n",
    "\n",
    "        if self.__dict__[\"TEST_PATH\"] is None:  # Not passed, so set it\n",
    "            self.__dict__[\"TEST_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"ROOT_PATH\"],\n",
    "                             self.__dict__[\"TEST_DIR\"])\n",
    "\n",
    "        if self.__dict__[\"SUBMISSION_PATH\"] is None:  # Not passed, so set\n",
    "            self.__dict__[\"SUBMISSION_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"ROOT_PATH\"],\n",
    "                             self.__dict__[\"SUBMISSION\"])\n",
    "        else:\n",
    "            self.__dict__[\"SUBMISSION_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"SUBMISSION_PATH\"],\n",
    "                             self.__dict__[\"SUBMISSION\"])\n",
    "\n",
    "        if self.__dict__[\"MODEL_PATH\"] is None:  # Not passed, so set it\n",
    "            self.__dict__[\"MODEL_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"ROOT_PATH\"],\n",
    "                             self.__dict__[\"MODEL_NAME\"])\n",
    "        else:\n",
    "            self.__dict__[\"MODEL_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"MODEL_PATH\"],\n",
    "                             self.__dict__[\"MODEL_NAME\"])\n",
    "\n",
    "        self.__dict__[\"IMAGE_DIM\"] = \\\n",
    "            (self.__dict__[\"SCALED_ROW_DIM\"],\n",
    "             self.__dict__[\"SCALED_COL_DIM\"],\n",
    "             self.__dict__[\"IMAGE_CHANNELS\"])\n",
    "\n",
    "        if self.__dict__[\"IMAGE_CHANNELS\"] == 1:\n",
    "            self.__dict__[\"COLOR_MODE\"] = \"grayscale\"\n",
    "        else:\n",
    "            self.__dict__[\"COLOR_MODE\"] = \"rgb\"\n",
    "\n",
    "    def set_train_path(self, train_path):\n",
    "        self.__dict__[\"TRAIN_PATH\"] = train_path\n",
    "\n",
    "    def set_class_names(self, class_name_list):\n",
    "        self.__dict__[\"CLASS_NAMES\"] = class_name_list\n",
    "\n",
    "        if self.__dict__[\"NUM_CLASSES\"] != \\\n",
    "           len(self.__dict__[\"CLASS_NAMES\"]):\n",
    "            raise ValueError(\"ERROR number of classses do not match, Classes: \"\n",
    "                             + str(self.__dict__[\"NUM_CLASSES\"])\n",
    "                             + \" Class List: \"\n",
    "                             + str(self.__dict__[\"CLASS_NAMES\"]))\n",
    "\n",
    "    def print_contents(self):\n",
    "        print(self.__dict__)\n",
    "\n",
    "    def print_key_value(self):\n",
    "        for key, value in self.__dict__.items():\n",
    "            print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3355,
     "status": "ok",
     "timestamp": 1586184025551,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "PMdwqph-h4yd",
    "outputId": "ca29ccb0-b8e5-4720-b2ee-19965f681c39"
   },
   "outputs": [],
   "source": [
    "# Setup GLOBALS/CONFIG ITEMS\n",
    "\n",
    "USING_KAGGLE = True\n",
    "# Set root directory path to data\n",
    "if USING_KAGGLE:\n",
    "    ROOT_PATH = \"../input/human-protein-atlas-image-classification/\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "else:\n",
    "    ROOT_PATH = \"/Users/john/Documents/ImageData/KaggleCellProteins\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "        \n",
    "# Establish global dictionary\n",
    "parms = GlobalParms(MODEL_NAME=\"model-cell-protein-all-V01.h5\",\n",
    "                    ROOT_PATH=ROOT_PATH,\n",
    "                    MODEL_PATH=\"\",\n",
    "                    TRAIN_DIR=\"train\", \n",
    "                    NUM_CLASSES=28,\n",
    "                    IMAGE_ROWS=224,\n",
    "                    IMAGE_COLS=224,\n",
    "                    IMAGE_CHANNELS=3,\n",
    "                    BATCH_SIZE=16, #32\n",
    "                    EPOCS=20,\n",
    "                    IMAGE_EXT=\".png\",\n",
    "                    FINAL_ACTIVATION='softmax',\n",
    "                    LOSS='binary_crossentropy',\n",
    "                    METRICS=['accuracy'])\n",
    "\n",
    "parms.print_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mhhvmqN7aFa"
   },
   "outputs": [],
   "source": [
    "# Simple helper method to display batches of images with labels....   \n",
    "\n",
    "def show_batch(image_batch, label_batch, number_to_show=25, r=5, c=5, print_shape=False):\n",
    "    show_number = min(number_to_show, parms.BATCH_SIZE)\n",
    "\n",
    "    if show_number < 8: #if small number, then change row, col and figure size\n",
    "        if parms.IMAGE_COLS > 64 or parms.IMAGE_ROWS > 64:\n",
    "            plt.figure(figsize=(25,25)) \n",
    "        else:\n",
    "            plt.figure(figsize=(10,10))  \n",
    "        r = 4\n",
    "        c = 2 \n",
    "    else:\n",
    "        plt.figure(figsize=(10,10))  \n",
    "\n",
    "    if show_number == 1:\n",
    "        image_batch = np.expand_dims(image_batch, axis=0)\n",
    "        label_batch = np.expand_dims(label_batch, axis=0)\n",
    "\n",
    "    for n in range(show_number):\n",
    "        if print_shape:\n",
    "            print(\"Image shape: {}  Max: {}  Min: {}\".format(image_batch[n].shape, np.max(image_batch[n]), np.min(image_batch[n])))\n",
    "        ax = plt.subplot(r,c,n+1)\n",
    "        cmap=\"gray\"\n",
    "        if len(image_batch[n].shape) == 3:\n",
    "            if image_batch[n].shape[2] == 3:\n",
    "                cmap=\"viridis\"\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]), cmap=plt.get_cmap(cmap))\n",
    "        \n",
    "        s=\"\"\n",
    "        for i, val in enumerate(label_batch[n].numpy()):\n",
    "            if val == 1:\n",
    "                #s += label_names[i] + \", \"\n",
    "                s += str(i) + \", \"\n",
    "        s = s[-1]\n",
    "        plt.title(s)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jOwJTE-M_gTo"
   },
   "outputs": [],
   "source": [
    "# Establish labels\n",
    "\n",
    "label_names = {\n",
    "    0:  \"Nucleoplasm\",  \n",
    "    1:  \"Nuclear membrane\",   \n",
    "    2:  \"Nucleoli\",   \n",
    "    3:  \"Nucleoli fibrillar center\",   \n",
    "    4:  \"Nuclear speckles\",\n",
    "    5:  \"Nuclear bodies\",   \n",
    "    6:  \"Endoplasmic reticulum\",   \n",
    "    7:  \"Golgi apparatus\",   \n",
    "    8:  \"Peroxisomes\",   \n",
    "    9:  \"Endosomes\",   \n",
    "    10:  \"Lysosomes\",   \n",
    "    11:  \"Intermediate filaments\",   \n",
    "    12:  \"Actin filaments\",   \n",
    "    13:  \"Focal adhesion sites\",   \n",
    "    14:  \"Microtubules\",   \n",
    "    15:  \"Microtubule ends\",   \n",
    "    16:  \"Cytokinetic bridge\",   \n",
    "    17:  \"Mitotic spindle\",   \n",
    "    18:  \"Microtubule organizing center\",   \n",
    "    19:  \"Centrosome\",   \n",
    "    20:  \"Lipid droplets\",   \n",
    "    21:  \"Plasma membrane\",   \n",
    "    22:  \"Cell junctions\",   \n",
    "    23:  \"Mitochondria\",   \n",
    "    24:  \"Aggresome\",   \n",
    "    25:  \"Cytosol\",   \n",
    "    26:  \"Cytoplasmic bodies\",   \n",
    "    27:  \"Rods & rings\"\n",
    "}\n",
    "\n",
    "parms.set_class_names(label_names)\n",
    "\n",
    "reverse_class_names = dict((v,k) for k,v in label_names.items())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process training csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14561,
     "status": "ok",
     "timestamp": 1586184036771,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "FlBxwHMJ_gG-",
    "outputId": "abac5fd0-8e86-4e9e-f673-868a226eb87d"
   },
   "outputs": [],
   "source": [
    "# Load and process cvs\n",
    "\n",
    "# Fills all of the protein targets using row apply method\n",
    "def fill_targets(row):\n",
    "#    print(row)\n",
    "    row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n",
    "    for num in row.Target:\n",
    "        name = label_names[int(num)]\n",
    "        row.loc[name] = 1\n",
    "    return row\n",
    "\n",
    "# load csv file\n",
    "all_df = pd.read_csv(os.path.join(parms.ROOT_PATH, \"train.csv\"))\n",
    "\n",
    "# Build empty protein targets\n",
    "for key in label_names.keys(): \n",
    "    all_df[label_names[key]] = 0\n",
    "\n",
    "# Apply fill_targets to fill proteins with \"1\"\n",
    "all_df = all_df.apply(fill_targets, axis=1)\n",
    "\n",
    "# Create number of targets column\n",
    "all_df[\"number_of_targets\"] = all_df.drop([\"Id\", \"Target\"],axis=1).sum(axis=1)  #add count col\n",
    "\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds a string label to pass into datasets\n",
    "# Datasets needs something hashable, so passing a string that will be converted to an array was the easiest\n",
    "\n",
    "def build_label(row):\n",
    "    row_label = np.zeros((parms.NUM_CLASSES), dtype=np.int32)\n",
    "    row_label[row.Target] = 1\n",
    "    row_label_s = str(row_label)\n",
    "    row_label_s = row_label_s[1:len(row_label_s)-1]\n",
    "    row.Labels = row_label_s\n",
    "    #return str(row_label)\n",
    "    return row\n",
    "\n",
    "all_df[\"Labels\"] = \"\"\n",
    "all_df = all_df.apply(build_label, axis=1)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows targets\n",
    "\n",
    "balanced_all_df = all_df.groupby('number_of_targets').apply(lambda x: x.sample(SAMPLES_PER_GROUP) if len(x) > SAMPLES_PER_GROUP else x)\n",
    "balanced_all_df['number_of_targets'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15214,
     "status": "ok",
     "timestamp": 1586184037453,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "XP9_2uhNAE4v",
    "outputId": "2bc6b876-a0e8-4875-eccc-88536ab9c0e2"
   },
   "outputs": [],
   "source": [
    "# Limits the number targets to help balance classes\n",
    "\n",
    "SAMPLES_PER_GROUP = 12000\n",
    "balanced_all_df = all_df.groupby('number_of_targets').apply(lambda x: x.sample(SAMPLES_PER_GROUP) if len(x) > SAMPLES_PER_GROUP else x)\n",
    "balanced_all_df['number_of_targets'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15206,
     "status": "ok",
     "timestamp": 1586184037454,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "rNE1O4WZAFAh",
    "outputId": "ec24b769-a325-4220-f996-fa3ba4123ca5"
   },
   "outputs": [],
   "source": [
    "# Split train and val, stratify by number of targets\n",
    "\n",
    "train_df, valid_df = train_test_split(balanced_all_df, \n",
    "                                      test_size = 0.2,\n",
    "                                      stratify = balanced_all_df['number_of_targets'])\n",
    "\n",
    "# Add some more training examples from the sparse examples\n",
    "print('Original Training len: ', train_df.shape[0], \"  Validation len: \", valid_df.shape[0])\n",
    "add_more_df = train_df.loc[train_df[\"number_of_targets\"] > 2]\n",
    "add_more_df = pd.concat([add_more_df, add_more_df])\n",
    "train_df = pd.concat([train_df, add_more_df])\n",
    "train_df.reset_index(drop=True)\n",
    "train_df = shuffle(train_df) # Shuffle\n",
    "\n",
    "print('After Adjust, Training len: ', train_df.shape[0], \"  Validation len: \", valid_df.shape[0])\n",
    "\n",
    "# set lengths and steps\n",
    "train_len = len(train_df)\n",
    "val_len = len(valid_df)\n",
    "images_list_len = train_len + val_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15199,
     "status": "ok",
     "timestamp": 1586184037455,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "vJVCTtPNAFKl",
    "outputId": "7687ac1e-8c6f-4201-9186-7959cf110d3c"
   },
   "outputs": [],
   "source": [
    "# Set counts\n",
    "\n",
    "steps_per_epoch = np.ceil(train_len // parms.BATCH_SIZE) # set step sizes based on train & batch\n",
    "validation_steps = np.ceil(val_len // parms.BATCH_SIZE) # set step sizes based on val & batch\n",
    "\n",
    "print(\"Total number: \", images_list_len, \"  Train number: \", train_len, \"  Val number: \", val_len)\n",
    "print(\"Steps/EPOC: \", steps_per_epoch, \"  Steps/Validation: \", validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15191,
     "status": "ok",
     "timestamp": 1586184037455,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "EMOhT88NBU7Y",
    "outputId": "88e06d37-ba7e-4e19-f9d1-e3b3ee87d36d"
   },
   "outputs": [],
   "source": [
    "# Double check training and validation counts\n",
    "\n",
    "print(train_df['number_of_targets'].value_counts())\n",
    "print(valid_df['number_of_targets'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1R8KsrBkjgl"
   },
   "source": [
    "## Build an input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzIHTsEUcY2p"
   },
   "outputs": [],
   "source": [
    "# Augments training images\n",
    "def image_mask_aug(image):\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:    \n",
    "        k = tf.random.uniform(shape=[], minval=1, maxval=4, dtype=tf.int32)\n",
    "        image = tf.image.rot90(image, k) #0-4, 0/360, 90/180/270\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_up_down(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Read, decode the image, convert to float\n",
    "def read_decode_image(image_id: tf.Tensor, label_string: tf.Tensor) -> tf.Tensor:\n",
    "\n",
    "    # load the raw data from the files\n",
    "    file_path = parms.TRAIN_PATH+\"/\"+image_id+\"_green\"+parms.IMAGE_EXT\n",
    "    image_g = tf.io.read_file(file_path)\n",
    "    image_g = tf.image.decode_png(image_g, channels=1)\n",
    "    image_g = tf.image.convert_image_dtype(image_g, parms.IMAGE_DTYPE)\n",
    "\n",
    "    file_path = parms.TRAIN_PATH+\"/\"+image_id+\"_blue\"+parms.IMAGE_EXT\n",
    "    image_b = tf.io.read_file(file_path)\n",
    "    image_b = tf.image.decode_png(image_b, channels=1)\n",
    "    image_b = tf.image.convert_image_dtype(image_b, parms.IMAGE_DTYPE)\n",
    "\n",
    "    file_path = parms.TRAIN_PATH+\"/\"+image_id+\"_red\"+parms.IMAGE_EXT\n",
    "    image_r = tf.io.read_file(file_path)\n",
    "    image_r = tf.image.decode_png(image_r, channels=1)\n",
    "    image_r = tf.image.convert_image_dtype(image_r, parms.IMAGE_DTYPE)\n",
    "\n",
    "    file_path = parms.TRAIN_PATH+\"/\"+image_id+\"_yellow\"+parms.IMAGE_EXT\n",
    "    image_y = tf.io.read_file(file_path)\n",
    "    image_y = tf.image.decode_png(image_y, channels=1)\n",
    "    image_y = tf.image.convert_image_dtype(image_y, parms.IMAGE_DTYPE)\n",
    "    \n",
    "    # Merge Red and Yellow images into a single image\n",
    "    image_r_plus_y = image_r + image_y\n",
    "    image_ry = tf.where(image_r_plus_y > 0, image_r_plus_y / 2, 0)\n",
    "\n",
    "    # Build label from string\n",
    "    b = tf.strings.split(label_string, sep=\" \")\n",
    "    label = tf.strings.to_number(b, tf.float32)\n",
    "\n",
    "    # Stack files to create a 3 dim image\n",
    "    image = tf.stack([image_g[:,:,0], image_b[:,:,0], image_ry[:,:,0]], axis=2)\n",
    "    image = tf.image.resize(image, (parms.IMAGE_ROWS, parms.IMAGE_COLS))\n",
    "    \n",
    "    # If image is dark, brighten by 10%\n",
    "    image_mean = tf.math.reduce_mean(image)\n",
    "    image_mean_adj = tf.cond(image_mean < 0.10, lambda: image_mean + 0.10, lambda: 0.0)\n",
    "    image = tf.where(image > 0, image + image_mean_adj, image)\n",
    "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "# Apply method for training files\n",
    "def process_train(image_id: tf.Tensor, label_string: tf.Tensor) -> tf.Tensor:\n",
    "    image, label = read_decode_image(image_id, label_string)\n",
    "    image = image_mask_aug(image)\n",
    "    return image, label\n",
    "\n",
    "# Apply method for validation files\n",
    "def process_val(image_id: tf.Tensor, label_string: tf.Tensor) -> tf.Tensor:\n",
    "    image, label = read_decode_image(image_id, label_string)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 167871,
     "status": "error",
     "timestamp": 1586183799314,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "3MxUIepA5rF-",
    "outputId": "4ef5e721-f62b-4ff2-f8d3-a47db287e0da"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from df\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_df[\"Id\"].values,\n",
    "                                                    train_df[\"Labels\"].values)\n",
    "                                                  )\n",
    "\n",
    "# Verify image paths were loaded\n",
    "for image_id, label in train_dataset.take(2):\n",
    "    print(\"Image ID: \", image_id.numpy().decode(\"utf-8\"), \"  Label: \", label.numpy())\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "train_dataset = train_dataset.map(process_train, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, label in train_dataset.take(1):\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    print(\"Label: \", label.numpy())\n",
    "    some_image = image.numpy()\n",
    "    some_label = label.numpy()\n",
    "\n",
    "train_dataset = train_dataset.batch(parms.BATCH_SIZE) \\\n",
    "                             .prefetch(1) \\\n",
    "                             .repeat()\n",
    "\n",
    "# Show the images, execute this cell multiple times to see the images\n",
    "for image, label in train_dataset.take(1):\n",
    "    sample_image, sample_label = image, label\n",
    "show_batch(sample_image, sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSrwCo5J7zWo"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from df\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((valid_df[\"Id\"].values,\n",
    "                                                  valid_df[\"Labels\"].values)\n",
    "                                                 )\n",
    "\n",
    "\n",
    "# Verify image paths were loaded\n",
    "for image_id, label in val_dataset.take(2):\n",
    "    print(\"Image ID: \", image_id.numpy().decode(\"utf-8\"), \"  Label: \", label.numpy())\n",
    "\n",
    "    # map training images to processing, includes any augmentation\n",
    "val_dataset = val_dataset.map(process_val, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, label in val_dataset.take(1):\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    print(\"Label: \", label.numpy())\n",
    "    some_image = image.numpy()\n",
    "    some_label = label.numpy()\n",
    "\n",
    "val_dataset = val_dataset.batch(parms.BATCH_SIZE) \\\n",
    "                         .prefetch(1) \\\n",
    "                         .repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-TZM_MFp5rGA"
   },
   "outputs": [],
   "source": [
    "# Final check before model training.  I added a string of the mask non-zero counts - need to make sure the masks \n",
    "# were created ok.  (got bit by this one after a small change....)\n",
    "\n",
    "# Test Validation or Train by changing the dataset\n",
    "\n",
    "#for image, mask in train_dataset.take(1):\n",
    "for image, label in val_dataset.take(1):\n",
    "    show_batch(image, label)  # Will show all of the batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WboW5rmAh4yv"
   },
   "source": [
    "## Build  model\n",
    "- add and validate pretrained model as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6KnOf_oh4yw"
   },
   "outputs": [],
   "source": [
    "# Create any call backs for training...These are the most common.\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, min_lr=1e-6)\n",
    "earlystopper = EarlyStopping(patience=8, verbose=1)\n",
    "checkpointer = ModelCheckpoint(parms.MODEL_PATH, monitor='val_simple_F1', verbose=1, mode=\"max\", save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/metrics-for-imbalanced-classification-41c71549bbb5\n",
    "def simple_F1(y_true, y_score):\n",
    "    # True positive\n",
    "    tp = tf.math.reduce_sum(y_true * y_score)\n",
    "    # False positive\n",
    "    fp = tf.math.reduce_sum(tf.cast((y_true == 0), y_true.dtype) * y_score)\n",
    "    # True negative\n",
    "    tn = tf.math.reduce_sum(tf.cast((y_true==0), y_true.dtype) * tf.cast((y_score==0), y_true.dtype))\n",
    "    # False negative\n",
    "    fn = tf.math.reduce_sum(y_true * tf.cast((y_score==0), y_true.dtype))\n",
    "\n",
    "    # F1 score\n",
    "    f1 = 2*tp / (2*tp + fp + fn)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dg1IuTqEh4y0"
   },
   "outputs": [],
   "source": [
    "# Create model and compile it\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D, Conv2DTranspose, Concatenate, Activation\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, Nadam, SGD\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "\n",
    "densenet = tf.keras.applications.DenseNet121(include_top=False, input_shape=(224,224,3))\n",
    "# Build and compile model.  I used this model before, did not adjust parms.\n",
    "# You can change to try different configurations.  (DO percentages, Dense layers, etc)\n",
    "def build_compile_model(parms):\n",
    "    model = Sequential()\n",
    "    model.add(densenet)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1024,activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(parms.NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=0.0005), \n",
    "        metrics=[simple_F1])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHJP9A8_lLnr"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_AE9vRvh4y8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build and Train model\n",
    "\n",
    "model = build_compile_model(parms)\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=parms.EPOCS, \n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[reduce_lr, earlystopper, checkpointer]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2606,
     "status": "ok",
     "timestamp": 1586109341054,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "btOfnuWEh4y_",
    "outputId": "64ca69b3-c4d4-4514-df08-f5dede7ac1c3"
   },
   "outputs": [],
   "source": [
    "# Plot the training history\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.figure()\n",
    "history_df[['loss', 'val_loss']].plot(title=\"Loss\")\n",
    "plt.xlabel('Epocs')\n",
    "plt.ylabel('Loss')\n",
    "history_df[['simple_F1', 'val_simple_F1']].plot(title=\"F1\")\n",
    "plt.xlabel('Epocs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COki5lZ0h4zG"
   },
   "source": [
    "## Validate model's predictions\n",
    "- Create actual_lables and predict_labels\n",
    "- Calculate Confusion Matrix & Accuracy\n",
    "- Display results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17157,
     "status": "ok",
     "timestamp": 1586109355618,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "tkrhk6FOh4zC",
    "outputId": "7d0288de-adbf-4bb0-de4a-93753e87a121"
   },
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "if USING_KAGGLE:\n",
    "    file_name = parms.MODEL_PATH\n",
    "else:\n",
    "    file_name = os.path.join(parms.ROOT_PATH, parms.MODEL_NAME)\n",
    "\n",
    "print(file_name)\n",
    "model = load_model(file_name, custom_objects={'simple_F1': simple_F1})\n",
    "print(\"loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_using_dataset_cell(model_actual,\n",
    "                              dataset,\n",
    "                              steps,\n",
    "                              batch_size,\n",
    "                              create_bad_results_list=False):\n",
    "    \"\"\"\n",
    "      Uses dataset to predict results.  Builds actual_labels, predict_labels\n",
    "      and predict_probabilities\n",
    "\n",
    "      Args:\n",
    "        model_actual : trained model to use for predictions\n",
    "        ds_iter : dataset iterator\n",
    "        steps : number of batches to process\n",
    "        create_bad_results_list : bool default True.  Lets you trun on/off\n",
    "            the creation of the bad results lists.\n",
    "\n",
    "      Returns:\n",
    "        actual_labels : list of actual labels\n",
    "        predict_labels : list of predicted labels\n",
    "        predict_probabilities : list of predicted probability array\n",
    "        bad_results : list of bad results [actual_labels, predict_labels,\n",
    "                      predict_probabilities, image]\n",
    "    \"\"\"\n",
    "\n",
    "    bad_cnt = 0.0\n",
    "    good_cnt = 0.0\n",
    "    total_cnt = 0\n",
    "    actual_labels = []\n",
    "    predict_labels = []\n",
    "    predict_probabilities = []\n",
    "    bad_results = []\n",
    "\n",
    "    for image_batch, label_batch in tqdm(dataset.take(steps)):\n",
    "        for j in range(batch_size):\n",
    "            image = image_batch[j]\n",
    "            label = label_batch[j].numpy()\n",
    "\n",
    "            total_cnt += 1\n",
    "            actual_label = label\n",
    "            \n",
    "            image = np.expand_dims(image, axis=0)\n",
    "\n",
    "            predict_probabilities_tmp = model_actual.predict(image)[0]\n",
    "            # Create binary predictions\n",
    "            predict_label = np.where(predict_probabilities_tmp > 0.5, 1., 0.)\n",
    "            \n",
    "            #print(actual_label, predict_label, predict_probabilities_tmp)\n",
    "            \n",
    "            actual_labels.append(actual_label)\n",
    "            predict_labels.append(predict_label)\n",
    "            predict_probabilities.append(predict_probabilities_tmp)\n",
    "\n",
    "            correct_flag = np.array_equal(actual_label, predict_label)\n",
    "            if correct_flag:\n",
    "                good_cnt = good_cnt + 1\n",
    "            else:\n",
    "                bad_cnt = bad_cnt + 1\n",
    "                if create_bad_results_list:\n",
    "                    bad_results.append([[actual_label],\n",
    "                                        [predict_label],\n",
    "                                        predict_probabilities_tmp,\n",
    "                                        image])\n",
    "    print(\" \")\n",
    "    print(\"total: \", total_cnt, \"  Good: \", good_cnt, \"  Bad: \",\n",
    "          bad_cnt, \"  percent good: \", str(good_cnt/total_cnt))\n",
    "\n",
    "    return actual_labels, predict_labels, predict_probabilities, \\\n",
    "        bad_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1550592,
     "status": "ok",
     "timestamp": 1586046633381,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "4T-oypFsh4zM",
    "outputId": "06c07c09-d047-43dd-8489-a72c4e3a21bd"
   },
   "outputs": [],
   "source": [
    "# Use model to generate predicted labels and probabilities\n",
    "\n",
    "labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset_cell(model, val_dataset, validation_steps, parms.BATCH_SIZE)\n",
    "\n",
    "# For troubleshooting, uncomment the print statement in predictions_using_dataset2 and set steps to 1\n",
    "#labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset_cell(model, val_dataset, 1, parms.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from personal library\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Used by show_confusion_matrix.\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title = 'Normalized confusion matrix'\n",
    "    else:\n",
    "        title = 'Confusion matrix'\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_confusion_matrix(labels,\n",
    "                          predict_labels,\n",
    "                          class_names,\n",
    "                          show_graph=True):\n",
    "    \"\"\"\n",
    "      Shows various accuracry measurements.\n",
    "\n",
    "      Args:\n",
    "        labels : actual labels\n",
    "        predict_labels : predicted labels\n",
    "        class_names : list of class names\n",
    "        show_graph : flag to show or not show the actual graph.  set\n",
    "                     to False for large number of classes.\n",
    "      Returns:\n",
    "        nothing\n",
    "    \"\"\"\n",
    "\n",
    "    # Accuracy score\n",
    "    print(\"Accuracy : \" + str(accuracy_score(np.array(labels), np.array(predict_labels))))\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(np.array(labels),\n",
    "                                np.array(predict_labels), digits=5))\n",
    "\n",
    "    if show_graph:\n",
    "        # Plot confusion matrix\n",
    "        cnf_matrix = confusion_matrix(labels, predict_labels)\n",
    "        print(cnf_matrix)\n",
    "        plot_confusion_matrix(cnf_matrix, classes=class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1550589,
     "status": "ok",
     "timestamp": 1586046633382,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "_IurHe_Uh4zO",
    "outputId": "4bedf73a-7d9f-494e-e11f-7ec659b0f1fd"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "                            accuracy_score\n",
    "\n",
    "show_confusion_matrix(labels, predict_labels, parms.CLASS_NAMES, show_graph=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kaggle-Cell-Training-V1.ipynb",
   "provenance": [
    {
     "file_id": "11uAUoq-UC0ftULnwk2LTbVryt3h-D3Q2",
     "timestamp": 1582044452297
    },
    {
     "file_id": "1KpHc6u2_eLqzTYla8bEH-SIPLGWtZ_vW",
     "timestamp": 1581035272578
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
