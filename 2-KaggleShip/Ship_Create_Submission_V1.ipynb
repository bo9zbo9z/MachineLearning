{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t22oBCHbpgHV"
   },
   "source": [
    "# Kaggle Ship Create Submission File on Kaggle Environment\n",
    "\n",
    "Link to competition: https://www.kaggle.com/c/airbus-ship-detection\n",
    "\n",
    "This notebook was converted from my prior Kaggle notebook.  Migrated to TF 2.x and converted various methods to be more native TF.  This will create a Kaggle submission file.  It uses a trained model and the normal tensor data set processing.  In the bottom cells you can check processing.  The model I created in the \"Ship_Create_Model_V1\" uses image dims of (224,224,3), so this notebook assums the same.  You can alter the expected dims in the configuration settings.  The final mask/rle encoded result is resized from (224, 224) to (768, 768).  This can also be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4M4h_6qhpgHZ"
   },
   "outputs": [],
   "source": [
    "# Change to True if using Kaggle environment....\n",
    "USING_KAGGLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DbPecelhpgHe"
   },
   "outputs": [],
   "source": [
    "# Normal includes...\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys, random, warnings, time, copy, csv\n",
    "import numpy as np \n",
    "from tqdm import notebook, trange, tqdm\n",
    "\n",
    "import IPython.display as display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import load_model \n",
    "from skimage.morphology import binary_opening, disk, label\n",
    "\n",
    "# This allows the runtime to decide how best to optimize CPU/GPU usage\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAN9pYJDRu_g"
   },
   "outputs": [],
   "source": [
    "# Config class that wraps global variable access, using personal libs is a pain in Kaggle, so copied in the class\n",
    "# Not all of the global vars are used, easier to jsut copy class over from lib\n",
    "\n",
    "class GlobalParms(object):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.keys_and_defaults = {\n",
    "         \"MODEL_NAME\": \"\",  # if you leave .h5 off, puts into a subdirectory\n",
    "         \"ROOT_PATH\": \"\",  # Location of the data for storing any data or files\n",
    "         \"TRAIN_DIR\": \"\",  # Subdirectory in the Root for Training files\n",
    "         \"TEST_DIR\": \"\",  # Optional subdirectory in  Root for Testing file\n",
    "         \"SUBMISSION_PATH\": None,  # Optional subdirectory for Contest files\n",
    "         \"MODEL_PATH\": None,  # Optional, subdirectory for saving/loading model\n",
    "         \"TRAIN_PATH\": None,  # Subdirectory in the Root for Training files\n",
    "         \"TEST_PATH\": None,  # Optional subdirectory in  Root for Testing file\n",
    "         \"SMALL_RUN\": False,   # Optional, run size will be reduced\n",
    "         \"NUM_CLASSES\": 0,  # Number of classes\n",
    "         \"CLASS_NAMES\": [],  # list of class names\n",
    "         \"IMAGE_ROWS\": 0,  # Row size of the image\n",
    "         \"IMAGE_COLS\": 0,  # Col size of the image\n",
    "         \"IMAGE_CHANNELS\": 0,  # Num of Channels, 1 for Greyscale, 3 for color\n",
    "         \"BATCH_SIZE\": 0,  # Number of images in each batch\n",
    "         \"EPOCS\": 0,  # Max number of training EPOCS\n",
    "         \"ROW_SCALE_FACTOR\": 1,  # Optional, allows scaling of an image.\n",
    "         \"COL_SCALE_FACTOR\": 1,  # Optional, allows scaling of an image.\n",
    "         \"IMAGE_EXT\": \".jpg\",  # Extent of the image file_ext\n",
    "         # Optional, default is np.float64, reduce memory by using np.float32\n",
    "         # or np.float16\n",
    "         \"IMAGE_DTYPE\": np.float32,\n",
    "         # Optional, change default if needed, can save memory space\n",
    "         \"Y_DTYPE\": np.int,\n",
    "         \"LOAD_MODEL\": False,  # Optional, If you want to load a saved model\n",
    "         \"SUBMISSION\": \"submission.csv\",  # Optional, Mainly used for Kaggle\n",
    "         \"METRICS\": ['accuracy'],  # ['categorical_accuracy'], ['accuracy']\n",
    "         \"FINAL_ACTIVATION\": 'sigmoid',  # sigmoid, softmax\n",
    "         \"LOSS\": \"\"  # 'binary_crossentropy', 'categorical_crossentropy'\n",
    "        }\n",
    "\n",
    "        self.__dict__.update(self.keys_and_defaults)\n",
    "        self.__dict__.update((k, v) for k, v in kwargs.items()\n",
    "                             if k in self.keys_and_defaults)\n",
    "\n",
    "        # Automatically reduce the training parms, change as needed\n",
    "        if self.__dict__[\"SMALL_RUN\"]:\n",
    "            self.__dict__[\"BATCH_SIZE\"] = 1\n",
    "            self.__dict__[\"EPOCS\"] = 2\n",
    "            self.__dict__[\"ROW_SCALE_FACTOR\"] = 1\n",
    "            self.__dict__[\"COL_SCALE_FACTOR\"] = 1\n",
    "\n",
    "        # Use configuration items to create real ones\n",
    "        self.__dict__[\"SCALED_ROW_DIM\"] = \\\n",
    "            np.int(self.__dict__[\"IMAGE_ROWS\"] /\n",
    "                   self.__dict__[\"ROW_SCALE_FACTOR\"])\n",
    "\n",
    "        self.__dict__[\"SCALED_COL_DIM\"] =  \\\n",
    "            np.int(self.__dict__[\"IMAGE_COLS\"] /\n",
    "                   self.__dict__[\"COL_SCALE_FACTOR\"])\n",
    "\n",
    "        if self.__dict__[\"TRAIN_PATH\"] is None:  # Not passed, so set it\n",
    "            self.__dict__[\"TRAIN_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"ROOT_PATH\"],\n",
    "                             self.__dict__[\"TRAIN_DIR\"])\n",
    "\n",
    "        if self.__dict__[\"TEST_PATH\"] is None:  # Not passed, so set it\n",
    "            self.__dict__[\"TEST_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"ROOT_PATH\"],\n",
    "                             self.__dict__[\"TEST_DIR\"])\n",
    "\n",
    "        if self.__dict__[\"SUBMISSION_PATH\"] is None:  # Not passed, so set\n",
    "            self.__dict__[\"SUBMISSION_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"ROOT_PATH\"],\n",
    "                             self.__dict__[\"SUBMISSION\"])\n",
    "        else:\n",
    "            self.__dict__[\"SUBMISSION_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"SUBMISSION_PATH\"],\n",
    "                             self.__dict__[\"SUBMISSION\"])\n",
    "\n",
    "        if self.__dict__[\"MODEL_PATH\"] is None:  # Not passed, so set it\n",
    "            self.__dict__[\"MODEL_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"ROOT_PATH\"],\n",
    "                             self.__dict__[\"MODEL_NAME\"])\n",
    "        else:\n",
    "            self.__dict__[\"MODEL_PATH\"] = \\\n",
    "                os.path.join(self.__dict__[\"MODEL_PATH\"],\n",
    "                             self.__dict__[\"MODEL_NAME\"])\n",
    "\n",
    "        self.__dict__[\"IMAGE_DIM\"] = \\\n",
    "            (self.__dict__[\"SCALED_ROW_DIM\"],\n",
    "             self.__dict__[\"SCALED_COL_DIM\"],\n",
    "             self.__dict__[\"IMAGE_CHANNELS\"])\n",
    "\n",
    "        if self.__dict__[\"IMAGE_CHANNELS\"] == 1:\n",
    "            self.__dict__[\"COLOR_MODE\"] = \"grayscale\"\n",
    "        else:\n",
    "            self.__dict__[\"COLOR_MODE\"] = \"rgb\"\n",
    "\n",
    "    def set_train_path(self, train_path):\n",
    "        self.__dict__[\"TRAIN_PATH\"] = train_path\n",
    "\n",
    "    def set_class_names(self, class_name_list):\n",
    "        self.__dict__[\"CLASS_NAMES\"] = class_name_list\n",
    "\n",
    "        if self.__dict__[\"NUM_CLASSES\"] != \\\n",
    "           len(self.__dict__[\"CLASS_NAMES\"]):\n",
    "            raise ValueError(\"ERROR number of classses do not match, Classes: \"\n",
    "                             + str(self.__dict__[\"NUM_CLASSES\"])\n",
    "                             + \" Class List: \"\n",
    "                             + str(self.__dict__[\"CLASS_NAMES\"]))\n",
    "\n",
    "    def print_contents(self):\n",
    "        print(self.__dict__)\n",
    "\n",
    "    def print_key_value(self):\n",
    "        for key, value in self.__dict__.items():\n",
    "            print(key, \":\", value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwZG6OTrpgHk"
   },
   "source": [
    "## Various Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "error",
     "timestamp": 1584898147443,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "Fu7fxm8fpgHl",
    "outputId": "0ca6418d-510f-4ff6-e2a7-96be8328b167"
   },
   "outputs": [],
   "source": [
    "# Set these to match your environment\n",
    "\n",
    "if USING_KAGGLE:\n",
    "    ROOT_PATH = \"../input/airbus-ship-detection/\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "else:\n",
    "    ROOT_PATH = \"/Users/john/Documents/ImageData/KaggleShip/\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "\n",
    "# Establish global dictionary\n",
    "parms = GlobalParms(ROOT_PATH=ROOT_PATH,\n",
    "                    MODEL_NAME=\"airModel.h5\",\n",
    "                    MODEL_PATH=\"\",\n",
    "                    TEST_DIR=\"test_v2\", \n",
    "                    IMAGE_ROWS=224,\n",
    "                    IMAGE_COLS=224,\n",
    "                    IMAGE_CHANNELS=3,\n",
    "                    SUBMISSION=\"submission.csv\",\n",
    "                    IMAGE_EXT=\".jpg\")\n",
    "\n",
    "parms.print_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oxvOvXdpgHq"
   },
   "outputs": [],
   "source": [
    "\n",
    "def multi_rle_encode(img, **kwargs):\n",
    "    '''\n",
    "    Encode connected regions as separated masks\n",
    "    '''\n",
    "    labels, num_labels = label(img, return_num=True)\n",
    "    #print(\"Labels \", num_labels, \" image dim: \", img.ndim)\n",
    "    #for i in range(num_labels):\n",
    "    #    print(\"label \", i, \" nonzero \", np.sum(labels[i]))\n",
    "        \n",
    "    if img.ndim > 2:\n",
    "        return [rle_encode(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n",
    "    else:\n",
    "        return [rle_encode(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n",
    "    \n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img, min_max_threshold=1e-3, max_mean_threshold=None):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    \n",
    "    A return of None means there is nothing to create, no masks.  No masks are added back at the very end.\n",
    "    This means that only masks are returned at first - helps with understanding how accurate.\n",
    "    '''\n",
    "    #print(\"rle_encode \", np.count_nonzero(img))\n",
    "    if np.count_nonzero(img) < 25:\n",
    "        return None\n",
    "    if np.max(img) < min_max_threshold:\n",
    "        return None ## no need to encode if it's all zeros\n",
    "    if max_mean_threshold and np.mean(img) > max_mean_threshold:\n",
    "        return None ## ignore overfilled mask\n",
    "    \n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list, shape=(768, 768)):\n",
    "    \"\"\"Take the individual ship masks and create a single mask array for all ships\"\"\"\n",
    "    \n",
    "    all_masks = np.zeros(shape, dtype = np.int16)\n",
    "    #print(\"All masks \", all_masks.shape)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            #print('calling decode', mask)\n",
    "            all_masks += rle_decode(mask, shape)\n",
    "    return np.expand_dims(all_masks, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UwGTA4CbpgHy"
   },
   "outputs": [],
   "source": [
    "# Shows image and masks\n",
    "def show_batch_mask(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        #print(display_list[i].shape)\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# Shows the images and executes the model for predictions\n",
    "def show_test_predictions(model, dataset=None,  num=1):\n",
    "    if dataset:\n",
    "        for image, image_id in dataset.take(num):\n",
    "            #print(image.shape)\n",
    "            pred_mask = model.predict(image)[0]\n",
    "            pred_mask = np.where(pred_mask > 0.5, 1, 0)\n",
    "            show_batch_mask([image[0], pred_mask])\n",
    "    else:\n",
    "        show_batch_mask([sample_image,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYegMLFBpgH1"
   },
   "outputs": [],
   "source": [
    "# Used for TensorFlow Datasets\n",
    "\n",
    "# Decode the image, convert to float, normalize by 255 and resize\n",
    "def decode_img(image: tf.Tensor) -> tf.Tensor:\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    image = tf.image.decode_jpeg(image, channels=parms.IMAGE_CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    image = tf.image.convert_image_dtype(image, parms.IMAGE_DTYPE)\n",
    "    return image\n",
    "\n",
    "# used by dataset to load images\n",
    "def process_test_image_id(image_id: tf.Tensor) -> tf.Tensor:\n",
    "    file_path = parms.TEST_PATH + \"/\" + image_id\n",
    "    # load the raw data from the file as a string\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = decode_img(image)\n",
    "    image = tf.image.resize(image, [parms.IMAGE_ROWS, parms.IMAGE_COLS])\n",
    "    return image, image_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_y1CV3ipgH5"
   },
   "source": [
    "## Build Tensor Dataset\n",
    "\n",
    "You can change the TEST_DIR in the config to use the training set if you want to see actual masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "_cell_guid": "",
    "_uuid": "",
    "colab": {},
    "colab_type": "code",
    "id": "CzT85-ASpgH6"
   },
   "outputs": [],
   "source": [
    "test_files = np.array(os.listdir(parms.TEST_PATH))\n",
    "print(\"Test: \", len(test_files), \" \", test_files[0])\n",
    "\n",
    "# modify to reduce the number of images processed, or comment out for full list\n",
    "test_files = test_files[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJOxXcHWpgH9"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from pd\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_files)\n",
    "\n",
    "# Verify image paths were loaded, all should be ok, but I've found a double check saves time later....\n",
    "for image_id in test_dataset.take(2):\n",
    "    print(image_id.numpy().decode(\"utf-8\"))\n",
    "\n",
    "# map training images to processing\n",
    "test_dataset = test_dataset.map(process_test_image_id, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked.  Both the actual image and the image_id should be returned\n",
    "for image, image_id in test_dataset.take(1):\n",
    "    print(\"Image ID: \", image_id.numpy().decode(\"utf-8\"))\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    some_image = image.numpy()\n",
    "\n",
    "#show_batch_mask([some_image, some_mask])\n",
    "\n",
    "test_dataset = test_dataset.batch(1).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czE3w1ewpgIA"
   },
   "outputs": [],
   "source": [
    "# Show the images, final check before running predictions.  Can change the take() number and execute multiple times\n",
    "for image, image_id in test_dataset.take(1):\n",
    "    sample_image= image[0]\n",
    "show_batch_mask([sample_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IendMPdHpgID"
   },
   "outputs": [],
   "source": [
    "# If a custom loss was used in training, need to have it here for model loading.  I included the ones I have been \n",
    "# playing with...\n",
    "\n",
    "# https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/\n",
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1,2,3))\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=(1,2,3))\n",
    "    return tf.reshape(1 - numerator / denominator, (-1, 1, 1))\n",
    "\n",
    "def combo_loss(y_true, y_pred):\n",
    "    def dice_loss(y_true, y_pred):\n",
    "        numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1,2,3))\n",
    "        denominator = tf.reduce_sum(y_true + y_pred, axis=(1,2,3))\n",
    "        return tf.reshape(1 - numerator / denominator, (-1, 1, 1))\n",
    "    return tf.keras.losses.binary_crossentropy(y_true, y_pred, from_logits=True) + dice_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6yBGsUw2pgIF"
   },
   "outputs": [],
   "source": [
    "# CHANGE THIS TO WHERE YOUR MODEL IS LOCATED...\n",
    "\n",
    "model_path = parms.MODEL_PATH\n",
    "seg_model = load_model(model_path, custom_objects={'combo_loss': combo_loss}) # Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTFuLEuGpgII"
   },
   "outputs": [],
   "source": [
    "show_test_predictions(seg_model, test_dataset, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rc1LJHAypgIM"
   },
   "outputs": [],
   "source": [
    "# Build predictions.  CV2 is used to resize the predicted mask.\n",
    "import cv2\n",
    "\n",
    "# predict and encode the result.  If None, then ignore the image, no ships were found or ships were too small.\n",
    "def pred_encode(image, image_id, model, **kwargs):\n",
    "    cur_rles = []\n",
    "    pred_mask = model.predict(image)[0]\n",
    "    \n",
    "    # need to enlarge the mask to 768,768 for final prediction\n",
    "    # for testing, you can comment this out and leave at 224,224\n",
    "    pred_mask = cv2.resize(pred_mask, dsize=(768,768), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    pred_mask = np.where(pred_mask > 0.5, 1, 0) \n",
    "    #print(image_id, np.count_nonzero(pred_mask))\n",
    "    cur_rles += multi_rle_encode(pred_mask, **kwargs)        \n",
    "    return [[image_id, rle] for rle in cur_rles if rle is not None]\n",
    "\n",
    "# Loop through the dataset and process the images\n",
    "def build_test_masks(dataset, model, steps, test):\n",
    "    if test == True:\n",
    "        steps = 2\n",
    "        \n",
    "    test_pred = []\n",
    "    for image_tf, image_id_tf in tqdm(dataset.take(steps)):\n",
    "        image = image_tf.numpy()\n",
    "        image_id = image_id_tf.numpy()[0].decode(\"utf-8\")\n",
    "        if test:\n",
    "            print(\"Image ID: \", image_id)\n",
    "            print(\"Image shape: {}  Max: {}  Min: {}\".format(image.shape, np.max(image), np.min(image)))\n",
    "\n",
    "        test_pred += pred_encode(image, image_id, model, min_max_threshold=1.0)\n",
    "            \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjMbCraZpgIO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build the list of results, only images that had ships were returned\n",
    "\n",
    "steps = len(test_files)\n",
    "test_pred = build_test_masks(test_dataset, seg_model, steps=steps, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Quw-2wjDpgIR"
   },
   "source": [
    "# Submission Notes...\n",
    "\n",
    "There is additional post processing to clean-up the mask that I did not show.  Basically, there is a balance between removing random predictions vs leaving them.  The small dots or \"ships\" could be actual ships or they could be bad predictions.  This only works on grayscale, try something like a dialation followed by a erosion.  (This is a closing operation.)\n",
    "\n",
    "https://scikit-image.org/docs/dev/api/skimage.morphology.html\n",
    "\n",
    "from skimage.morphology import erosion, dilation, disk\n",
    "- selem = disk(6)\n",
    "- return erosion(dilation(mask, selem), selem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfyqNGfWpgIS"
   },
   "outputs": [],
   "source": [
    "# Create dataframe from result list\n",
    "sub = pd.DataFrame(test_pred)\n",
    "sub.columns = ['ImageId', 'EncodedPixels']\n",
    "sub = sub[sub.EncodedPixels.notnull()]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LhH7KlhxpgIU"
   },
   "outputs": [],
   "source": [
    "# Raw final display of images and predictions from submission file\n",
    "# Onle last check....\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "def masks_using_color(in_mask_list, shape=(768,768)):\n",
    "    # Take the individual ship masks and create a color mask array for each ships\n",
    "    all_masks = np.zeros(shape, dtype = np.float)\n",
    "    scale = lambda x: (len(in_mask_list)+x+1) / (len(in_mask_list)*2) ## scale the heatmap image to shift \n",
    "    for i,mask in enumerate(in_mask_list):\n",
    "        if isinstance(mask, str):\n",
    "            all_masks[:,:] += scale(i) * rle_decode(mask, shape=shape)\n",
    "    return all_masks\n",
    "\n",
    "TOP_PREDICTIONS=5\n",
    "fig, m_axs = plt.subplots(TOP_PREDICTIONS, 2, figsize = (9, TOP_PREDICTIONS*5))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "\n",
    "for (ax1, ax2), image_name in zip(m_axs, sub.ImageId.unique()[:TOP_PREDICTIONS]):\n",
    "    image = imread(os.path.join(parms.TEST_PATH, image_name))\n",
    "    image = np.expand_dims(image, 0)/255.0\n",
    "    ax1.imshow(image[0])\n",
    "    ax1.set_title('Image: ' + image_name)\n",
    "    ax2.imshow(masks_using_color(sub.query('ImageId==\"{}\"'.format(image_name))['EncodedPixels']))\n",
    "    ax2.set_title('Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtL5MdzqpgIX"
   },
   "outputs": [],
   "source": [
    "# Create final csv file\n",
    "# This is where images that did not have any predicted ships are added - join with sample_submission file\n",
    "sub1 = pd.read_csv(parms.ROOT_PATH + 'sample_submission_v2.csv')\n",
    "sub1 = pd.DataFrame(np.setdiff1d(sub1['ImageId'].unique(), sub['ImageId'].unique(), assume_unique=True), columns=['ImageId'])\n",
    "sub1['EncodedPixels'] = None\n",
    "print(len(sub1), len(sub))\n",
    "\n",
    "sub = pd.concat([sub, sub1])\n",
    "print(len(sub), \"  Path: \", parms.SUBMISSION_PATH)\n",
    "sub.to_csv(parms.SUBMISSION_PATH, index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RuizXjhgpgIa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Ship_Create_Submission_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
