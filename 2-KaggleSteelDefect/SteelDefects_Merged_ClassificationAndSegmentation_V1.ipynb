{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rl85J9Iqh4yQ"
   },
   "source": [
    "## Kaggle Steel Defects - Merged Classification and Segmentation\n",
    "\n",
    "Link to competition: https://www.kaggle.com/c/severstal-steel-defect-detection\n",
    "\n",
    "This notebook was converted from my prior Kaggle notebook.  Migrated to TF 2.x and converted various methods to be more native TF.  This notebook combines the Classification and Segmentation models.  A first classification pass is done on all images.  Images that were identified as having defects were then use to on the second segmentation pass.  The final step is to merge the results into a simgle dataframe.  The final dice_coef score is from using the training images and comparing with the actual ground truth.\n",
    "\n",
    "\n",
    "Final dice_coef Score from Training images:  0.8544026199594487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24858,
     "status": "ok",
     "timestamp": 1587599568907,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "xjJySeIXh_md",
    "outputId": "e52dbb1c-f7ca-4479-f36f-1e45bb39d722"
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "# Google Collab specific stuff....\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "!ls \"/content/drive/My Drive\"\n",
    "\n",
    "USING_COLLAB = True\n",
    "%tensorflow_version 2.x\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28397,
     "status": "ok",
     "timestamp": 1587599572457,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "8kn1SgibviFV",
    "outputId": "c0b8e7f6-355e-4fd0-dfe1-415ae233211a"
   },
   "outputs": [],
   "source": [
    "# To start, install kaggle libs\n",
    "#!pip install -q kaggle\n",
    "\n",
    "# Workaround to install the newest version\n",
    "# https://stackoverflow.com/questions/58643979/google-colaboratory-use-kaggle-server-version-1-5-6-client-version-1-5-4-fai\n",
    "!pip install kaggle --upgrade --force-reinstall --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38937,
     "status": "ok",
     "timestamp": 1587599583005,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "xWXUL38Tvn8k",
    "outputId": "d64f0e4a-27b0-4ad4-ae11-4ec2cfd7efe6"
   },
   "outputs": [],
   "source": [
    "# Upload your \"kaggle.json\" file that you created from your Kaggle Account tab\n",
    "# If you downloaded it, it would be in your \"Downloads\" directory\n",
    "\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45464,
     "status": "ok",
     "timestamp": 1587599589541,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "ZttY2gU-voIb",
    "outputId": "3a031fe4-54a6-46c3-9c12-cfb1ed5aea59"
   },
   "outputs": [],
   "source": [
    "# On your VM, create kaggle directory and modify access rights\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73468,
     "status": "ok",
     "timestamp": 1587599617552,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "aYXtZYElvoUy",
    "outputId": "e1cbd8d4-9565-443d-bc52-116fa4573c1b"
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions list\n",
    "!kaggle competitions download -c severstal-steel-defect-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 103965,
     "status": "ok",
     "timestamp": 1587599648057,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "tQSrMlPlwA_c",
    "outputId": "5afc1661-a579-430a-b7b6-fff3a4a3f6a4"
   },
   "outputs": [],
   "source": [
    "!unzip -uq severstal-steel-defect-detection.zip \n",
    "!ls train_images/a75bb4c01*.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhuQ5I7Aevr7"
   },
   "outputs": [],
   "source": [
    "# Cleanup to add some space....\n",
    "!rm -r test_images\n",
    "!rm severstal-steel-defect-detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 107490,
     "status": "ok",
     "timestamp": 1587599651591,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "6w1an-l5h4yT",
    "outputId": "1235c4f9-56ce-41e8-908b-c17f8ebca746"
   },
   "outputs": [],
   "source": [
    "# Setup sys.path to find MachineLearning lib directory\n",
    "\n",
    "try: USING_COLLAB\n",
    "except NameError: USING_COLLAB = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "if \"MachineLearning\" in sys.path[0]:\n",
    "    pass\n",
    "else:\n",
    "    print(sys.path)\n",
    "    if USING_COLLAB:\n",
    "        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    else:\n",
    "        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1DL2FAhfsRf"
   },
   "outputs": [],
   "source": [
    "#%reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 111793,
     "status": "ok",
     "timestamp": 1587599655903,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "csTt9CUvh4yZ",
    "outputId": "60947a79-fb4a-4877-f2d1-a8ad293220c8"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys, random, warnings, time, copy, csv, gc\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook, tnrange, tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "print(\"AUTOTUNE: \", AUTOTUNE)\n",
    "\n",
    "from TrainingUtils import *\n",
    "from losses_and_metrics.Losses_Babakhin import make_loss, Kaggle_IoU_Precision, dice_coef_loss_bce\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aplx71Xjh4yg"
   },
   "source": [
    "## Helper methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 111784,
     "status": "ok",
     "timestamp": 1587599655904,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "PMdwqph-h4yd",
    "outputId": "849a7e7f-db36-4597-f89c-0a1a796d86f6"
   },
   "outputs": [],
   "source": [
    "# GLOBALS/CONFIG ITEMS\n",
    "\n",
    "# Set root directory path to data\n",
    "if USING_COLLAB:\n",
    "    #ROOT_PATH = \"/content/drive/My Drive/ImageData/KaggleSteelDefects\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    ROOT_PATH = \"\"\n",
    "    MODEL_PATH= \"/content/drive/My Drive/ImageData/KaggleSteelDefects\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "else:\n",
    "    ROOT_PATH = \"/Users/john/Documents/ImageData/KaggleSteelDefects\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    MODEL_PATH= \"/Users/john/Documents/ImageData/KaggleSteelDefects\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "# Establish global Classification dictionary\n",
    "parms_class = GlobalParms(MODEL_NAME=\"model-SteelDefects-Classification-V01.h5\",\n",
    "                    ROOT_PATH=ROOT_PATH,\n",
    "                    TEST_PATH=\"train_images\", \n",
    "                    MODEL_PATH=MODEL_PATH,\n",
    "                    NUM_CLASSES=2,\n",
    "                    CLASS_NAMES=[\"Good\", \"Defect\"],\n",
    "                    IMAGE_ROWS=224,\n",
    "                    IMAGE_COLS=224,\n",
    "                    IMAGE_CHANNELS=3,\n",
    "                    BATCH_SIZE=32)\n",
    "\n",
    "parms_class.print_contents()\n",
    "\n",
    "# Establish global Segmentation dictionary\n",
    "parms_seg = GlobalParms(MODEL_NAME=\"model-SteelDefects-Segmentation-V01.h5\",\n",
    "                    ROOT_PATH=ROOT_PATH,\n",
    "                    TEST_PATH=\"train_images\", \n",
    "                    MODEL_PATH=MODEL_PATH,\n",
    "                    NUM_CLASSES=4,\n",
    "                    CLASS_NAMES=[\"1\", \"2\", \"3\", \"4\"],\n",
    "                    IMAGE_ROWS=256,\n",
    "                    IMAGE_COLS=800,\n",
    "                    IMAGE_CHANNELS=3,\n",
    "                    BATCH_SIZE=32)\n",
    "\n",
    "\n",
    "parms_seg.print_contents()\n",
    "\n",
    "# Other globals...\n",
    "ORIG_MASK_SHAPE = (256, 1600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mhhvmqN7aFa"
   },
   "outputs": [],
   "source": [
    "# Simple helper method to display batches of images with labels....  \n",
    "\n",
    "def show_segmentation_image_masks(image_in, masks_in=None):\n",
    "    if tf.is_tensor(image_in):\n",
    "        image = image_in.numpy()\n",
    "    else:\n",
    "        image = image_in\n",
    "\n",
    "    if tf.is_tensor(masks_in): \n",
    "        masks = masks_in.numpy()\n",
    "    else:\n",
    "        masks = masks_in\n",
    "\n",
    "    #print(image.shape, masks.shape)\n",
    "\n",
    "    # cv2.polylines and cv2.findContours display better when range is 0-255\n",
    "    # https://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html\n",
    "    image = image * 255\n",
    "    palet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]\n",
    "    fig, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "    if masks is not None:\n",
    "        title = \"Labels: \"\n",
    "        for j in range(parms_seg.NUM_CLASSES):\n",
    "            msk = np.ascontiguousarray(masks[:, :, j], dtype=np.uint8)\n",
    "            if np.count_nonzero(msk) > 0:\n",
    "                title = title + str(j+1) + \",  \"\n",
    "                contours, _ = cv2.findContours(msk, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "                for i in range(0, len(contours)):\n",
    "                    cv2.polylines(image, contours[i], True, palet[j], 2) \n",
    "\n",
    "        title = title[:-3]  \n",
    "        ax.set_title(title)\n",
    "\n",
    "    #ax.imshow(tf.keras.preprocessing.image.array_to_img(image), cmap=plt.get_cmap('gray'))\n",
    "    #print(image.shape, image.dtype, np.max(image), np.min(image))\n",
    "    ax.imshow(image/255, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "def show_segmentation_batch_image_masks(image, masks=None):\n",
    "    for i in range(len(image)):\n",
    "        if masks is None:\n",
    "            show_segmentation_image_masks(image[i])\n",
    "        else:\n",
    "            show_segmentation_image_masks(image[i], masks[i])\n",
    "\n",
    "\n",
    "# Simple helper method to display batches of clasification images      \n",
    "def show_classification_batch(image_batch, label_batch=None, number_to_show=25, r=5, c=5, print_shape=False):\n",
    "    show_number = min(number_to_show, parms_class.BATCH_SIZE)\n",
    "    show_number = min(show_number, len(image_batch))\n",
    "\n",
    "    if show_number < 8: #if small number, then change row, col and figure size\n",
    "        if parms_class.IMAGE_COLS > 64 or parms_class.IMAGE_ROWS > 64:\n",
    "            plt.figure(figsize=(25,25)) \n",
    "        else:\n",
    "            plt.figure(figsize=(10,10))  \n",
    "        r = 4\n",
    "        c = 2 \n",
    "    else:\n",
    "        plt.figure(figsize=(10,10))  \n",
    "\n",
    "    for n in range(show_number):\n",
    "        if print_shape:\n",
    "            print(\"Image shape: {}  Max: {}  Min: {}\".format(image_batch[n].shape, \n",
    "                                                             np.max(image_batch[n]), \n",
    "                                                             np.min(image_batch[n])))\n",
    "        ax = plt.subplot(r,c,n+1)\n",
    "        cmap=\"gray\"\n",
    "        if len(image_batch[n].shape) == 3:\n",
    "            if image_batch[n].shape[2] == 3:\n",
    "                cmap=\"viridis\"\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image_batch[n]), cmap=plt.get_cmap(cmap))\n",
    "        if label_batch is not None:\n",
    "            plt.title(parms.CLASS_NAMES[np.argmax(label_batch[n])])\n",
    "\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FhZQxXSA09c"
   },
   "outputs": [],
   "source": [
    "# Helper methods to create mask's or rle's\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(rle, input_shape):\n",
    "    width, height = input_shape[:2]\n",
    "    \n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    \n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def build_masks(rles, input_shape):\n",
    "    depth = len(rles)\n",
    "    masks = np.zeros((*input_shape, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks[:, :, i] = rle2mask(rle, input_shape)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = [mask2rle(masks[:, :, i]) for i in range(depth)]\n",
    "    \n",
    "    return rles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dg1IuTqEh4y0"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, Nadam, SGD\n",
    "########\n",
    "K = tf.keras.backend\n",
    "\n",
    "loss_function = \"bce_dice\"  # bce_dice, lovasz\n",
    "loss = make_loss(loss_function)    \n",
    "\n",
    "def dice_coef_np(y_true, y_pred, smooth=1):\n",
    "    y_true_f = np.ndarray.flatten(y_true)\n",
    "    y_pred_f = np.ndarray.flatten(y_pred)\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vj36IOCWQXce"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 111956,
     "status": "ok",
     "timestamp": 1587599656090,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "VlqtDZyuNZwH",
    "outputId": "67408530-4c83-4c6a-90d0-466996e0aa6b"
   },
   "outputs": [],
   "source": [
    "# Get all file names\n",
    "image_file_list = load_file_names_Util(parms_class.TEST_PATH,\n",
    "                                       parms_class.IMAGE_EXT,\n",
    "                                       full_file_path=False)\n",
    "print(image_file_list[:5])\n",
    "\n",
    "# Set steps and Create train ALL csv\n",
    "all_df = pd.DataFrame(image_file_list, columns=[\"ImageId\"])\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzIHTsEUcY2p"
   },
   "outputs": [],
   "source": [
    "# Mapped method to load classification images\n",
    "def process_load_calssification_image(image_id: tf.Tensor) -> tf.Tensor:\n",
    "    file_path = parms_class.TEST_PATH + \"/\" + image_id\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=parms_class.IMAGE_CHANNELS)\n",
    "    image = tf.image.convert_image_dtype(image, parms_class.IMAGE_DTYPE)\n",
    "    image = tf.image.resize(image, [parms_class.IMAGE_ROWS, parms_class.IMAGE_COLS])\n",
    "\n",
    "    return image_id, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120596,
     "status": "ok",
     "timestamp": 1587599664739,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "3MxUIepA5rF-",
    "outputId": "728df326-4308-4fa0-99b5-d2ad67b7737c"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from pf\n",
    "all_dataset = tf.data.Dataset.from_tensor_slices(all_df[\"ImageId\"].values)\n",
    "                                               \n",
    "# Verify image and label were loaded\n",
    "for image_id in all_dataset.take(2):\n",
    "    print(\"Image ID: \", image_id.numpy().decode(\"utf-8\"))\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "all_dataset = all_dataset.map(process_load_calssification_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image_id, image in all_dataset.take(1):\n",
    "    print(\"ImageId: \", image_id.numpy().decode(\"utf-8\"))\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    some_image = image.numpy()\n",
    "\n",
    "all_dataset = all_dataset.prefetch(1).repeat()\n",
    "\n",
    "# Uncomment to show the batch of images, execute this cell multiple times to see the images\n",
    "#for batch_image in train_dataset.take(1):\n",
    "#    show_classification_batch(batch_image)\n",
    "\n",
    "show_classification_batch([some_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 133845,
     "status": "ok",
     "timestamp": 1587599677996,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "XsGaN_VNJ8Wq",
    "outputId": "d518ca3f-c47f-4c6a-a158-79ab411def01"
   },
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "model_class = load_model(parms_class.MODEL_PATH)\n",
    "print(\"Loaded model: \", parms_class.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OOPeLkKJ8eU"
   },
   "outputs": [],
   "source": [
    "# Use model to generate predicted labels and probabilities\n",
    "\n",
    "def create_classification_predictions(model_actual,\n",
    "                              dataset,\n",
    "                              steps):\n",
    "    \"\"\"\n",
    "      Uses dataset to predict results and return list.\n",
    "\n",
    "      Args:\n",
    "        model_actual : trained model to use for predictions\n",
    "        dataset : dataset iterator\n",
    "        steps : number of batches to process\n",
    "        batch_size : size of the batch\n",
    "\n",
    "      Returns:\n",
    "        pred_results :  list of the ImageId's and classification result\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    classification_list = []\n",
    "    no_defect_list = []\n",
    "    defect_list = []\n",
    "\n",
    "    for batch_image_id, batch_image in tqdm(dataset.take(steps)):\n",
    "        image_id = batch_image_id.numpy().decode(\"utf-8\")\n",
    "        image = batch_image\n",
    "\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        predict_probabilities_tmp = model_actual.predict(image)[0]\n",
    "        predict_label = np.argmax(predict_probabilities_tmp)\n",
    "\n",
    "        classification_list.append([image_id, predict_label, predict_probabilities_tmp])\n",
    "        if predict_label == 0:\n",
    "            no_defect_list.append(image_id)\n",
    "        else:\n",
    "            defect_list.append(image_id)\n",
    "\n",
    "    return classification_list, no_defect_list, defect_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 495068,
     "status": "ok",
     "timestamp": 1587600880811,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "u9PAWZWlKLM1",
    "outputId": "c0ef4c9e-7e87-4055-a71c-a1ebe3a19091"
   },
   "outputs": [],
   "source": [
    "classification_list, no_defect_list, defect_list = create_classification_predictions(model_class, all_dataset, len(all_df))\n",
    "#classification_list, no_defect_list, defect_list = create_classification_predictions(model_class, all_dataset, 10)\n",
    "print(len(classification_list), classification_list[:10])\n",
    "print(len(no_defect_list), no_defect_list[:4])\n",
    "print(len(defect_list), defect_list[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1587600881211,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "XLvqg5ZKGcT0",
    "outputId": "031a0b87-fa71-4a46-a8c7-28cb7aaa6ddb"
   },
   "outputs": [],
   "source": [
    "classification_results = []\n",
    "for i, image_id in enumerate(no_defect_list):\n",
    "    classification_results.append([image_id+\"_1\", \"\"])\n",
    "    classification_results.append([image_id+\"_2\", \"\"])\n",
    "    classification_results.append([image_id+\"_3\", \"\"])\n",
    "    classification_results.append([image_id+\"_4\", \"\"])\n",
    "\n",
    "print(classification_results[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUhqwdVqKID_"
   },
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5535,
     "status": "ok",
     "timestamp": 1587599733449,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "tkrhk6FOh4zC",
    "outputId": "311dd05b-f0ae-4bcf-be5d-d0a07d9d2568"
   },
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "model_seg = load_model(parms_seg.MODEL_PATH, custom_objects={'loss': loss, 'dice_coef': dice_coef})\n",
    "print(\"loaded: \", parms_seg.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1935,
     "status": "ok",
     "timestamp": 1587600882777,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "HMnidHwZkv9f",
    "outputId": "4f4c86bb-0c43-4998-e8f4-60a8e8283b0d"
   },
   "outputs": [],
   "source": [
    "# build defect_df\n",
    "defect_df = pd.DataFrame(defect_list, columns=[\"ImageId\"])\n",
    "defect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDxsiJFVBRA6"
   },
   "outputs": [],
   "source": [
    "# Mapped method to load segmentation images\n",
    "def process_load_segmentation_image(image_id: tf.Tensor) -> tf.Tensor:\n",
    "    file_path = parms_seg.TEST_PATH + \"/\" + image_id\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=parms_seg.IMAGE_CHANNELS)\n",
    "    image = tf.image.convert_image_dtype(image, parms_seg.IMAGE_DTYPE)\n",
    "    image = tf.image.resize(image, [parms_seg.IMAGE_ROWS, parms_seg.IMAGE_COLS])\n",
    "\n",
    "    return image_id, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3239,
     "status": "ok",
     "timestamp": 1587600884094,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "tKc2goatgjho",
    "outputId": "a0b82466-c60b-48da-fb99-c5102a36ca37"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from pf\n",
    "defect_dataset = tf.data.Dataset.from_tensor_slices(defect_df[\"ImageId\"].values)\n",
    "                                               \n",
    "# Verify image and label were loaded\n",
    "for image_id in defect_dataset.take(2):\n",
    "    print(\"Image ID: \", image_id.numpy().decode(\"utf-8\"))\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "defect_dataset = defect_dataset.map(process_load_segmentation_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image_id, image in defect_dataset.take(1):\n",
    "    print(\"ImageId: \", image_id.numpy().decode(\"utf-8\"))\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    some_image = image.numpy()\n",
    "\n",
    "defect_dataset = defect_dataset.prefetch(1).repeat()\n",
    "\n",
    "# Uncomment to show the batch of images, execute this cell multiple times to see the images\n",
    "#for batch_image in defect_dataset.take(1):\n",
    "#    show_segmentation_batch_image_masks(batch_image)\n",
    "\n",
    "show_segmentation_batch_image_masks([some_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOWxlaMVCOSD"
   },
   "outputs": [],
   "source": [
    "def predictions_using_dataset_masks(model_actual,\n",
    "                              dataset,\n",
    "                              steps,\n",
    "                              pred_threshold=0.50):\n",
    "    \"\"\"\n",
    "      Uses generator to predict results.  Builds actual_labels, predict_labels\n",
    "      and predict_probabilities\n",
    "\n",
    "      Args:\n",
    "        model_actual : trained model to use for predictions\n",
    "        dataset : dataset iterator\n",
    "        steps : number of batches to process\n",
    "\n",
    "      Returns:\n",
    "        list of predicted defects with class and rle\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    segmentation_results = []\n",
    "\n",
    "    for batch_image_id, batch_image in tqdm(dataset.take(steps)):\n",
    "\n",
    "        image_id = batch_image_id.numpy().decode(\"utf-8\")\n",
    "        image = batch_image\n",
    "\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        # image = tf.reshape(image, (1, *image.shape))\n",
    "\n",
    "        predict_probabilities_tmp = model_actual.predict(image)[0]\n",
    "\n",
    "        pred_masks = np.where(predict_probabilities_tmp > pred_threshold, 1, 0)\n",
    "        if np.count_nonzero(pred_masks) == 0:\n",
    "            #print(\"none predicted found, adjusting np.where....\")\n",
    "            pred_masks = np.where(predict_probabilities_tmp > pred_threshold / 2, 1, 0) \n",
    "\n",
    "        #print(image_id, \"  pred_masks \", np.max(pred_masks), np.min(pred_masks))\n",
    "\n",
    "        pred_masks = np.resize(pred_masks, (*ORIG_MASK_SHAPE, parms_seg.NUM_CLASSES)) \n",
    "        pred_masks = np.where(pred_masks > 0.5, 1, 0)\n",
    "\n",
    "        pred_rles = build_rles(pred_masks)\n",
    "        #print(image_id, \"  pred_rles \", pred_rles)\n",
    "        segmentation_results.append([image_id+\"_1\", pred_rles[0]])\n",
    "        segmentation_results.append([image_id+\"_2\", pred_rles[1]])\n",
    "        segmentation_results.append([image_id+\"_3\", pred_rles[2]])\n",
    "        segmentation_results.append([image_id+\"_4\", pred_rles[3]])\n",
    "\n",
    "    return segmentation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 539909,
     "status": "ok",
     "timestamp": 1587601420779,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "4T-oypFsh4zM",
    "outputId": "7023463a-70d8-4107-886b-a879e5ad8909"
   },
   "outputs": [],
   "source": [
    "# Use model to generate predicted labels and probabilities\n",
    "\n",
    "segmentation_results = predictions_using_dataset_masks(model_seg, defect_dataset, len(defect_df))\n",
    "#segmentation_results = predictions_using_dataset_masks(model_seg, defect_dataset, 10)\n",
    "print(segmentation_results[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yBEMWf0tQnJt"
   },
   "source": [
    "## Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1742,
     "status": "ok",
     "timestamp": 1587601894604,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "4e2xRnkGh4zU",
    "outputId": "f2b4e92b-9e6b-49e3-ccb5-680f09df68f5"
   },
   "outputs": [],
   "source": [
    "#Create a df from both lists, 004f40c73.jpg_1, ImageId_ClassId,EncodedPixels\n",
    "submission_list = segmentation_results + classification_results\n",
    "sorted(submission_list)\n",
    "submission_df = pd.DataFrame(submission_list, columns =[\"ImageId_ClassId\", \"EncodedPixels\"])\n",
    "\n",
    "#submission_df.to_csv(\"<your directory>/submission.csv\")\n",
    "\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgtCWt5oKUj0"
   },
   "source": [
    "## Validate results against training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 540075,
     "status": "ok",
     "timestamp": 1587601420958,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "UE6coCOIKTh2",
    "outputId": "68b535c0-1e43-4657-b77b-a2e88783042d"
   },
   "outputs": [],
   "source": [
    "# Load train DEFECT csv\n",
    "image_defect_df = pd.read_csv(os.path.join(parms_seg.ROOT_PATH, \"train.csv\"))\n",
    "image_defect_df[\"ImageId_ClassId\"] = image_defect_df[\"ImageId\"]+\"_\"+image_defect_df[\"ClassId\"].astype(str)\n",
    "\n",
    "image_defect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 90078,
     "status": "ok",
     "timestamp": 1587601656875,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "slNQGgiJKTrU",
    "outputId": "d1d227cd-e384-4e5a-8bbc-db372c7c3f92"
   },
   "outputs": [],
   "source": [
    "def score_rle(defect_rle, sub_rle):\n",
    "    # did not find a real entry and no entry in submission, score 1\n",
    "    #print(\"rle sub: \", len(sub_rle), type(sub_rle), sub_rle,  \"  defect: \", len(defect_rle), type(defect_rle), defect_rle)\n",
    "\n",
    "    if (defect_rle == \"\") and (sub_rle == \"\"):\n",
    "        #print(\"Score: \", 1)\n",
    "        return 1.0\n",
    "    else: \n",
    "      # score rle's using dice\n",
    "        mask_defect = rle2mask(defect_rle, ORIG_MASK_SHAPE)\n",
    "        mask_sub = rle2mask(sub_rle, ORIG_MASK_SHAPE)\n",
    "        #print(\"mask defect \", mask_defect)\n",
    "        #print(\"mask sub \", mask_sub)\n",
    "\n",
    "        score = dice_coef_np(mask_defect, mask_sub)\n",
    "        #print(\"Score: \", score)\n",
    "        return score\n",
    "\n",
    "score = 0.0\n",
    "for i in tqdm(range(len(submission_list))):\n",
    "    sub_image_id = submission_list[i][0]\n",
    "    sub_rle = submission_list[i][1]\n",
    "    #print(sub_image_id, sub_rle)\n",
    "    image_class_df = image_defect_df.loc[image_defect_df[\"ImageId_ClassId\"] == sub_image_id] \n",
    "    tmp_str = image_class_df[\"EncodedPixels\"].values\n",
    "    if len(tmp_str) == 0:\n",
    "        tmp_str = \"\"\n",
    "    else:\n",
    "        tmp_str = tmp_str[0]\n",
    "    #print(\"asdfg \",len(tmp_str), tmp_str)\n",
    "    score += score_rle(tmp_str, sub_rle)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Score: \", score / len(submission_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xc84VkI0cAJq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SteelDefects_Merged_ClassificationAndSegmentation_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
