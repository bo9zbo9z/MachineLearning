{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rl85J9Iqh4yQ"
   },
   "source": [
    "## Kaggle Steel Defects - Segmentation (locate and identify defects with masks)\n",
    "\n",
    "Link to competition: https://www.kaggle.com/c/severstal-steel-defect-detection\n",
    "\n",
    "This notebook was converted from my prior Kaggle notebook.  Migrated to TF 2.x and converted various methods to be more native TF.  \n",
    "- Pre-trained model is from Pavel Yakubovshiy, (https://github.com/qubvel/segmentation_models) \n",
    "\n",
    "## Final Classification Report and metrics from Training images:\n",
    "\n",
    "Epoch 00010: loss: 0.1354 - dice_coef: 0.7605 - val_loss: 0.1564 - val_dice_coef: 0.7244 - lr: 5.0000e-05\n",
    "\n",
    "Total:  1416   Good class:  1053.0   Bad class:  363.0   class percent good:  0.7436440677966102\n",
    "\n",
    "Final dice_coef score:  0.5803109915075524\n",
    "\n",
    "Accuracy : 0.7436440677966102\n",
    "\n",
    "Classification Report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         4.0       0.96      0.99      0.98       907\n",
    "         5.0       0.00      0.00      0.00        29\n",
    "         6.0       0.00      0.00      0.00         2\n",
    "         8.0       0.85      0.53      0.65        95\n",
    "        12.0       0.62      0.88      0.73       101\n",
    "        16.0       0.00      0.00      0.00         0\n",
    "        17.0       0.00      0.00      0.00       168\n",
    "        18.0       0.00      0.00      0.00        34\n",
    "        19.0       0.00      0.00      0.00        16\n",
    "        20.0       0.23      0.38      0.29        45\n",
    "        21.0       0.00      0.00      0.00        14\n",
    "        24.0       0.00      0.00      0.00         5\n",
    "        28.0       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.74      1416\n",
    "    \n",
    "   macro avg       0.20      0.21      0.20      1416\n",
    "   \n",
    "weighted avg       0.73      0.74      0.73      1416\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3728,
     "status": "ok",
     "timestamp": 1587504180265,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "xjJySeIXh_md",
    "outputId": "3d488587-51c3-41d9-dcd4-fac2eae159ed"
   },
   "outputs": [],
   "source": [
    "#\"\"\"\n",
    "# Google Collab specific stuff....\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "!ls \"/content/drive/My Drive\"\n",
    "\n",
    "USING_COLLAB = True\n",
    "%tensorflow_version 2.x\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29781,
     "status": "ok",
     "timestamp": 1587492690763,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "8kn1SgibviFV",
    "outputId": "ab9b569b-73ab-42ee-ac36-8b98ca4074ce"
   },
   "outputs": [],
   "source": [
    "# To start, install kaggle libs\n",
    "#!pip install -q kaggle\n",
    "\n",
    "# Workaround to install the newest version\n",
    "# https://stackoverflow.com/questions/58643979/google-colaboratory-use-kaggle-server-version-1-5-6-client-version-1-5-4-fai\n",
    "!pip install kaggle --upgrade --force-reinstall --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39246,
     "status": "ok",
     "timestamp": 1587492700237,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "xWXUL38Tvn8k",
    "outputId": "a8cb7285-378e-4719-faa2-3454f95613c2"
   },
   "outputs": [],
   "source": [
    "# Upload your \"kaggle.json\" file that you created from your Kaggle Account tab\n",
    "# If you downloaded it, it would be in your \"Downloads\" directory\n",
    "\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46962,
     "status": "ok",
     "timestamp": 1587492707961,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "ZttY2gU-voIb",
    "outputId": "e60f75b9-231f-41ad-fd98-088aea843b89"
   },
   "outputs": [],
   "source": [
    "# On your VM, create kaggle directory and modify access rights\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73333,
     "status": "ok",
     "timestamp": 1587492734339,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "aYXtZYElvoUy",
    "outputId": "566742a6-c11f-4e27-b7a2-70dc5497900e"
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions list\n",
    "!kaggle competitions download -c severstal-steel-defect-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 106177,
     "status": "ok",
     "timestamp": 1587492767191,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "tQSrMlPlwA_c",
    "outputId": "93060956-47e9-4b17-d2a4-6b8900e2bb9d"
   },
   "outputs": [],
   "source": [
    "!unzip -uq severstal-steel-defect-detection.zip \n",
    "!ls train_images/a75bb4c01*.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhuQ5I7Aevr7"
   },
   "outputs": [],
   "source": [
    "# Cleanup to add some space....\n",
    "!rm -r test_images\n",
    "!rm severstal-steel-defect-detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 110164,
     "status": "ok",
     "timestamp": 1587492771188,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "6w1an-l5h4yT",
    "outputId": "f1a0babc-180a-44a9-9c8f-279b6cd0778d"
   },
   "outputs": [],
   "source": [
    "# Setup sys.path to find MachineLearning lib directory\n",
    "\n",
    "try: USING_COLLAB\n",
    "except NameError: USING_COLLAB = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "if \"MachineLearning\" in sys.path[0]:\n",
    "    pass\n",
    "else:\n",
    "    print(sys.path)\n",
    "    if USING_COLLAB:\n",
    "        sys.path.insert(0, '/content/drive/My Drive/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    else:\n",
    "        sys.path.insert(0, '/Users/john/Documents/GitHub/MachineLearning/lib')  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1DL2FAhfsRf"
   },
   "outputs": [],
   "source": [
    "#%reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115100,
     "status": "ok",
     "timestamp": 1587492776134,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "csTt9CUvh4yZ",
    "outputId": "2c8f3e0b-730e-41b1-c38e-9cec57513654"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os, sys, random, warnings, time, copy, csv, gc\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook, tnrange, tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "print(\"AUTOTUNE: \", AUTOTUNE)\n",
    "\n",
    "from TrainingUtils import *\n",
    "from losses_and_metrics.Losses_Babakhin import make_loss, Kaggle_IoU_Precision, dice_coef_loss_bce\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aplx71Xjh4yg"
   },
   "source": [
    "## Examine and understand data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1587504230135,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "PMdwqph-h4yd",
    "outputId": "d303a1c5-c289-497e-eb9b-fef287dc6d92"
   },
   "outputs": [],
   "source": [
    "# GLOBALS/CONFIG ITEMS\n",
    "\n",
    "# Set root directory path to data\n",
    "if USING_COLLAB:\n",
    "    #ROOT_PATH = \"/content/drive/My Drive/ImageData/KaggleSteelDefects\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    ROOT_PATH = \"\"\n",
    "    MODEL_PATH= \"/content/drive/My Drive/ImageData/KaggleSteelDefects\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "else:\n",
    "    ROOT_PATH = \"/Users/john/Documents/ImageData/KaggleSteelDefects\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    MODEL_PATH= \"/Users/john/Documents/ImageData/KaggleSteelDefects\"  ###### CHANGE FOR SPECIFIC ENVIRONMENT\n",
    "    \n",
    "# Establish global dictionary\n",
    "parms = GlobalParms(MODEL_NAME=\"model-SteelDefects-Segmentation-V01.h5\",\n",
    "                    ROOT_PATH=ROOT_PATH,\n",
    "                    #TRAIN_DIR=\"train_images\",\n",
    "                    TRAIN_PATH=\"train_images\", \n",
    "                    MODEL_PATH=MODEL_PATH,\n",
    "                    SMALL_RUN=False,\n",
    "                    NUM_CLASSES=4,\n",
    "                    CLASS_NAMES=[\"1\", \"2\", \"3\", \"4\"],\n",
    "                    IMAGE_ROWS=256,\n",
    "                    IMAGE_COLS=800,\n",
    "                    IMAGE_CHANNELS=3,\n",
    "                    BATCH_SIZE=8,\n",
    "                    EPOCS=20,\n",
    "                    IMAGE_EXT=\".jpg\",\n",
    "                    FINAL_ACTIVATION='sigmoid',\n",
    "                    LOSS=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
    "\n",
    "# Other globals...\n",
    "ORIG_MASK_SHAPE = (256, 1600)\n",
    "STARTING_MODEL_PATH = \"/content/drive/My Drive/GitHub/MachineLearning/2-KaggleSteelDefects/segmodel-256-800-c4-V01.h5\"\n",
    "\n",
    "parms.print_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mhhvmqN7aFa"
   },
   "outputs": [],
   "source": [
    "# Simple helper method to display batches of images with labels....  \n",
    "\n",
    "def show_image_masks(image_in, masks_in):\n",
    "    if tf.is_tensor(image_in):\n",
    "        image = image_in.numpy()\n",
    "    else:\n",
    "        image = image_in\n",
    "\n",
    "    if tf.is_tensor(masks_in): \n",
    "        masks = masks_in.numpy()\n",
    "    else:\n",
    "        masks = masks_in\n",
    "\n",
    "    #print(image.shape, masks.shape)\n",
    "\n",
    "    # cv2.polylines and cv2.findContours display better when range is 0-255\n",
    "    # https://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html\n",
    "    image = image * 255\n",
    "    palet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]\n",
    "    title = \"Labels: \"\n",
    "    fig, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "      \n",
    "    for j in range(parms.NUM_CLASSES):\n",
    "        msk = np.ascontiguousarray(masks[:, :, j], dtype=np.uint8)\n",
    "        if np.count_nonzero(msk) > 0:\n",
    "            title = title + str(j+1) + \",  \"\n",
    "            contours, _ = cv2.findContours(msk, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "            for i in range(0, len(contours)):\n",
    "                cv2.polylines(image, contours[i], True, palet[j], 2) \n",
    "\n",
    "    title = title[:-3]  \n",
    "    ax.set_title(title)\n",
    "\n",
    "    #ax.imshow(tf.keras.preprocessing.image.array_to_img(image), cmap=plt.get_cmap('gray'))\n",
    "    #print(image.shape, image.dtype, np.max(image), np.min(image))\n",
    "    ax.imshow(image/255, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "def show_batch_image_masks(image, masks):\n",
    "    for i in range(len(image)):\n",
    "        show_image_masks(image[i], masks[i])\n",
    "\n",
    "\n",
    "# Helper methods to create mask's or rle's\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(rle, input_shape):\n",
    "    width, height = input_shape[:2]\n",
    "    \n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    \n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def build_masks(rles, input_shape):\n",
    "    depth = len(rles)\n",
    "    masks = np.zeros((*input_shape, depth))\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks[:, :, i] = rle2mask(rle, input_shape)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = [mask2rle(masks[:, :, i])\n",
    "            for i in range(depth)]\n",
    "    \n",
    "    return rles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115335,
     "status": "ok",
     "timestamp": 1587492776390,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "VlqtDZyuNZwH",
    "outputId": "c5ba6ec1-0e74-4af7-bafe-12bfc6e49c73"
   },
   "outputs": [],
   "source": [
    "# Load train DEFECT csv\n",
    "image_defect_df = pd.read_csv(os.path.join(parms.ROOT_PATH, \"train.csv\"))\n",
    "\n",
    "# Load image file sizes for possible stratification usage\n",
    "image_defect_df['ImageSize'] = image_defect_df['ImageId'].map(lambda image_id: round(os.stat(os.path.join(parms.TRAIN_PATH, image_id)).st_size))\n",
    "#image_defect_df['ImageSize'] = 50\n",
    "\n",
    "print(image_defect_df.loc[image_defect_df[\"ImageId\"] == \"0025bde0c.jpg\"])\n",
    "image_defect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115329,
     "status": "ok",
     "timestamp": 1587492776391,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "cW1OhNAfnM9S",
    "outputId": "8ada81e6-4628-48f3-8dfc-ba74f6cfd2d5"
   },
   "outputs": [],
   "source": [
    "# Stratifing by image_size, my prior notebook used the number of white pixels, this was easier and gave a better spread\n",
    "image_defect_df_cut = pd.cut(image_defect_df[\"ImageSize\"], bins=[0, 85000, 104000, 115000, 1000000]) \n",
    "ax = image_defect_df_cut.value_counts(sort=False).plot.bar(rot=0, color=\"b\", figsize=(20,6)) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115322,
     "status": "ok",
     "timestamp": 1587492776391,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "3YRRc4omWOXS",
    "outputId": "5c56882d-ba51-4485-884f-6b466503b381"
   },
   "outputs": [],
   "source": [
    "# Apply method to create the group number\n",
    "def group_by_image_size(x):\n",
    "    #[0, 85000, 104000, 115000, 1000000])\n",
    "    if x < 85000:\n",
    "        return 0\n",
    "    elif x < 104000:\n",
    "        return 1\n",
    "    elif x < 115000:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "image_defect_df['ImageGroup'] = image_defect_df['ImageSize'].apply(group_by_image_size)\n",
    "image_defect_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115695,
     "status": "ok",
     "timestamp": 1587492776772,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "YC21p-btRfhJ",
    "outputId": "b0473521-7d25-4799-ddb2-76bac93c3273"
   },
   "outputs": [],
   "source": [
    "# Select a balanced subset for training\n",
    "SAMPLES_PER_GROUP = 200000\n",
    "balanced_train_df = image_defect_df.groupby('ImageGroup').apply(lambda x: x.sample(SAMPLES_PER_GROUP) if len(x) > SAMPLES_PER_GROUP else x)\n",
    "balanced_train_df['ImageGroup'].hist(bins=balanced_train_df['ImageGroup'].max()+1)\n",
    "print(balanced_train_df.shape[0], 'ImageGroup')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1R8KsrBkjgl"
   },
   "source": [
    "## Build an input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115689,
     "status": "ok",
     "timestamp": 1587492776773,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "q2ncufD4SKG8",
    "outputId": "9664c444-6aca-4c50-8a1a-4f2f867a8298"
   },
   "outputs": [],
   "source": [
    "# Split train and val, stratify by number of targets\n",
    "\n",
    "train_df, valid_df = train_test_split(balanced_train_df, \n",
    "                                      test_size = 0.2,\n",
    "                                      stratify = balanced_train_df['ImageGroup'])\n",
    "\n",
    "# Add some more training examples from the sparse examples\n",
    "#print('Original Training len: ', train_df.shape[0], \"  Validation len: \", valid_df.shape[0])\n",
    "#add_more_df = train_df.loc[train_df[\"DefectCount\"] > 1]\n",
    "#add_more_df = pd.concat([add_more_df, add_more_df])\n",
    "#train_df = pd.concat([train_df, add_more_df])\n",
    "#train_df.reset_index(drop=True)\n",
    "\n",
    "train_df = shuffle(train_df) # Shuffle\n",
    "\n",
    "print('After Adjust, Training len: ', train_df.shape[0], \"  Validation len: \", valid_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115683,
     "status": "ok",
     "timestamp": 1587492776774,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "LAt1pTMSZtI8",
    "outputId": "7c0292ff-fcd3-4cc7-ed99-87196a66f46b"
   },
   "outputs": [],
   "source": [
    "# set lengths and steps\n",
    "train_len = len(train_df)\n",
    "val_len = len(valid_df)\n",
    "images_list_len = train_len + val_len\n",
    "\n",
    "steps_per_epoch = np.ceil(train_len // parms.BATCH_SIZE) # set step sizes based on train & batch\n",
    "validation_steps = np.ceil(val_len // parms.BATCH_SIZE) # set step sizes based on val & batch\n",
    "\n",
    "print(\"Total number: \", images_list_len, \"  Train number: \", train_len, \"  Val number: \", val_len)\n",
    "print(\"Steps/EPOC: \", steps_per_epoch, \"  Steps/Validation: \", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 115675,
     "status": "ok",
     "timestamp": 1587492776774,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "AJ1h1bVeZ7CH",
    "outputId": "a85bf34b-1065-4f5b-b26f-329a1b79f3ef"
   },
   "outputs": [],
   "source": [
    "# Final look at the distribution since we added more of the sparse cases\n",
    "print(train_df[\"ImageGroup\"].value_counts())\n",
    "print(valid_df[\"ImageGroup\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhwlsx-48daB"
   },
   "source": [
    "### Training and Validation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzIHTsEUcY2p"
   },
   "outputs": [],
   "source": [
    "# Read, decode the image, convert to float\n",
    "def read_decode_image(image_id: tf.Tensor) -> tf.Tensor:\n",
    "    file_path = parms.TRAIN_PATH + \"/\" + image_id\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=parms.IMAGE_CHANNELS)\n",
    "    image = tf.image.convert_image_dtype(image, parms.IMAGE_DTYPE)\n",
    "    return image\n",
    "\n",
    "# Build mask(s) from rles\n",
    "def load_masks(image_id_in: tf.Tensor) -> tf.Tensor:\n",
    "    image_id = image_id_in.numpy().decode(\"utf-8\")\n",
    "    image_df = image_defect_df.loc[image_defect_df['ImageId'] == image_id]\n",
    "    #print(\"df \", image_id, image_df)\n",
    "\n",
    "    rles = [None] * parms.NUM_CLASSES # Create blank list\n",
    "    for i, image_row in image_df.iterrows():\n",
    "        indx = int(image_row[\"ClassId\"]) - 1\n",
    "        #print(\"row \", indx, image_row)\n",
    "        rles[indx] = image_row[\"EncodedPixels\"] # Fill in any encoded masks\n",
    "        \n",
    "    masks = build_masks(rles, input_shape=ORIG_MASK_SHAPE)\n",
    "\n",
    "    return masks\n",
    "\n",
    "# Augmentations for training dataset, done after cache\n",
    "def image_aug(image: tf.Tensor, masks: tf.Tensor) -> tf.Tensor:\n",
    "    # Must use custom precent, random.uniform, because both image and mask must match\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        masks = tf.image.flip_left_right(masks)\n",
    "        \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_up_down(image)\n",
    "        masks = tf.image.flip_up_down(masks)\n",
    "    \n",
    "    return image, masks\n",
    "\n",
    "# pre-cache mapped method to load image and masks\n",
    "def process_load_image_masks(image_id: tf.Tensor) -> tf.Tensor:\n",
    "    image = read_decode_image(image_id)  \n",
    "\n",
    "    [masks,] = tf.py_function(load_masks, [image_id], [tf.int32])  #parms must be tensors\n",
    "    masks.set_shape((*ORIG_MASK_SHAPE, parms.NUM_CLASSES))\n",
    "    \n",
    "    image = tf.image.resize(image, [parms.IMAGE_ROWS, parms.IMAGE_COLS])\n",
    "    masks = tf.image.resize(masks, [parms.IMAGE_ROWS, parms.IMAGE_COLS])\n",
    "\n",
    "    return image, masks\n",
    "\n",
    "# post-cache mapped method, does image augmentation\n",
    "def process_train_post_cache(image: tf.Tensor, masks: tf.Tensor) -> tf.Tensor:\n",
    "    image, masks = image_aug(image, masks)\n",
    "    return image, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10638,
     "status": "ok",
     "timestamp": 1587492910775,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "3MxUIepA5rF-",
    "outputId": "97f26116-cd1a-408e-d991-f65354a84c5f"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from pf\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_df[\"ImageId\"].values)\n",
    "                                               \n",
    "# Verify image and label were loaded\n",
    "for image_id in train_dataset.take(2):\n",
    "    train_image_id = image_id.numpy().decode(\"utf-8\")\n",
    "    print(\"Image ID: \", image_id.numpy().decode(\"utf-8\"))\n",
    "\n",
    "# map training images to processing, includes any augmentation\n",
    "train_dataset = train_dataset.map(process_load_image_masks, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, masks in train_dataset.take(1):\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    print(\"Masks shape: {}  Max: {}  Min: {}\".format(masks.numpy().shape, np.max(masks.numpy()), np.min(masks.numpy())))\n",
    "    some_image = image.numpy()\n",
    "    some_masks = masks.numpy()\n",
    "\n",
    "# Remove cache if running under Kaggle\n",
    "#train_dataset = train_dataset \\\n",
    "train_dataset = train_dataset.cache(\"./steel_train_seg.tfcache\") \\\n",
    "                             .map(process_train_post_cache, num_parallel_calls=AUTOTUNE) \\\n",
    "                             .batch(parms.BATCH_SIZE) \\\n",
    "                             .prefetch(1) \\\n",
    "                             .repeat()\n",
    "\n",
    "# Uncomment to show the batch of images, execute this cell multiple times to see the images\n",
    "#for batch_image, batch_masks in train_dataset.take(1):\n",
    "#    show_batch_image_masks(batch_image, batch_masks)\n",
    "\n",
    "show_batch_image_masks([some_image], [some_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EF_khIPYe2-y"
   },
   "outputs": [],
   "source": [
    "# Double check that training labels and image_id are all good, can use different image_id's\n",
    "image_defect_df.loc[image_defect_df[\"ImageId\"] == train_image_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1587492914248,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "8h8z2RKofa9y",
    "outputId": "c7c36b5b-1b73-46b6-dbd5-65354db863a0"
   },
   "outputs": [],
   "source": [
    "# Create Dataset from pd\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(valid_df[\"ImageId\"].values)\n",
    "\n",
    "\n",
    "# Verify image and label were loaded\n",
    "for image_id in val_dataset.take(2):\n",
    "    val_image_id = image_id.numpy().decode(\"utf-8\")\n",
    "    print(\"Image ID: \", image_id.numpy().decode(\"utf-8\"))\n",
    "\n",
    "    # map training images to processing, includes any augmentation\n",
    "val_dataset = val_dataset.map(process_load_image_masks, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Verify the mapping worked\n",
    "for image, masks in val_dataset.take(1):\n",
    "    print(\"Image shape: {}  Max: {}  Min: {}\".format(image.numpy().shape, np.max(image.numpy()), np.min(image.numpy())))\n",
    "    print(\"Masks shape: {}  Max: {}  Min: {}\".format(masks.numpy().shape, np.max(masks.numpy()), np.min(masks.numpy())))\n",
    "    some_image = image\n",
    "    some_masks = masks\n",
    "\n",
    "# Remove cache if running under Kaggle\n",
    "#val_dataset = val_dataset.cache(\"./steel_val_seg.tfcache2\") \\\n",
    "val_dataset = val_dataset \\\n",
    "                         .batch(parms.BATCH_SIZE) \\\n",
    "                         .prefetch(1) \\\n",
    "                         .repeat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YipJyMNThFtB"
   },
   "outputs": [],
   "source": [
    "# Double check that val labels and image_id are all good, can use different image_id's\n",
    "image_defect_df.loc[image_defect_df[\"ImageId\"] == val_image_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9958,
     "status": "ok",
     "timestamp": 1587492926975,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "juyUqlWvfbKE",
    "outputId": "197f948c-d0f9-483f-b510-00a0bbeb9c93"
   },
   "outputs": [],
   "source": [
    "# Final check before model training.  Test Validation or Train by changing the dataset\n",
    "\n",
    "#for batch_image, batch_masks in train_dataset.take(1):\n",
    "for batch_image, batch_masks in val_dataset.take(1):  \n",
    "    show_batch_image_masks(batch_image, batch_masks)\n",
    "    \n",
    "#show_batch_image_masks([some_image], [some_masks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WboW5rmAh4yv"
   },
   "source": [
    "## Build  model\n",
    "- add and validate pretrained model as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6KnOf_oh4yw"
   },
   "outputs": [],
   "source": [
    "# Create any call backs for training...These are the most common.\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, min_lr=1e-6)\n",
    "earlystopper = EarlyStopping(patience=6, verbose=1)\n",
    "checkpointer = ModelCheckpoint(parms.MODEL_PATH, monitor='val_dice_coef', verbose=1, mode=\"max\", save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dg1IuTqEh4y0"
   },
   "outputs": [],
   "source": [
    "# Create model and compile it\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization, UpSampling2D, Conv2DTranspose, Concatenate, Activation\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, Nadam, SGD\n",
    "########\n",
    "K = tf.keras.backend\n",
    "\n",
    "\n",
    "loss_function = \"bce_dice\"  # bce_dice, lovasz\n",
    "loss = make_loss(loss_function)    \n",
    "\n",
    "def dice_coef_np(y_true, y_pred, smooth=1):\n",
    "    y_true_f = np.ndarray.flatten(y_true)\n",
    "    y_pred_f = np.ndarray.flatten(y_pred)\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def compile_model(parms, model):\n",
    "    model.compile(\n",
    "        loss= loss,\n",
    "        optimizer=Adam(lr=0.00005),  #\n",
    "        metrics=[dice_coef])    \n",
    "    return model\n",
    "\n",
    "#def compile_model(parms, model):\n",
    "#    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "#                  loss= make_loss(loss_function),\n",
    "#                  metrics=[lb_metric])\n",
    "#    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UHJP9A8_lLnr"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xAAn8TkXx_q"
   },
   "outputs": [],
   "source": [
    "# Reload the model from prior runs\n",
    "#model = load_model(parms.MODEL_PATH, custom_objects={'loss': loss, 'dice_coef': dice_coef})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5213,
     "status": "ok",
     "timestamp": 1587493815115,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "iNoWnLV6QyJS",
    "outputId": "2fd3ebb7-8da1-493e-de49-e61661418563"
   },
   "outputs": [],
   "source": [
    "# train from empty seg model, comment out if loading existing model\n",
    "model = load_model(STARTING_MODEL_PATH)\n",
    "print(\"Loaded: \", STARTING_MODEL_PATH)\n",
    "\n",
    "model = compile_model(parms, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvN_9VrseIyG"
   },
   "outputs": [],
   "source": [
    "#!ls\n",
    "#!rm steel_train_seg.tfcache_0.lockfile\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8497941,
     "status": "error",
     "timestamp": 1587504122693,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "P_AE9vRvh4y8",
    "outputId": "0495e64f-44d5-4b9a-baf5-3d3734043d38",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=parms.EPOCS, \n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    callbacks=[reduce_lr, earlystopper, checkpointer] \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btOfnuWEh4y_"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot the training history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "plt.figure()\n",
    "history_df[['loss', 'val_loss']].plot(title=\"Loss\")\n",
    "plt.xlabel('Epocs')\n",
    "plt.ylabel('Loss')\n",
    "history_df[['dice_coef', 'val_dice_coef']].plot(title=\"Accuracy\")\n",
    "plt.xlabel('Epocs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COki5lZ0h4zG"
   },
   "source": [
    "## Validate model's predictions\n",
    "- Create actual_lables and predict_labels\n",
    "- Calculate Confusion Matrix & Accuracy\n",
    "- Display results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33111,
     "status": "ok",
     "timestamp": 1587504278742,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "tkrhk6FOh4zC",
    "outputId": "b0c02c1c-9304-4d16-aafd-c7355af1164d"
   },
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "   \n",
    "model = load_model(parms.MODEL_PATH, custom_objects={'loss': loss, 'dice_coef': dice_coef})\n",
    "print(\"loaded: \", parms.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAzyVsJ6RYHU"
   },
   "outputs": [],
   "source": [
    "# Show a batch of images with predictions and scores....\n",
    "for batch_image, batch_masks in train_dataset.take(1):\n",
    "    score_total = 0\n",
    "    pred_masks = model.predict(batch_image)\n",
    "    for z in range(parms.BATCH_SIZE):\n",
    "        show_image_masks(batch_image[z], batch_masks[z])\n",
    "        pred_masks_img = np.where(pred_masks[z] > 0.5, 1, 0)\n",
    "        if np.count_nonzero(pred_masks_img) == 0:\n",
    "            print(\"none predicted found, adjusting np.where....\")\n",
    "            pred_masks_img = np.where(pred_masks_img > 0.20, 1, 0)     \n",
    "        show_image_masks(batch_image[z], pred_masks_img)\n",
    "        score = dice_coef_np(batch_masks[z].numpy(), pred_masks_img)\n",
    "        score_total = score_total + score\n",
    "        print(z, \"  Score: \", score)\n",
    "\n",
    "    print(\"Final batch score: \", score_total / parms.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOWxlaMVCOSD"
   },
   "outputs": [],
   "source": [
    "def predictions_using_dataset_masks(model_actual,\n",
    "                              dataset,\n",
    "                              steps,\n",
    "                              batch_size,\n",
    "                              create_bad_results_list=False,\n",
    "                              score_min=0.10,\n",
    "                              predict_one_min=0.5):\n",
    "    \"\"\"\n",
    "      Uses generator to predict results.  Builds actual_labels, predict_labels\n",
    "      and predict_probabilities\n",
    "\n",
    "      Args:\n",
    "        model_actual : trained model to use for predictions\n",
    "        ds_iter : dataset iterator\n",
    "        steps : number of batches to process\n",
    "        create_bad_results_list : bool default True.  Lets you trun on/off\n",
    "            the creation of the bad results lists.\n",
    "\n",
    "      Returns:\n",
    "        actual_labels : list of actual labels\n",
    "        predict_labels : list of predicted labels\n",
    "        predict_probabilities : list of predicted probability array\n",
    "        bad_results : list of bad results [actual_labels, predict_labels,\n",
    "                      predict_probabilities, image]\n",
    "    \"\"\"\n",
    "\n",
    "    bad_cnt = 0.0\n",
    "    good_cnt = 0.0\n",
    "    total_cnt = 0\n",
    "    actual_labels = []\n",
    "    predict_labels = []\n",
    "    predict_probabilities = []\n",
    "    bad_results = []\n",
    "    score_total = 0\n",
    "\n",
    "    for image_batch, label_batch in tqdm(dataset.take(steps)):\n",
    "        for j in range(batch_size):\n",
    "            actual_label = []\n",
    "            pred_label = []\n",
    "            image = image_batch[j]\n",
    "            label = label_batch[j].numpy()\n",
    "            #print(\"label \", label.shape, np.max(label), np.min(label))\n",
    "\n",
    "            total_cnt += 1\n",
    "   \n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            # image = tf.reshape(image, (1, *image.shape))\n",
    "\n",
    "            predict_probabilities_tmp = model_actual.predict(image)[0]\n",
    "\n",
    "            pred_masks = np.where(predict_probabilities_tmp > 0.5, 1, 0)\n",
    "            if np.count_nonzero(pred_masks) == 0:\n",
    "                #print(\"none predicted found, adjusting np.where....\")\n",
    "                pred_masks = np.where(predict_probabilities_tmp > 0.20, 1, 0) \n",
    "\n",
    "            #show_image_masks(image[0], label)\n",
    "            #show_image_masks(image[0], pred_masks)\n",
    "\n",
    "            score = dice_coef_np(label, pred_masks)\n",
    "            score_total = score_total + score\n",
    "            #print(j, \"  Score: \", score)\n",
    "            #print(\"predict \", np.max(predict_probabilities_tmp[:,:,0]),\n",
    "            #                  np.max(predict_probabilities_tmp[:,:,1]),\n",
    "            #                  np.max(predict_probabilities_tmp[:,:,2]),\n",
    "            #                  np.max(predict_probabilities_tmp[:,:,3]))\n",
    "\n",
    "            predict_label = np.zeros(parms.NUM_CLASSES + 1)\n",
    "            actual_label =  np.zeros(parms.NUM_CLASSES + 1)\n",
    "            for z in range(parms.NUM_CLASSES):\n",
    "                if np.max(predict_probabilities_tmp[:, :, z]) > predict_one_min:\n",
    "                    predict_label[z] = 1\n",
    "\n",
    "                if np.max(label[:, :, z]) == 1:\n",
    "                    actual_label[z] = 1\n",
    "            \n",
    "            if score < score_min:\n",
    "                predict_label[4] = 1\n",
    "                actual_label[4] = 1\n",
    "\n",
    "            correct_flag = np.array_equal(actual_label, predict_label)\n",
    "\n",
    "            np_tmp = np.array([1,2,4,8,16])\n",
    "            actual_label_amt = np.sum(actual_label * np_tmp)\n",
    "            predict_label_amt = np.sum(predict_label * np_tmp)\n",
    "\n",
    "            actual_labels.append(actual_label_amt)\n",
    "            predict_labels.append(predict_label_amt)\n",
    "            predict_probabilities.append(predict_probabilities_tmp)\n",
    "            #print(correct_flag, \"  Label \", actual_label, \"  Pred Label \", predict_label)\n",
    "\n",
    "            if correct_flag:\n",
    "                good_cnt = good_cnt + 1\n",
    "            else:\n",
    "                bad_cnt = bad_cnt + 1\n",
    "\n",
    "            if score < score_min: # or could use correct_flag\n",
    "                if create_bad_results_list:\n",
    "                    bad_results.append([[actual_label],\n",
    "                                        [predict_label],\n",
    "                                        predict_probabilities_tmp,\n",
    "                                        score,\n",
    "                                        image])\n",
    "    print(\" \")\n",
    "    print(\"Total: \", total_cnt, \"  Good class: \", good_cnt, \"  Bad class: \",\n",
    "          bad_cnt, \"  class percent good: \", str(good_cnt/total_cnt))\n",
    "    print(\"Final dice_coef score: \", str(score_total / total_cnt))\n",
    "\n",
    "    return actual_labels, predict_labels, predict_probabilities, \\\n",
    "        bad_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 119597,
     "status": "ok",
     "timestamp": 1587504398363,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "4T-oypFsh4zM",
    "outputId": "4fb17c7f-e09f-45a9-f2cf-67dfe72bfe4b"
   },
   "outputs": [],
   "source": [
    "# Use model to generate predicted labels and probabilities\n",
    "\n",
    "#create_bad_results_list=True\n",
    "labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset_masks(model, val_dataset, validation_steps, parms.BATCH_SIZE)\n",
    "#labels, predict_labels, predict_probabilities, bad_results = predictions_using_dataset_masks(model, val_dataset, 1, parms.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkNS9yBcSG2t"
   },
   "outputs": [],
   "source": [
    "def show_confusion_matrix2(labels,\n",
    "                          predict_labels,\n",
    "                          show_graph=True):\n",
    "    \"\"\"\n",
    "      Shows various accuracry measurements.\n",
    "\n",
    "      Args:\n",
    "        labels : actual labels\n",
    "        predict_labels : predicted labels\n",
    "        class_names : list of class names\n",
    "        show_graph : flag to show or not show the actual graph.  set\n",
    "                     to False for large number of classes.\n",
    "      Returns:\n",
    "        nothing\n",
    "    \"\"\"\n",
    "\n",
    "    # Accuracy score\n",
    "    print(\"Accuracy : \" + str(accuracy_score(labels, predict_labels)))\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(np.array(labels),\n",
    "                                np.array(predict_labels)))\n",
    "    if show_graph:\n",
    "        # Plot confusion matrix\n",
    "        cnf_matrix = confusion_matrix(labels, predict_labels)\n",
    "        print(cnf_matrix)\n",
    "        plot_confusion_matrix(cnf_matrix, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120623,
     "status": "ok",
     "timestamp": 1587504399404,
     "user": {
      "displayName": "John Diekhoff",
      "photoUrl": "",
      "userId": "01476344131643501321"
     },
     "user_tz": 300
    },
    "id": "_IurHe_Uh4zO",
    "outputId": "d992b82c-c1ed-471b-93ec-512a82213867"
   },
   "outputs": [],
   "source": [
    "show_confusion_matrix2(labels, predict_labels)\n",
    "# defect 1->0,  2->1, 4->2, 8->3,  3->0+1, 16->no label & bad score  Larger than 16-> bad score, subtract 16 to get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4e2xRnkGh4zU"
   },
   "outputs": [],
   "source": [
    "#Create a df from the bad results list, can save as csv or use for further analysis\n",
    "bad_results_df = pd.DataFrame(bad_results, columns =['actual', 'predict', 'prob', 'image'])\n",
    "bad_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JW3AQv7Fh4zh"
   },
   "outputs": [],
   "source": [
    "bad_act, bad_pred, bad_prob, bad_images = zip(*bad_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reSRPklT5rG0"
   },
   "outputs": [],
   "source": [
    "# display images....        \n",
    "def show_bad_batch(image_batch, bad_act, bad_pred, number_to_show=25):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    show_number = number_to_show\n",
    "    if len(image_batch) < number_to_show:\n",
    "        show_number = len(image_batch)\n",
    "      \n",
    "    for n in range(show_number):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(np.squeeze(image_batch[n])))\n",
    "        #s = parms.CLASS_NAMES[bad_pred[n][0]]\n",
    "        s = \"Act: \"+ str(bad_act[n][0]) + \" Pred: \" + str(bad_pred[n][0])\n",
    "        plt.title(s)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8mTsZs0-5rG3"
   },
   "outputs": [],
   "source": [
    "\n",
    "show_bad_batch(bad_images, bad_act, bad_pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SteelDefects_Segmentation_V1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
